\onehalfspacing

Use Case driven

\section{Lösungsansatz: Wikidata als offener Forschungsdatenmanagement-Service}
Auf diese Prinzipien beruft sich auch die Wikimedia Foundation, für ihre Produkte und macht diese auch für die Wissenschaft interessant. Mittlerweile gibt es diverse Kooperationen zwischen wissenschaftlichen Einrichtungen und der Wikimedia. So hat die Deutsche Nationalbibliothek ein Projekt gestartet, in dem sie die GND zugänglicher und nachnutzbarer für gestalten will und damit ihre strenge GND-Policy
setzt alle FAIR-Prinzipien um
eigene Wikibase-Instanzen aufsetzen --> technisch aufwändig und Informatik-Kenntnisse, wäre von befragten Historiker*innen nicht umgesetzbar gewesen
ähnliche Infrastrukturen nicht gibt, direkt in Wikidata gearbeitet werden (das was derzeit zur Verfügung steht)
Gleichzeitig in dieser Arbeit: von größtmöglichem Open Tech Stack ausgehen, Einschränungen nach unten offen halten, aber Devise Open Science radikal umgesetzt werden, soll am Ende auch Drawbacks dieser prototypischen Umsetzung diskutiert werden, nicht in Stein gemeißelt ggf. nachjustieren, mutig offeneren Lösungen entgegentreten

Beispiele aus der historischen Forschung:
https://archivfuehrer-kolonialzeit.de/
https://blog.ehri-project.eu/2018/02/12/using-wikidata/


Sichtbarkeit von Daten, Datenkonsistenz und -integrität in Wikidata

Erklären, warum nicht eigene Wikibase-Instanz

\section{Implementierung}

Strukturiert an einen idealtypischen Forschungsprozess. Nicht alle möglichen Anwendungsfälle abgedeckt werden. Aber Abdeckung gesamten Forschungsdatenlebenszyklus sicher stellen

\subsection{Wikidata:WikiProject Destruction of the Economic Existence of the Jews Research}
bildet Grundlage

\subsection{Metadaten: Die Forschungsprojekte als Wikidata-Items}
Metadatenschema

\subsection{Modellierung mit den Wikidata-Entities}
Formale Beschreibung jüdischer Gewerbebetriebe Datenmodell, 
EntitySchema items, properties, qualifiers und references
\subsection{Erfassung im ,,Linked Data Interface''}

\subsection{Möglichkeiten der Datenanalyse und -visualisierung in Wikidata}

\subsection{Wikidata-Schnittstellen zur Daten(nach)nutzung}

Abfrage, Auswertung, Visualisierung, Zitation, Nachnutzung

Sparql query Service
Maps
stable URI's
Sparql Endpoints

\section{Ergebnisse}

Wie kann Schnittstelle zwischen Wissenschaft und öffentlichem Wissen/ Öffentlichkeit funktionieren (Fellow-Programm Wikimedia)

hier auf Desiderate aus den Interviews eingehen

\paragraph{Benefits}

\paragraph{Drawbacks}

Datenqualität in Wikidata nicht perfekt, aber bei Christoph auch nicht
Datenkonsistenz und -integrität

\paragraph{Sideeffects}

Datenqualität der Wikidata verbessern und Informationen auf der Wikipedia nachweislich stärker kontextualisieren als bisher
--> am Beispiel von \url{https://de.wikipedia.org/w/index.php?title=Wodka_Gorbatschow&oldid=222273519} und Q2587685

Abschließend zur Forschungsfeldbetrachtung ist festzustellen, dass das dieses inhaltlich mit steigender Anzahl von Lokalstudien in den letzten 20 Jahren enorm voranschritt, aber im Vergleich auf konzeptueller Ebene die Weiterentwicklung überraschend stagnierte. Wenn mehrheitlich in den Studien der Begriff ,,Arisierung'' (oder ,,Entjudung'') kritisch und problemorientiert hinterfragt wird, in der Konsequenz aber nicht aus der wissenschaftlichen Arbeit verbannt, sondern entgegen der eigenen Argumentation als Untersuchungsbegriff beibehalten wird, dann herrscht ein offensichtlicher Mangel an einer breiteren konzeptionellen und methodischen Auseinandersetzung im Forschungsfeld. Dafür spricht auch, dass es bis heute keine einheitliche Definition des Begriffs gibt.\footnote{Und die es auch in der Geschichte des Begriffs nie gegeben hat.\textbf{Vgl. Nietzel und Kreutzmüller}} Einerseits wird darunter speziell der Transfer von jüdischem Eigentum, insbesondere Firmeneigentum, in nicht-jüdischen Besitz und andererseits generisch der gesamte Prozess der wirtschaftlichen Existenzvernichtung der Juden gefasst, wobei dieser unterschiedlich ausgedehnt wurde\footnote{Nachweis} Einen allgemeingültigen wissenschaftlichen Konsens scheint es auf der methodischen Ebene im Forschungsfeld nicht zu geben. Unklar ist, warum nach den eindeutig nachvollziehbaren Gegeneinwänden und alternativen Vorschlägen aus dem Forschungsfeld selbst sich diese methodische Schwäche bis heute hartnäckig hält.


Die Herausforderung besteht darin, zentrale sowie einheitliche Infrastrukturen zu schaffen, die von den überwiegend einzelgeförderten Forschungsprojekten - bei der DFG immerhin mehr als ein Drittel im Jahr 2020 projektbezogener Einzelförderung – nicht allen Forschungsvorhaben ein nachhaltiges Forschungsdatenmanagement inhärent ist. Da es entsprechende Forschungsgebiete in der Vergangenheit schlichtweg noch nicht gab, war der Umgang mit Forschungsdaten mehr von individuellen digitalen Kenntnissen und Kompetenzen des oder der Wissenschaftler*in abhängig als von allgemeingültigen wissenschaftlichen Kriterien sowie technischen Standards. Zeitökonomisch betrachtet bedeutet der wissenschaftliche Umgang mit digitalen Forschungsdaten zudem Arbeitsaufwand, der zu den routinierten Abläufen hinzukommt. Erst recht, wenn sich ganz neu mit dieser Thematik auseinandergesetzt werden muss. Das wirft die berechtigte Frage nach dem Kosten-Nutzen-Verhältnis für die eigene Forschungsarbeit auf.

Eine Synthese dieser bisher nebeneinander existierenden Forschungsergebnisse gibt es noch nicht.\footnote{Vgl. Nietzel S.}