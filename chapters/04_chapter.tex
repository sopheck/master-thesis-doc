\onehalfspacing

Use Case driven

\section{Lösungsansatz: Wikidata als offener Forschungsdatenmanagement-Service}
Auf diese Prinzipien beruft sich auch die Wikimedia Foundation, für ihre Produkte und macht diese auch für die Wissenschaft interessant. Mittlerweile gibt es diverse Kooperationen zwischen wissenschaftlichen Einrichtungen und der Wikimedia. So hat die Deutsche Nationalbibliothek ein Projekt gestartet, in dem sie die GND zugänglicher und nachnutzbarer für gestalten will und damit ihre strenge GND-Policy
setzt alle FAIR-Prinzipien um
eigene Wikibase-Instanzen aufsetzen --> technisch aufwändig und Informatik-Kenntnisse, wäre von befragten Historiker*innen nicht umgesetzbar gewesen
ähnliche Infrastrukturen nicht gibt, direkt in Wikidata gearbeitet werden (das was derzeit zur Verfügung steht)
Gleichzeitig in dieser Arbeit: von größtmöglichem Open Tech Stack ausgehen, Einschränungen nach unten offen halten, aber Devise Open Science radikal umgesetzt werden, soll am Ende auch Drawbacks dieser prototypischen Umsetzung diskutiert werden, nicht in Stein gemeißelt ggf. nachjustieren, mutig offeneren Lösungen entgegentreten

Beispiele aus der historischen Forschung:
https://archivfuehrer-kolonialzeit.de/
https://blog.ehri-project.eu/2018/02/12/using-wikidata/


Sichtbarkeit von Daten, Datenkonsistenz und -integrität in Wikidata

Erklären, warum nicht eigene Wikibase-Instanz

\section{Implementierung}

Strukturiert an einen idealtypischen Forschungsprozess. Nicht alle möglichen Anwendungsfälle abgedeckt werden. Aber Abdeckung gesamten Forschungsdatenlebenszyklus sicher stellen

\subsection{Wikidata:WikiProject Destruction of the Economic Existence of the Jews Research}
bildet Grundlage

\subsection{Metadaten: Die Forschungsprojekte als Wikidata-Items}
Metadatenschema

\subsection{Modellierung mit den Wikidata-Entities}
Formale Beschreibung jüdischer Gewerbebetriebe Datenmodell, 
EntitySchema items, properties, qualifiers und references
\subsection{Erfassung jüdischer Gewerbebetriebe mit dem ,,Linked Data interface''}

\subsection{Möglichkeiten der Datenanalyse und -visualisierung in Wikidata}

\subsection{Wikidata-Schnittstellen zur Daten(nach)nutzung}

Abfrage, Auswertung, Visualisierung, Zitation, Nachnutzung

Sparql query Service
Maps
stable URI's
Sparql Endpoints

\section{Ergebnisse}

Wie kann Schnittstelle zwischen Wissenschaft und öffentlichem Wissen/ Öffentlichkeit funktionieren (Fellow-Programm Wikimedia)

\paragraph{Benefits}

\paragraph{Drawbacks}

Datenqualität in Wikidata nicht perfekt, aber bei Christoph auch nicht
Datenkonsistenz und -integrität

\paragraph{Sideeffects}

Datenqualität der Wikidata verbessern und Informationen auf der Wikipedia nachweislich stärker kontextualisieren als bisher
--> am Beispiel von \url{https://de.wikipedia.org/w/index.php?title=Wodka_Gorbatschow&oldid=222273519} und Q2587685


Die Herausforderung besteht darin, zentrale sowie einheitliche Infrastrukturen zu schaffen, die von den überwiegend einzelgeförderten Forschungsprojekten - bei der DFG immerhin mehr als ein Drittel im Jahr 2020 projektbezogener Einzelförderung – nicht allen Forschungsvorhaben ein nachhaltiges Forschungsdatenmanagement inhärent ist. Da es entsprechende Forschungsgebiete in der Vergangenheit schlichtweg noch nicht gab, war der Umgang mit Forschungsdaten mehr von individuellen digitalen Kenntnissen und Kompetenzen des oder der Wissenschaftler*in abhängig als von allgemeingültigen wissenschaftlichen Kriterien sowie technischen Standards. Zeitökonomisch betrachtet bedeutet der wissenschaftliche Umgang mit digitalen Forschungsdaten zudem Arbeitsaufwand, der zu den routinierten Abläufen hinzukommt. Erst recht, wenn sich ganz neu mit dieser Thematik auseinandergesetzt werden muss. Das wirft die berechtigte Frage nach dem Kosten-Nutzen-Verhältnis für die eigene Forschungsarbeit auf.