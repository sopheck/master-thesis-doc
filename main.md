---
author:
- |
  vorgelegt von:\
  Sophie Eckenstaler
date: am 07.06.2022
publishers: |
  Erstbetreuer: Prof. Dr. Rüdiger Hohls, Institut für
  Geschichtswissenschaften, HU Berlin\
  Zweitbetreuer: Prof. Dr. Michael Wildt, Institut für
  Geschichtswissenschaften, HU Berlin\
  Studiengang: Master of Arts, Geschichtswissenschaften, Schwerpunkt:
  Digital History\
  Matrikelnr.: 596272\
  E-Mail: sophie.eckenstaler@hu-berlin.de\
  Eberswalde, den 7. Juni 2022
subject: Masterarbeit
subtitle: Konzeption eines offenen Forschungsdatenmanagements am
  Beispiel von Forschungsdaten zu jüdischen Gewerbebetrieben im
  Nationalsozialismus
title: Open Science in den Geschichtswissenschaften?
titlehead: |
  Humboldt-Universität zu Berlin\
  Philosophische Fakultät\
  Institut für Geschichtswissenschaften
---

# Einleitung

Forschungsdatenmanagement in Verbindung

Die große Menge an Open Science Initiativen Anwendern von Open Science
Angeboten zeigt, dass Open Science in der Wissenschaft angekommen und in
Begriff ist, sich dort zu etablieren. Aufschwung erlebte Open Science
zuletzt im Zusammenhang mit der COVID-19-Pandemie, wo der als Mangel und
damit letzten Endes Leben zu retten angesehen Den Bedarf von Open
Science verstärkt.

Im Kern geht es auch darum, die Integrität von wissenschaftlicher
Forschung zu wahren, sie gerade im sogenannten postfaktischen Zeitalter
zu stärken, das heißt sie weniger anfällig für Betrug und Fälschung in
einer digitalen Welt zu machen.

Auch bei wissenschafts- wie gesellschaftspolitischen Entscheidungen
gewinnt Open Science auf Bundes- sowie auf EU-Ebene an Relevanz, wobei
zu konstatieren ist, dass der Schwerpunkt zumindest in Deutschland

Wenn auch noch nicht die volle Bandbreite von Open Science, so
unterstützt die Deutsche Forschungsgemeinschaft (DFG) immerhin offiziell
gezielt Open Access-Publikationen finanziell.

Die Europäische Union hat Open Science zu einem von insgesamt drei
Grundsatzzielen für die Forschungsarbeit in Europa erklärt und die
Deutsche UNESCO-Kommission betont in ihrer Empfehlung für Open Science:

,,Darüber hinaus besteht mit Open Science eine Chance auf die praktische
Umsetzung von seit Langem bestehenden politischen Forderungen: Mit Open
Science kann Teilhabe an und Zugang zu wissenschaftlichen Erkenntnissen
als Gemeingut und Menschenrecht praktisch umgesetzt werden, wie es
bereits seit Ende des Zweiten Weltkriegs in der Allgemeinen Erklärung
der Menschenrechte gefordert war." Und auch auf der EU-Ebene

## Ausgangspunkt

Berliner Forschungsdaten zu jüdischen Gewerbebetrieben, Transformation
von Access-DB in Online-DB liegen detailliert vor

Für die technische Implementierung des offenen
Forschungsdatenmanagements braucht es geeignete Infrastruktursoftware
bzw. -dienste, die sich allerdings im wissenschaftlichen Kontext derzeit
noch im Aufbau befinden, wie in Kapitel 2 gezeigt worden ist.
Festzuhalten ist also, dass es eine standardisierte Nutzung von
Forschungsdatenemanagement in der historischen Forschung noch nicht
gibt. Diese offene Situation wird in dieser Arbeit vor allem dazu
genutzt, explorative Wege im Forschungsdatenmanagement zu bestreiten, um
Chancen und Grenzen für die historische Forschung auszuloten.

## Fragestellung und Zielsetzung

Was kann Open Science für die geschichtswissenschaftliche Forschung
bringen. Zeigen, was hinsichtlich FDM und Open Science heute möglich
ist.

Implementierbarkeit von offenem FDM exemplarisch untersuchen, indem
prototypische Lösung implementiert wird und Möglichkeiten sowie Grenzen
dieser Implementierung herausgearbeitet werden.

FDM offen bezüglich: - technisch offen ist, das heißt das offene
Technologien verwendete Damit läuft die Konzeption auf eine
prototypische Lösung von offenem FDM hinaus, die übertragbar auch auf
andere zeitgeschichtliche Forschungsfelder ist. Versuch unternommen
werden Open Science auf Forschungsdatenmanagement anzuwenden. über den
gesamten Research Data Lifecycle hinweg, die Forschungsdaten offen sind.
Am beispiel des Forschungsfeld untersuchen, welchen Mehrgewinn das
insbesondere für die historische Forschung bringen kann.

hier Fokus klar machen, der auf Lokalstudien liegt, die systematisch
Forschungsdaten gesammelt haben, weil 1. sie die meisten Daten gesammelt
haben und 2. zum Zweck gesammelt, Erkenntnisprofit zu erzielen

## Methodisches Vorgehen

hier erwähnen, dass Open Science Framework verwendet wurde --\> dort
sind auch alle Materialien enthalten (public)

Strukturiert an einen idealtypischen Forschungsprozess. Nicht alle
möglichen Anwendungsfälle abgedeckt werden. Aber Abdeckung gesamten
Forschungsdatenlebenszyklus sicher stellen

Mit den Open Science-Grundsätzen sowie den Konzepte Open und FAIR Data
steht das Gerüst von offenem Forschungsdatenmanagement vor allem
hinsichtlich der Qualitätssicherung weitgehend fest.

prototypische Lösung --\> an idealtypischen Forschungsdatenlebenszyklus
entlang entwickelt und orientiert sich am empirischen Forschungsprozess

Beim Forschungsdatenmanagement geht es im Kern darum,
phasenübergreifende Workflows nach gängigen Standards oder Best
Practises zu entwickeln, die den wissenschaftlichen Umgang mit den
Forschungsdaten in jeder Phase des Forschungsprozesses sicher stellen
sowie darüber hinaus den gesamten Forschungsdatenlebenszyklus abdecken.
Die Open Science-Grundsätze sowie die Strategie der Open Research Data,
die Open Data und FAIR Data Principles verbindet, geben die
Qualitätseigenschaften vor, während mit den in Kapitel 3
herausgearbeiteten Kriterien, Stakeholdern, rechtlichen und ethischen
Rahmenbedingungen die spezifischen funktionalen Anforderungen des
Forschungsfelds feststehen. Damit kann im Anschluss eine erste
Implementierung des offenen FDM am Beispiel der Forschungsdaten zu
jüdischen Gewerbebetrieben prototypisch erfolgen.

Strukturiert an einen idealtypischen Forschungsprozess. Nicht alle
möglichen Anwendungsfälle abgedeckt werden. Aber Abdeckung gesamten
Forschungsdatenlebenszyklus sicher stellen und für jede Phase
herausarbeiten, wan an funktionalen Anforderungen für offenes FDM
gebraucht werden

# Grundlagen

nicht-funktionale Anforderungen, Qualitätseigenschaften von offenem FDM

## Open Science

Was das Schlüsselwort ,,Open" im Kontext von Wissenschaft aussagt,
erschließt sich nicht sofort. Um zu verstehen, was Open Science ist und
warum diese als notwendig für die traditionelle Wissenschaft gewertet
wird, wird die gleichnamige Bewegung in den Blick genommen und deren
Ursprünge überblickt.[^1] Zudem wird der Versuch unternommen, den
Begriff Open Science für eine Anwendung in dieser Arbeit zu definieren.
Anhand von existierenden Konzepten und Infrastruktuen wird abschließend
herausgearbeitet, wo Open Science gegenwärtig steht, woraus sich
wiederum Konsequenzen für die Implementierung eines offenen
Forschungsdatenmanagements ergeben.

### Ursprünge der Open Science-Bewegung

Hinsichtlich der Entstehung der Open Science-Bewegung können zwei
Entwicklungsstränge verfolgt werden. Zum einen lässt sie sich auf ein
konkretes Ereignis innerhalb der Wissenschaft zurückverfolgen, nämlich
auf die sogenannte Replikationskrise. Hier bezieht sich Open Science
explizit auf die Transformation wissenschaftlicher Forschungsmethoden
und -praktiken, um Forschung noch robuster zu machen. Zum anderen ist
Open Science Teil der breiteren sozialen Open-Bewegung, welche von der
Do-it-yourself-Bewegung, der Hacker-Bewegung der 1960/ 70er sowie der
Freie-Software-Bewegung der 1980er Jahre (Vorgänger der Open
Source-Bewegung) stark beeinflusst ist.[^2]

##### Replikationskrise

Ab Mitte der 2010er Jahre erhielten in der Wissenschaft, vordergründig
in der Psychologie sowie in den Lebens- und Naturwissenschaften,
zunehmend Replikationsstudien Aufmerksamkeit. Diese konnten in
sogenannten Replikationsversuchen eine statistisch signifikante Anzahl
publizierter empirischer Forschungsergebnisse entweder falsifizieren
oder nicht replizieren, weil die Daten nicht zur Verfügung standen.[^3]
Das löste die vielfach diskutierte ,,Replikationskrise" in den
betroffenen Fächern aus. Zum einen ging es, hinsichtlich der
Falsifizierungen, nachträglich um Ursachenforschung, die sich auf
Defizite insbesondere bei den Forschungsmethoden und in der
Publikationspraxis wissenschaftlicher Journals fokussierte.[^4] Aber
auch die Replikationsstudien selbst wurden kritisch betrachtet.[^5] Zum
anderen war, hinsichtlich der Nichverfügbarkeit von Daten, eine
wesentliche Eigenschaft von robuster evidenzbasierter Forschung, nämlich
die Nachvollziehbarkeit ihrer Ergebnisse durch Replikation (als
Bestandteil von Qualitätssicherung), nicht mehr gegeben und damit in der
Konsequenz auch ein gesellschaftlicher Bedeutungsverlust von
Wissenschaft bei der Wissensproduktion zu befürchten.

Kurzum ging es um die existenzielle Frage, wie Wissenschaft praktiziert
werden muss, damit wissenschaftliche Forschung, insbesondere die
statistisch empirische, reliabel ist. Als Antwort auf diese Krise hat
sich in den vergangenen Jahren die internationale Open Science-Bewegung
formiert[^6], die in den Anfangsjahren stark auf die Frage nach
Replizierbarkeit von Forschungsstudien fokussiert war.

In Deutschland hat sich zuletzt das *German Reproducibility Network*
(GRN) gegründet, das fachübergreifend gezielt Replikationsstudien und
Open Science Praktiken unterstützen möchte.[^7] Auf internationaler
Ebene ist vor allem das interdisziplinäre *Center for Open Science*
(COS) zu nennen, welches in direkter Reaktion auf die Replikationskrise
2013 in den USA gegründet wurde[^8]. Eine der ersten Aktivitäten des COS
war das mit der University of Viginia gemeinsam großangelegte
*Reproducibility Project*, in dem sich eine Autorengruppe, welche sich
,,Open Science Collaboration" nannte, systematisch mit der
Reproduzierbarkeit von 100 Forschungsstudien in der Psychologie
auseinandersetzte.[^9]. Nach der Bestandsaufnahme, bei der die Rate
nichtreplizierbarer Forschungsstudien wie bei vorausgegangenen
Replikationsstudien signifikant hoch war, widmete sich das COS verstärkt
den Strategien zur Überwindung der Replikationskrise, die im Kern
ebenfalls als eine methodische Krise identifiziert wurde sowie
zweifelhafte Forschungspraktiken aufdeckte.

##### Open-Bewegung

Die Open Science-Bewegung ist Teil der breiten sozialen Open-Bewegung,
welche unter den Begriffen ,,Open", ,,Openness" beziehungsweise ,,Free"
subsumiert, ,,Daten, Entwürfe, Fotos, Musikstücke oder sonstige Inhalte
und Wissen" [^10] aus allen gesellschaftlichen Bereichen zur
Weiterverbreitung sowie Wiederverwendbarkeit schrankenlos zur Verfügung
stellen und dadurch Teilhabe als demokratisches Prinzip in einer
freiheitlichen Gesellschaft stärken will. Außerdem sieht sie in dieser
Kultur der Offenheit Potenzial für neue Innovationen[^11] Diese
Forderungen sind zwar nicht grundsätzlich neu, bekamen aber mit der
Verbreitung des World Wide Web (WWW) ab Mitte der 1990er Jahre[^12]
einen neuen Schub. Dies ist in der Natur des WWW selbst begründet. Denn
dessen Schlüsseleigenschaft ist es - seit seiner Entstehung 1989 -
Informationen system- und plattformunabhängig in einer gemeinsamen
Netzwerkinfrastruktur zu übertragen und auszutauschen.[^13] Damit
eignete es sich auch, die Forderungen der Open-Bewegung technisch zu
implementieren. Folglich werden überwiegend webbasierte Technologien in
der Open-Bewegung eingesetzt, insbesondere die des Web 2.0, welche die
Interaktionsmöglichkeiten im digitalen Raum erheblich erweiterten.[^14]
Eine wichtige Voraussetzung für viele heutige Open (Science) Projekte
war zudem, dass die Technologien hinter dem WWW selbst von Anfang an
offen waren, diese also (kosten)frei für jeden zur Verfügung standen und
von jedem genutzt werden konnten.[^15]

Die Open Science-Bewegung kann in diesem Kontext als Weiterentwicklung
der vor 20 Jahren gegründeten Open Access-Bewegung gesehen werden, in
der sich Wissenschaftler\*innen 2002/2003 zusammengeschlossen haben, um
offenen Zugang zu wissenschaftlichen Forschungsergebnissen zu
fördern.[^16] Daneben umfasst die Open-Bewegung unter anderem Open
Knowledge, Open GLAM, Open Government, Open Design, Open Innovation,
wobei es eine trennscharfe Abgrenzung nicht gibt. So lässt sich Open
Data auch als Querschnittsbereich auffassen, der in andere Bereiche wie
Open Science hineinreicht.[^17]. Eine Vertreterin der ersten Stunde der
Open-Bewegung und die wohl populärste ist die gemeinnützige Wikimedia
Foundation, Inc. (WMF)[^18] mit Sitz in den USA.[^19] Bereits seit 2001
stellt sie digitale Dienste kostenfrei zur Verfügung, mit denen Wissen
offen ausgetauscht und geteilt werden kann. Ihr bekanntestes und
ältestes Projekt ist die freie Enzyklopädie *Wikipedia*[^20]. Die WMF
engagiert sich aber nicht ausschließlich mit der Wikipedia in der
Open-Bewegung, sondern hat inzwischen eine Vielzahl an digitalen
,,Schwesternprojekten"[^21] Daneben stellt sie eine Reihe ihrer
MediaWiki Software-Komponenten in Open Source zur Verfügung.[^22] Eine
weitere und mit der WMF koopierende Organisation in der Open-Bewegung
ist die Open Knowledge Foundation (OKF), die 2005 in London gegründete
wurde[^23] und von der es seit 2011 auch einen deutschen Ableger in
Berlin gibt.[^24]. Die OKF hat unter anderem das Open
Source-Datenmanagementsystem *ckan*[^25] entwickelt, mit dem
Datenkollektionen verwaltet und als Open Data-Portale veröffentlicht
werden können. Der Fokus liegt hierbei auf Politik, öffentlichen
Verwaltungen und (privatwirtschaftlichen) Unternehmen.

Beide hier vorgestellten Initiativen engagieren sich ebenfalls in der
Open Science. An der deutschsprachige OKF hat sich die Arbeitsgruppe
Open Science gegründet, die wiederum von der Wikimedia Deutschland
unterstützt wird.[^26] In der offenen AG kommen unterschiedliche Akteure
aus der Wissenschaft zusammen, die gemeinsam Open Science-Ziele für die
Wissenschaft formulieren.[^27] Die Wikimedia Deutschland gibt die
Blogreihe „Freies Wissen und Wissenschaft" heraus, in der bisher Stärken
und Vorteile von Open Science für die traditionelle Wissenschaft
herausgearbeitet wurden.[^28] Außerdem hat sie zwischen 2016 und 2021
das interdisziplinäre Fellow-Programm *Freies Wissen* durchgeführt, mit
dem Nachwuchswissenschaftler\*innen bei der Integration von Open Science
in das eigene Forschungsprojekt gefördert wurden.[^29] Mit diesem
Zugriff auf die Wissenschaft war der Effekt des Programms auch, dass
Open Science-Multiplikatoren ausgebildet wurden, die die Idee und Praxis
von Open Science in wissenschaftlichen Einrichtungen und Communities
verbreiten und festigen.[^30]

### Definition

Eine allgemeingültige Definition von Open Science, die hier eins zu eins
übernommen werden kann, existiert nicht.[^31] Erschwerend kommt hinzu,
dass ebenfalls die Begriffe Open Research oder Open Scholarship oft,
aber nicht immer synonym verwendet werden.[^32] Hieraus ergibt sich ein
Definitionsproblem für diese Arbeit, das sich aus dem IST-Stand von Open
Science ergibt. Denn entsprechende Verfahren und Strukturen sowohl auf
der technischen als auch auf der organisatorischen Ebene haben sich
schlichtweg noch nicht etabliert. Zwar gibt es - wie der vorherige
Abschnitt gezeigt hat - ein großes Bekenntnis zu Open Science, doch die
feste Verankerung in das bestehende Wissenschaftssystem ist noch nicht
erfolgt. Erst aber in diesem Prozess wird sich Open Science abschließend
konsolidieren.

Daher wird sich in dieser Arbeit in erster Linie an den sogenannten Open
Science-Grundsätze orientiert, die den Handlungsrahmen vorgeben. Auf
diese berufen sich auch die recherchierten Initiativen. Sie können wie
folgt zusammengefasst werden: Während von wissenschaftlicher Seite
insbesondere Transparenz, offene Kommunikation, Kollaboration,
Reproduzierbarkeit und Wiederverwendbarkeit in der Forschung betont
wird, ist es von der Open-Bewegung her vor allem öffentliche
Partizipation, die zentral ist. Open Science wird als moderne
Wissenschaftspraxis gesehen, die traditionelle Wissenschaft dort
transformiert, wo es - wie die Replikationskrise gezeigt hat - notwendig
ist. Das primäre Ziel ist es, durch Open Science Reliabilität von
Wissenschaft zu stärken, Qualität von Forschung im digitalen Zeitalter
zu steigern und Wissenschaft selbst zu demokratisieren.[^33] Eine
wichtige Eigenschaft dieser Grundsätze ist zudem, dass sie generisch,
das heißt über alle wissenschaftlichen Domänen hinweg gültig sind.[^34]
Von daher spricht Open Science nicht allein die lebens- und
naturwissenschaftlichen Bereiche, sondern gleichermaßen auch die
geisteswissenschaftlichen an und deren Grundsätze sind folglich auch auf
die hier betrachteten Forschungsdaten zu jüdischen Gewerbebetrieben
anwendbar.

Es wird abschließend deutlich, dass es *die* Open Science nicht gibt und
in welcher konkreten Form Open Science sich am Ende durchsetzen wird,
muss in dieser Arbeit offen bleiben. Letztendlich hängt diese
Entwicklung stark vom Selbstverständnis der jeweiligen Initiatve,
Einrichtung oder des jeweiligen Wissenschaftsbereichs sowie von anderen
Variablen wie rechtliche oder forschungsethische Rahmenbedingungen ab.
Es ist vorstellbar, dass sich Open Science unter der gemeinsamen Klammer
der Open Science-Grundsätze zukünftig weiter ausdifferenzieren wird und
unterschiedliche Grade nebeneinander existieren werden. Für das offene
Forschungsdatenmanagement bedeutet diese Situation, dass mit Open
Science keine globale Spezifikation vorliegt, die umgesetzt werden muss,
sondern Spielraum bei der Integration von Open Science-Ansätzen besteht.
Umso mehr ist diese vom konkreten Kontext der Forschungsdaten abhängig
und weniger.

### Konzepte und Infrastrukturen

##### Konzepte

In Bezug auf Konzepte von Open Science wird häufig der *Umbrella Term*
herangezogen, um die verschiedenenen Handlungsfelder in der Wissenschaft
zu veranschaulichen and damit die Dimensionen von Open Science zu
verdeutlichen (Abb. 2.1.).

Die Europäische Kommission zum Beispiel definiert für das große
EU-Infrastrukturprojekt ,,European Open Science Cloud" (EOSC)[^35],
welche im Rahmen des Langzeitprogramms *Horizon Europe* aufgebaut
wird[^36], sechs Handlungsfelder - wie aus der Abbildung 2.1.
hervorgeht. Dabei kombinieren die Handlungsfelder Praktiken aus der
traditionellen Wissenschaft mit den Open Science-Grundsätzen und
entwickeln daraus Lösungskonzepte für die wissenschaftliche Forschung
nach Schwerpunkten. Open Data-Konzepte unter dem Dach der Open Science
zum Beispiel konzentrieren sich auf den wissenschaftlichen Umgang mit
den im Forschungsprozess anfallenden digitalen Forschungsdaten, während
sich Open Access-Konzepte mit Fragen des freien Zugangs zu diesen und
sonstigen wissenschaftlichen Materialen beschäftigen. Citizen
Science-Konzepte entwickeln Lösungen, wie unter Beibehaltung
wissenschaftlicher Integrität Partizipation an Wissenschaft gestärkt
werden kann.[^37]

Die Handlungsfelder können voneinander abweichen, wie ein Blick auf die
Abbildung 2.2 zeigt. Die Abweichungen zwischen beiden Abbildungen lassen
den Schluss zu, dass es ganz ähnlich zum Open Science-Grad letztlich vom
konkreten (wissenschaftlichen) Kontext abhängt, welche Handlungsfelder
unter Open Science definiert werden und es hier folglich eine strenge
Vorgabe nicht gibt. Schließlich hängt diese Definition auch davon ab, wo
und ob überhaupt Handlungsbedarf für Open Science gesehen wird. Dass die
Replikationskrise dringenden Handlungsbedarf vorwiegend in den Lebens-
und Naturwissenschaften offenbart hat, heißt nicht, dass dieser
gleichermaßen auch in geisteswissenschaftlichen Fächern gesehen wird, wo
vorwiegend hermeneutische Forschungsmethoden angewandt werden, die sich
fundamental von den statistisch empirschen der Naturwissenschaften
unterscheiden. Das bedeutet im Umkehrschluss, dass Handlungsbedarf
gegebenenfalls erst noch geschaffen werden muss.

##### Infrastrukturen

Anhand der gegenwärtigen fachübergreifenden Anwendungsmöglichkeiten von
Open Science in der eigenen Forschung können grob drei Gruppen von
Infrastrukuren unterschieden werden: 1. zentrale, 2. dezentrale und 3.
nachgenutzte Infrastrukturen:

1.  Begleitend zur Reproduzierbarkeitsstudie des COS wurde das *Open
    Science Framework* (OSF)[^38] entwickelt, das im Hintergrund eine
    zentrale IT- Infrastruktur über eine Plattform bereitstellt, die
    bekannte Open Science Verfahren wie Präregistrierung, Preprints und
    Generierung von Permalinks ermöglicht. Zum Funktionsumfang gehören
    außerdem Projektversionierung sowie ein generisches Repositorium zum
    Speichern und Aggregieren multipler Inhalte unterschiedlicher
    Formaten. Im veröffentlichten, diese Arbeit von Beginn an
    begleitenden, OSF-Projekt ,,Master thesis: Open Science in
    History?"[^39] wurde zum Beispiel die LaTex-Version der
    schriftlichen Arbeit, welche mit Git versioniert und auf GitHub
    zugänglich ist, und die Zotero-Library mit der verwendeten Literatur
    über die Add-ons-Funktionalität sowie die prototypische
    Wikidata-Lösung für offenes Forschungsdatenmanagement als Komponente
    dem Projekt hinzugefügt. Lokal gespeicherte Materialien wie die
    Interviewtranskripte (.pdf), der Fragebogen (.pdf) und die
    Literaturauswertung (.csv) wurden manuell hochgeladen. Dafür stehen
    verschiedenen Server zur Verfügung, darunter auch in Deutschland
    (Frankfurt am Main). Heterogene Dienste und verteilte Ressourcen
    können also im OSF zusammengeführt und dort synchron gehalten
    werden. Damit ist das OSF im Kern ein Projektmanagement-Tool, das
    durch eine homogen gestaltete kollaborative Arbeitsumgebung
    Wissenschaftler\*innen dabei unterstützt, ihr methodisches Vorgehen
    transparent zu machen sowie Workflows zu automatisieren und dadurch
    systematisch Open Science über den gesamten Forschungsprozess zu
    praktizieren.[^40] Dass das OSF steigende Anwenderzahlen
    insbesondere durch akademische Einrichtungen in den USA
    verzeichent,[^41], weist darauf hin, dass es das Potential hat, sich
    zu einem Standard zu entwickeln. Eine mögliche negative Nebenfolge
    dieser Entwicklung ist die Entstehung einer Plattformabhängikeit,
    die anderen gesellschaftlichen Bereichen inzwischen kritisiert wird
    und gegen die sich Widerstand regt.[^42] Freilich steht hinter der
    Plattformökonomie selbst kein Automatismus und es nicht gesagt, dass
    das OSF irgendwann in einer Reihe mit den großen US-amerikanischen
    Digitalkonzernen[^43] stehen wird. Dennoch bleibt festzuhalten, dass
    das COS, als zentraler Akteur hinter dem OSF, mit seiner Plattform
    Gestaltungsmacht in der Frage hat, was Offenheit in der Wissenschaft
    bedeutet. Diese Macht wird mit steigenden Nutzerzahlen wachsen.

2.  Eine etwas andere Entwicklung ist derzeit auf europäischer Ebene zu
    beobachten, wo es ein zentrales und globales Infrastrukturangebot,
    wie das OSF, nicht gibt. Zwar existieren einzelne fachübergreifende
    Projekte wie zum Beispiel das Repositorium *Zenodo* (seit
    2016)[^44], doch ist dieses Infrastrukturangebot funktional auf die
    Archivierung und Zugänglichkeit einzelner digitaler Ressourcen
    zugeschnitten[^45], die wiederum von ,,Communities" kuratiert werden
    können[^46]. Auf die Masterarbeit angewandt, konnte das
    GitHub-Repositorium mit der Versionierung hier nicht - analog zum
    OSF - eingebunden und synchronisiert werden. Zenodo bietet aber die
    Möglichkeit, automatisiert den jeweils aktuellen Repo-Release von
    GitHub als verpackte .zip-Archivdatei hochzuladen und zu
    veröffentlichen.[^47] Der erste Release dieser Arbeit erfolgte aber
    üblicherweise erst mit deren Abgabe und damit in der finalen Phase
    des Enstehungsprozesses. Das ist kein Beleg, aber ein Indiz dafür,
    dass der Schwerpunkt in Zenodo auf *publizierbaren* Ressourcen
    liegt. Diese Vermutung wird auch von einer Stichprobenauswertung zur
    Nutzung von Zenodo in dessen globaler Suche nach ,,Datasets" und
    ,,Publications \| Articles" gestützt.[^48] Auf GitHub bezogen,
    besteht der Hauptunterschied zum OSF darin, dass Zenodo bis auf
    Releases keine Services zur Integration automatisierter Workflows im
    Portfolio hat. Wer mit Zenodo konsequent Open Science
    phasenübergreifend praktizieren will, muss dies über manuell
    iteratives Hochladen von Ressourcen machen. Mit der *European Open
    Science Cloud* (EOSC, seit 2018)[^49] gibt es allerdings aktuell ein
    großes europäisches Infrastrukturprojekt, das zum Ziel hat, Dienste,
    Daten und andere Ressourcen ,,from a wide range of national,
    regional and institutional public research infrastructures across
    Europe"[^50] über das *EOSC Portal*[^51] zentral zu verzeichnen, die
    wiederum von EOSC-Nutzer\*innen in eigenen Projekten verwaltet
    werden können. Der Unterschied zum OSF besteht hauptsächlich darin,
    dass die EOSC kein Infrastrukturangebot ist, auf der individuell
    Open Research praktiziert werden kann. Die EOSC ist selbst nur
    Aggregator bereits existierender Angebote, registriert und vernetzt
    diese miteinander. Sie ist mehr Verzeichnes als Plattform, das
    Sichtbarkeit und Recherchierbarkeit dezentraler Infrastrukturen
    ermöglicht. Die Möglichkeiten der Interkation sind daher auf diese
    Zwecke beschränkt.[^52]

3.  Neben dem Aufbau neuer Infrastrukturen für die Wissenschaft gibt es
    außerdem den Ansatz, bestehende und etablierte Infrastrukturen aus
    der weiter gefassten Open-Bewegung nutzbar zu machen. Hervorzuheben
    sind die Angebote der Wikimedia Foundation, die sich, wie in Kapitel
    2.1.1 beschrieben, mit dem ,,Fellow-Programm Freies Wissen" bereits
    aktiv in die Open Science-Bewegung eingebracht hat. Aktuell laufen
    unterschiedliche Projekte, die das sogenannte Wiki\*versum in der
    wissenschaftlichen Forschungsarbeit nutzen. Aus dem Fellow Programm
    stammt das Wiki\*versum-Projekt *Die Datenlaube*, wo das Massenblatt
    ,,Die Gartenlaube -- Illustrirtes Familienblatt" aus dem 19.
    Jahrhundert mittels Commons, Wikisource und Wikidata kollaborativ
    erschlossen und analysiert wurde.[^53] Ein weiteres, nicht aus dem
    Fellow Programm stammendes Projekt ist die *Bamberger
    Islam-Enzyklopädie*. Bei diesem wurde wissenschaftlich betreut in
    der deutschsprachigen Wikipedia eine Enzyklopädie zum Themenbereich
    Islam aufgebaut und wird in der Fortsetzung kollaborativ
    ergänzt.[^54] Vorteilhaft bei den Wiki\*versum-Lösungen ist die
    Ausnutzung von Synergieeffekten. Die Wissenschaft kann die
    langjährigen Erfahrungen der Wikimedia bei der Implementierung von
    Offenheitskriterien für sich nutzen und deren Tools frei verwenden.
    Umgekehrt können dadurch gleichzeitig fundierte Erkenntnisse aus der
    wissenschaftlichen Forschung effizient in die Öffentlichkeit
    transferiert und das Wissen im Wiki\*versum dadurch für alle
    verbessert werden. Die Projekte zeigen schließlich auch, dass
    vorhandene offene Infrastrukturen für die wissenschaftliche
    Forschung adaptiert und damit nutzbar gemacht werden können. Mit dem
    großen Angebotsspektrum bietet sich zudem für viele Open
    Sciene-Handlungsfelder eine Nutzungsoption. Auch wenn sich die WMF
    im Bereich der Open Science engagiert, bleibt alledings abschließend
    anzumerken, dass deren Angebote nicht auf die Bedürfnisse der
    Wissenschaft zugeschnitten sind, sondern in erster Linie dem
    Grundsatz des freien Wissens für alle folgen. Daher muss für jedes
    Projekt individuell evaluiert werden, inwiefern hier ein oder
    mehrere Wikimedia-Angebote für die eigene Forschungsarbeit in Frage
    kommen.[^55]

Der Blick auf die Infrastrukturebene zeigt, dass die Möglichkeiten von
offener Wissenschaft stark von den Infrastrukturen im Hintergrund
abhängen. Letztendlich manifestiert sich in ihnen der Grad an Open
Science, der am Ende von Forschenden praktiziert werden kann. Daher ist
es nicht nur auf der Konzept-, sondern auch auf der Infrastrukturebene
wichtig, Bedarfe und Standards für die wissenschaftliche Forschung zu
formulieren. Seitens der Anbieter von Open Science-Infrastrukturen
müssen diese Anforderungen aufgenommen und umgesetzt werden. Sie stehen
hier in der Verantwortung, mögliche Machtgefälle und Abhängikeiten
fortlaufend zu reflektieren und zu kommunizieren, das heißt sich die
Frage nach Vertrauenswürdigkeit und Legitimation immer wieder neu zu
stellen. In diesem Zusammenhang wurden bereits die *TRUST Principles*
formuliert, die Transparency, Responsibility, User focus, Sustainability
and Technology als Rahmenbedingungen bei der Infrastrukturentwicklung
vorgeben.[^56]

## Forschungsdatenmanagement

Die historischen Daten zu jüdischen Gewerbebetrieben zeigen
exemplarisch, dass digitale Forschungsdaten längst Bestandteil auch in
der Forschungsarbeit von Historiker\*innen geworden sind. Mit ihnen
rücken in den Geschichtswissenschaften (neue) computergestützte
qualitative wie quantitative Analyse- und Auswertungsverfahren in den
Fokus.[^57]

Wenn aber Forschungsdaten epistemologisch an Bedeutung für die
Wissenschaft im Allgemeinen und für die Geschichtswissenschaften im
Besonderen gewinnen, dann stellen sich unweigerlich Fragen nach dem
wissenschaftlichen Umgang mit ihnen. Daraus wurde sowohl auf
wissenschaftlicher als auch auf politischer Ebene bereits die
Notwendigkeit eines nachhaltigen Forschungsdatenmanagements (FDM)
abgeleitet, welches sich mit der Gestaltung wissenschaftlicher
Standards, Workflows und Best Practices zur Handhabung von digitalen
Forschungsdaten im Forschungsprozess und darüber hinaus auf
methodischer, konzeptioneller, organisatorischer und technischer Ebene
beschäftigt.[^58] FDM ist dabei kein Selbstzweck, sondern will
phasenübergreifende Qualität von Forschung auch im digitalen Zeitalter
weiterhin sicher stellen. Ziel von FDM ist es zudem, Datentransfer und
Datennutzung zu fördern. Damit rekurriert es direkt auf Open
Science-Grundsätze der Transparenz, Kollaboration und
Wiederverwendbarkeit. Auch wenn Forschungsdatenmanagement den
,,Openess"-Gedanken nicht im Namen trägt, so sind die Anknüpfungspunkte
an Open Science offentsichtlich, die sich auch in den *FAIR Principles*
manifestieren, die in Kapitel 2.2.2 näher erläutert sind. Von daher ist
es naheliegend Forschungsdatenmanagement und Open Science
zusammenzudenken, was im wissenschaftlichen Diskurs und in der Praxis
bereits passiert.[^59]

Klar ist, dass diese Aufgabe allein auf individueller Ebene nicht
bewältigt werden kann, sondern dafür entsprechende Infrastrukturen und
Dienste bereitgestellt werden müssen. Aktuell gibt es nationale
Anstrengungen wie die ,,Nationale Forschungsdateninfrastruktur (NFDI)"
am Bundesministerium für Bildung und Forschung (BMBF), die in dieser
offenen Situation die Entwicklung von Lösungsstrategien massiv fördern
und dadurch vorantreiben wollen.[^60] Diese deutsche Initiative geht
zurück auf die Bund-Länder-Vereinbarung zu Aufbau und Förderung einer
Nationalen Forschungsdateninfrastruktur (NFDI) vom 26. November 2018, in
der ein Förderzeitraum von 2019 bis 2028 und eine jährlich Fördersumme
von 90 Millionen Euro für jährlich 30 Forschungsverbünde (sogenannte
Konsortien) vorgesehen sind.[^61] Mit der Durchführung wurde die
Deutsche Forschungsgemeinschaft (DFG) beauftragt.[^62] Zur
organisatorischen Koordination auf der wissenschaftlichen Ebene hat sich
2020 der Verein Nationale Forschungsdateninfrastruktur (NFDI) e.V.
gegründet.[^63] Aus der aktuell veröffentlichten statistischen Übersicht
der DFG geht hervor, dass in der dritten Antragsrunde, die zum Zeitpunkt
des Verfassens dieser Arbeit noch lief, auch geschichtswissenschaftlich
arbeitende Fachdisziplinen mit dem Titel ,,NFDI4Memory - Konsortium für
historisch arbeitende Geisteswissenschaften" vertreten sind.[^64] Zudem
ist seit 2019 die Website <https://4memory.de/> online, auf der zum
Vorhaben und über aktuelle Aktivitäten informiert wird. Auch der
*Verband der Historiker und Historikerinnen in Deutschland* (VHD)
engagiert sich in NFDI4Memory.[^65], das - sollte es positiv beschieden
werden - im Januar 2023 an den Start gehen könnte.[^66]

Festzuhalten bleibt abschließend, dass Handlungsbedarf für
Forschungsdatenmanagement mehrheitlich auf allen Eben erkannt und die
Weichen zur Umsetzung von FDM gestellt wurden. Deutlich geworden ist
jedoch auch, dass sich die notwendigen Infrastrukturen dafür gegenwärtig
noch im Aufbau befinden.

### Forschungsdaten und Forschungsdatenlebenszyklus

Gegenstand von Forschungsdatenmanagement sind Forschungsdaten. Generell
sind damit digitale Ressourcen gemeint, die im Zuge wissenschaftlicher
Forschungsarbeit erzeugt werden. Aber nicht alle Daten aus dem
Forschungsprozess sind Forschungsdaten. Als Abgrenzungskriterium gilt,
dass Forschungsdaten Grundlage von Forschungsergebnissen bilden, also
einen epistemologischen Wert für die wissenschaftliche Forschung haben.
Welche Daten genau darunter fallen, ist in jedem Forschungsvorhaben
indiviuell zu definieren.[^67] Im Zusammenhang mit dieser Arbeit sind
zum Beispiel die Audiodateien der Experteninterviews, die zugehörigen
Transkripte und das Codesystem eindeutig als Forschungsdaten zu
klassifizieren, wohingegen die E-Mail-Nachrichten mit den
Terminabsprachen für die Interviews nicht darunter gezählt werden
würden, da sie für die Erkenntnisgenerierung nicht relevant waren. Das
bedeutet aber nicht, dass E-Mails per se keine Forschungsdaten sein
können. Wie nun schon mehrfach festgestellt, ist diese Einstufung
kontextabhängig.

Forschungsdaten durchlaufen in der Regel einen mehrstufigen Prozess der
Erhebung/ Erfassung, Verarbeitung, Analyse und Visualisierung sowie
Veröffentlichung. Um eine wissenschaftlich korrekte Handhabung in jeder
dieser Phasen zu garantieren, orientiert sich FDM an einen
idealtypischen Forschungsdatenlebenszyklus (Abb. 2.3).

An sich hält dieser Zyklus keine fundamental neue Information für die
Wissenschaft bereit. Vor allem die ersten vier Phasen entsprechen den
vertrauten und etablierten Phasen im Forschungsprozess. Neu hingegen
sind die letzten zwei Phasen der Datenarchivierung und -nachnutzung,
denn hier geht FDM über den traditionellen Forschungsprozess hinaus.
Forschungsdaten sollen über die Laufzeit von Forschungsprojekten hinaus
langfristig verfügbar und nachnutzbar gehalten werden, sodass sie
Ausgangspunkt wieder neuer Forschungsvorhaben sein können. Dieses
,,Zurückspielen" in den Forschungsprozess als iterativer Vorgang stellt
ein zentrales Merkmal von Forschungsdatenmanagement dar.

### FAIR Data Principles und Open Data

Qualitätskriterien zum wissenschaftlichen Umgang mit Forschungsdaten
werden durch die
***F**(indable)**A**(ccessible)**I**(nteroperable)**R**(e-usable)
Principles* klar definiert. Sie wurden im Jahr 2016 erstmals
veröffentlicht[^68] und gehen auf einen Workshop des *Lorentz Workshop
Centers* an der Universität Leiden (Niederlande) aus dem Jahr 2014
zurück.[^69] Die FAIR Data Principles haben sich seitdem zu einem Best
Practice im Umgang mit Forschungsdaten in der Wissenschaft entwickelt.
Zentral bei deren Umsetzung sind die sogenannten Metadaten, welche die
inhaltlichen Daten formal beschreiben (Daten über Daten). Sie sind
insofern essentiell, als dass sie erstens den inhaltlichen Daten den
notwendigen Kontext für eine nachträgliche Quellenkritik geben und sie
zweitens die technische Ausgangslage zur besseren Auffindbarkeit und
Interoperabilität der inhaltlichen Daten bilden.

Wie FAIR Data technisch funktioniert, ist in der Literatur und in
anderen (digitalen) Formaten inzwischen hinreichend besprochen worden
und wird im Rahmen dieser Arbeit daher nicht im Einzelnen wiederholt.
Stattdessen wird auf die bereits existenten Informationsplattformen zu
Forschungsdatenmanagement verwiesen, die auch in dieser Arbeit genutzt
wurden: Im deutschsprachigen Raum ist vor allem das Portal
forschungsdaten.info hervorzuheben, das an der Universität Koblenz
gehosted wird[^70] sowie auf das öffentliche Wiki
forschungsdaten.org[^71]. Auf internationaler Ebene gibt es die *GO Fair
Initiative* sowie das Institut *The Future of Research Communications
and e-Scholarship* (USA), welche jeweils ebenfalls eine ausführliche
Informationsplattformen zur Implementierung von FAIR Data Grundsätzen
bereitstellen.[^72]. Ziel dieser Angebotsformate ist es, praxisnah und
für unterschiedliche Wissenschaftsbereiche FDM und FAIR Data Principles
zu vermitteln.[^73]

Interessanter scheint an dieser Stelle die Frage, in welchem Verhältnis
FAIR Data zu Open Data stehen. Denn wie in Kapitel 2.1.3 gezeigt wurde,
rekurriert Open Science nicht auf FAIR sondern auf Open Data als
Lösungskonzept. Welcher Unterschied besteht also zwischen beiden
Konzepten beziehungsweise warum ist es notwendig, neben Open Data, auch
noch FAIR Data zu formulieren. Und die entscheidenede Frage ist: Sind
die FAIR Data Principles Open Science?

Für einen Abgrenzungsversuch werden zwei Kerneigenschaften von Open Data
herangezogen. Erstens steht bei Open Data Interoperabiltät von Daten im
Zentrum. Damit verbunden ist die Hoffnung, dass durch Austausch und
Teilen konsequent offener Daten, Datensätze gänzlich neu kombiniert,
aggregiert oder verknüpft werden können, woraus wiederum neue offene
Werke jeglicher Art geschaffen werden können.[^74] Neben offener
Lizenzierung ist Voraussetzung dafür, dass die Daten in einem offenen
Format vorliegen, welche nach dem 5-Sterne-Modell des WWW-Erfinders und
Linked-Data-Initiators Tim Berners-Lee klassifiziert sind.[^75] Diese
Modell gibt zum einen eine basale Orientierung darüber, welche Formate
als ,,offen" gelten. Darunter werden vor allem nicht-proprietäre Formate
gezählt. Gleichzeitig bildet es eine Abstufung und repräsentiert damit
die möglichen Open Data-Grade. Im höchsten Grad (= 5 Sterne) können
Daten aus dezentralen Datenquellen im gesamten Web maschinell
identifiziert und verknüpft werden. Dieses Konzept wird als *Linked
(Open) Data* bezeichnet und ermöglicht, nicht mehr nur Daten, sondern
Informationen maschinell zu verarbeiten.[^76] Die Vision dahinter ist,
vom ursprünglichen Web of Documents, über ein Web of Data hin zu einem
Web of Linked Data oder auch Semantic Web zu kommen, mit Wissen digital
abgebildet, gespeichert und abgefragt werden kann.[^77] Die in FAIR Data
separat formulierten Kriterien der Auffindbarkeit, Zugänglichkeit und
Wiederverwendbarkeit von Daten werden bei Open Data vorausgesetzt, um in
der höchsten Stufe Interoperabilität zu erreichen. Allerdings können
Daten, die nicht interoperabel sind, nach dem 5-Sterne-Modell trotzdem
Open Data sein, wenn sie zum Beispiel als PDF- (= 1 Stern) oder
CSV-Files (= 2 Sterne) vorliegen. Diese Variabilität lassen die FAIR
Data Principles an dieser Stelle nicht zu. Hier reicht es streng
genommen nicht aus, wenn (Meta)Daten in Form eines PDF's oder einer CSV
für andere zugänglich aber nicht gleichzeitig für den maschinellen
Datenaustausch geeignet sind. Es ist klar, dass mit dieser Einschränkung
seitens der FAIR Data Principles in erster Linie Standards des
wissenschaftlichen Arbeitens sichergestellt werden sollen. Für diese
Arbeit ist daher zu beachten, dass Forschungsdaten Open Data sein können
ohne dabei gleichzeitig die wissenschaftlichen Kriterien der FAIR Data
Grundsätze zu erfüllen.

Zweitens geht Open Data im Allgemeinen über Open Access hinaus, zielt
also nicht nur darauf ab, freien (lesenden) Zugang zu Daten zu schaffen,
sondern dass diese gleichzeitig universell geteilt, modifiziert und neu
publiziert werden können. Das setzt eine offene Lizenz der Daten voraus,
wie sie in der ,,Open Definition" der Open Knowledge Foundation
eingefordert wird:

> The work must be in the public domain or provided under an open
> license \[\...\]. Any additional terms accompanying the work (such as
> a terms of use, or patents held by the licensor) must not contradict
> the work's public domain status or terms of the license.[^78]

Unter offener Lizenz wird demnach in erster Linie die Veröffentlichung
ohne jegliche Restriktionen oder sonstige Vorgaben verstanden. Dies
entspricht einer Veröffentlichung in Public Domain (CC0 ,,No Rights
Reserved")[^79]. Als ,,offen" gelten auch jene Lizenzen, die als einzige
Einschränkung die Namensnennung haben, aber die freie Nutzung von Daten
erlauben (CC-BY und CC-BY-SA). Alle Lizenzen, welche die Nachnutzung in
irgendeiner Form einschränken, zählen strenggenommen nicht mehr zu Open
Data,wie sie von der OKF definiert wurden.

Einen Standard für offene Lizenzen einzuführen, war und ist das
Hauptanliegen des globalen Netzwerks *Creative Commons* (CC).[^80]. Mit
den *Creative Commons licenses* stellt es allgemeingültige Lizenzen zur
Verfügung, die für eigene Inhalte einfach verwendet werden können.[^81]
Anders als die OKF nehmen sie in der Frage der Offenheit eine Abstufung
vor und kategorisieren die ,,Most Open" als *Free Cultural Works*[^82],
die mit Open Data gleichgesetzt werden können.[^83] Es werden jedoch
auch wesentlich limitiertere Lizenzen zur Verfügung gestellt. Damit
verfolgt die CC vor allem das Ziel, die ,,all rights reserved"-Lizenz,
die jegliche Nachnutzung von vornherein ausschließt, vermeidbar zu
machen und Lizenzgeber zu ermutigen, frei lizensierbare Inhalte
eindeutig zu kommunizieren.[^84]

Open Data ist demnach mit seiner Kultur der offene Lizensierung
radikaler. Damit verfolgt die Open-Bewegung vor allem auch ein
politisches Ziel. Mit steuerlich finanzierten Mitteln entstandene Daten
aus dem öffentlichen Sektor (Wetter-, Verkehrs- oder Geodaten) sollen
als Allgemeingut anerkannt und in der Konsequenz die Grundsatzziele der
Partizipation und Bürgerbeteiligung als Paradigma in der Politik
ausgestaltet werden.[^85] Die Open-Bewegung stellt sehr klar, dass
darunter personenbezogene Daten nicht gezählt werden:

> The key point is that when opening up data, the focus is on
> non-personal data, that is, data which does not contain information
> about specific individuals.[^86]

Hervorzuheben ist also, dass es ausschließlich um rechtlich
unbedenkliche Daten geht, die in der Vergangenheit kaum oder gar nicht
zugänglich waren und deren Öffnung Open Data vorantreiben will. Folgt
man dieser Argumentation weiter, müssten demnach auch alle
Forschungsdaten, die aus öffentlich finanzierten Forschungsprojekten
stammen, in offener Lizenz veröffentlicht werden. Hier wiederum sind es
die FAIR Data Principles, die in der Lizenzfrage Spielraum lassen und
dazu explizit keine Vorgabe machen. Denn aus Sicht der Wissenschaft ist
es möglich, dass forschungsethische Abwägungen oder eine eventuelle
Gefährdung der wissenschaftlichen Integrität die Veröffentlichung von
Forschungsdaten in einer Open Data-Form nicht erlauben.[^87] Daher hat
sich bei den FAIR Data Principles die Regel durchgesetzt, Daten ,,so
eingeschränkt wie nötig und so offen wie möglich" zu halten. Damit
können Forschungsdaten, deren Zugriff auf eine exklusive Gruppe oder
Domäne beschränkt ist, die FAIR Data Grundsätze vollumfänglich erfüllen
und gleichzeitig niemals Open Data sein. Dennoch kann diese Praxis zu
Open Science gezählt werden, da FAIR Data grundsätzlich
wissenschaftliche Forschung öffnet, auch wenn dies nur für eine fest
definierte Gruppe gilt. Aber auch in der Wissenschaft ist ein Trend zu
Open Data erkennbar. Mit den *Pantom Principles*, welche von der Open
Knowledge Foundation in Zusammenarbeit mit Wissenschaftlern aus den USA
und der UK initiiert wurden, soll in der Wissenschaft dafür sensibiliert
werden, Open Data systematisch auch in der wissenschaftlichen Kontext
mitzudenken.[^88]

Dieser Gedanke soll in der in dieser Arbeit aufgegriffen und eine
Strategie der Open Research Data verfolgt werden, die Konzepte FAIR Data
und Open Data kombiniert.

# Kontextualisierung und Parametrisierung

## Einordnung der Forschungsdaten

Inhaltlich sind die hier exemplarisch betrachteten Forschungsdaten zur
Vernichtung der jüdischen Gewerbetätigkeit in den größeren Themenkomplex
der wirtschaftlichen Verfolgung, Verdrängung und Vernichtung der Juden
im Nationalsozialismus eingebettet. Die ersten grundlegenden,
wissenschaftlichen Auseinandersetzungen dazu erfolgten zwar schon früh
in der BRD im Nachkriegsdeutschland.[^89] Allerdings blieben diese
vereinzelt und ohne größere Resonanz. Erst Ende der 1990er Jahren trat
in Deutschland eine längere Forschungswelle zum Thema auf, die eine
Bandbreite an Studien hervorgebracht hat. In deren Folge etablierte sich
ein eigenes Forschungsfeld zur wirtschaftlichen Existenzvernichtung der
Juden im Nationalsozialismus, in dem vor allem lokal- und
regionalgeschichtliche Zugänge dominieren.[^90] Es lieferte innerhalb
der NS-Forschung weitere Erklärungsansätze zur antisemitischen
Verfolgungs- und Vernichtungspolitik, deren Antriebskräfte in der
Vergangenheit unterschiedlich interpretiert wurden.[^91] Hierbei waren
lange nationalsozialistische Akteure, kommunale Verwaltungsinstanzen und
nicht-jüdische Nutznießer sowie deren Strategien, Verhalten und
Handlungsoptionen Schwerpunkt der Forschung. Diese Fokussierung wurde in
zunehmendem Maß als zu einseitig kritisiert, da insbesondere die
jüdischen Betroffenen ganz ausgeblendet oder sie ausschließlich als
passive Opfer gezeigt worden seien. Zudem entwickelte sich langsam ein
wissenschaftlicher Diskurs über die Anwendung historischer
Begrifflichkeiten in der Forschung.[^92] Im Zentrum stand hierbei die
Kritik, dass die meisten Studien die Bandbreite und Komplexität des
Forschungsthemas unter dem diffusen Begriff ,,Arisierung" untersuchten
und diesen dabei unterschiedlich ausdehnten.[^93] Häufig lag der
Schwerpunkt der Untersuchung jedoch auf jüdischen Unternehmern und der
Übernahme deren Eigentums[^94], wodurch die historische Forschung
zuweilen Schlagseite erlitt, da andere Aspekte der wirtschaftlichen
Existenzvernichtung wie zum Beispiel die Verdrängung von Juden aus ihren
Berufen unterbelichtet blieben.[^95] Zusammengefasst war der Einwand,
dass die bisher verwendeten Untersuchungsbegriffe ,,engführend"[^96]
dahingehend seien, das Geschehene nur einseitig zu rekonstruieren, zu
dessen gesamtheitlicher Analyse folglich nicht taugen.[^97]

Ab Mitte der 2000er Jahre lässt sich daraufhin eine Weiterentwicklung
beobachten, die vor allem von größeren universitären Forschungsprojekten
vorangetrieben wurde und die mit der Verschiebung in der
Forschungsperspektive sowie der begrifflichen Ausdifferenzierung einher
ging.[^98] Die neueren Studien unterschieden sich im Wesentlichen
dadurch, dass sie die jüdischen Betroffenen als handelnde Akteure
begriffen und deren *agency* in den Blick nahmen. Außerdem versuchten
sie erstmals mit den Begriffen ,,Arisierung" oder ,,Entjudung" zu
brechen[^99] und Phänomene des Forschungsthema durch eine
wissenschaftliche Terminologie zu benennen. Dabei wurde ein
prozessorientierter Zugang gewählt, der an die Holocaust-Forschung des
US-amerikanischen Historikers Raul Hilberg anknüpfte. Hilberg
analysierte den Massenmord an den Juden wegweisend als einen Prozess,
der über Definition, Kennzeichnung, Enteignung, Konzentration und Mord
mehrstufig verlief.[^100] Als integraler Bestandteil dieses Prozesses
wurde die Vernichtung der wirtschaftlichen Existenz der Juden im
Nationalsozialismus als ein mehrschichtiger Gesamtprozess analysiert,
der sich aus den abgrenzbaren, aber überlagernden und in
Wechselbeziehung stehenden Teilprozessen Verdrängung, Besitztransfer,
Liquidation und Vermögensentzug zusammensetzte. Diese schlossen folglich
die Verdrängung der Juden aus dem Berufsleben, die Vernichtung der
jüdischen Gewerbetätigkeit durch Besitzübernahme oder Liquidation sowie
die Entziehung des Vermögens der Juden ein.[^101]

Mit diesem Forschungsansatz konnte zum einen anhand der drei deutschen
Großstädte Berlin, Frankfurt am Main und Breslau empirisch gezeigt
werden, dass die als jüdisch verfolgten Unternehmen nicht - wie bisher
durch die Schwerpunktsetzung der historischen Forschung suggeriert -
größtenteils in den Besitz nichtjüdischer Erwerber\*innen übergingen,
sondern schlichtweg liquidiert wurden.[^102] Diesbezüglich lag der
Erkenntnisfortschritt in der Freilegung des Teilprozess der Vernichtung
der jüdischen Gewerbetätigkeit als ein ,,großangelegtes
Liquidationsprogramm", das bisher kaum als solches von der historischen
Forschung reflektiert worden war.[^103] Des Weiteren wurde durch den
Wechsel der Forschungsperspektive systematisch herausgearbeitet, dass
sich die jüdischen Betroffenen gegen ihre Entrechtung wehrten und dazu
verschiedenen institutionelle wie individuelle Strategien nutzten.[^104]

An diesen Forschungsstand anknüpfend unternahm zuletzt der Historiker
Benno Nietzel im Jahr 2009 den Versuch, die zahlreichen
Forschungsstudien zur Vernichtung der wirtschaftlichen Existenz der
Juden im Nationalsozialismus zu ordnen, indem er die bisherigen
Forschungsfragen, Untersuchungsgegenstände sowie Forschungsergebnisse
zusammenfasste und strukturierte. Er diagnostizierte dem Forschungsfeld
im Großen und Ganzen weiterhin methodisch-konzeptionelle Probleme
aufgrund undifferenzierter Zugänge[^105] und folglich eine ,,analytische
Hilflosigkeit angesichts der Vielschichtigkeit und Komplexität des
Prozesses \[der wirtschaftlichen Existenzvernichtung der Juden, Anm.
S.E.\]", die Erkenntnisfortschritt im Forschungsfeld hemmen.[^106]

## Kriterien des offenen Forschungsdatenmanagements

Nachdem der historiographische Kontext der Forschungsdaten zu jüdischen
Gewerbebetrieben klar ist, können darauf aufbauend die drei Kriterien
,,anschlussfähig", ,,projektübergreifend" und ,,partizipativ" entwickelt
werden, welche die Anknüpfungspunkte für Open Science-Ansätze darstellen
und das *offene* Forschungsdatenmanagement im Forschungsfeld
spezifizieren.

### Anschlussfähig

Wenn die wirtschaftliche Existenzvernichtung der Juden als ein
abgrenzbares Forschungsfeld definiert ist, dann lässt es sich folglich
für eine differenzierte Unterschung abstecken. Nach Nietzel kann dies in
fünf Teilbereichen erfolgen:[^107]

-   Verdrängung der Juden aus dem Berufsleben (Angestellte, Beamte,
    Selbstständige wie Rechtsanwälte, Ärzte oder Wissenschaftler)

-   Vernichtung der jüdischen Gewerbetätigkeit (Besitztransfer und
    Liquidation)

-   staatliche Enteignung des jüdischen Vermögens (Privatbesitz,
    Firmenvermögen, Immobilienvermögen aus Grundbesitz)

-   Entgrenzung (transnationale Perspektiven)

-   Wiedergutmachung nach 1945 in der BRD

Zwar betonte Nietzel deren überschneidende Beziehungen und Verhältnisse
zueinander, nahm aber in erster Linie eine separierte Betrachtung zum
Zwecke der inhaltlichen Erschließung und zur Herausarbeitung von
Spezifika des Forschungsthemas vor.[^108]

Neben den bereits erläuterten Teilprozessen ordnete Nietzel dem
Forschungsfeld außerdem die historisch untrennbare materielle
Wiedergutmachung nach 1945 in der BRD zu, welche zum einen die
Restitution/ Rückerstattung und zum anderen die Entschädigung meint.
Hiervon ausgenommen ist die Entziehung und die Restitution von
Kulturgütern, die Nietzel dem eigenen Forschungsfeld der
Provenienzforschung zuordnete.[^109] Im Falle der Entgrenzung vor allem
nach Kriegsbeginn geht um die europaweite Perspektive der
wirtschaftlichen Existenzvernichtung. Im Sinne des transnationalen
Forschungsansatzes stehen dabei der Transfer von Erfahrungswissen und
der Export von Verfolgungspraktiken sowie deren Weiterentwicklung in den
besetzten Gebieten im Fokus. Auch Kollaboration und die Rolle von
deutschen Unternehmen bei der Ausplünderung der europäischen Juden
werden in den Blick genommen.[^110]

Nietzels Systematisierungsversuch wurde bisher auffallend wenig von der
historischen Forschung rezipiert.[^111] Lediglich der Historiker
Christoph Kreutzmüller nahm 2016 darauf Bezug und ergänzte den neuesten
Forschungsstand zur Vernichtung der jüdischen Gewerbetätigkeit.[^112]
Auch wenn dieser eine deutliche Professionalisierung darstellt, weil
erstmals unter Einbeziehung aller relevanten Forschungsstudien
konzeptionell mit dem komplexen Forschungsthema auseinandergesetzt
wurde, so bleibt festzuhalten, dass der Begriff ,,Arisierung" als
Untersuchungsbegriff in der historischen Forschung nach wie vor zur
Anwendung kommt.[^113]

Diese Situation ist für das offene Forschungsdatenmanagement insofern
problematisch, als dass sich mit ,,Arisierung" (oder auch ,,Entjudung")
auf der technischen Ebene nicht arbeiten lässt, da eine
widerspruchsfreie Abbildung und Beschreibung des unpräzisen Begriffs in
Form eines Datenmodells nicht möglich ist. Eine kritische Reflexion
reicht, wie es in den meisten Studien gehandhabt wird, hier nicht aus,
da die technische Implementierung an sich zur Differenzierung zwingt.
Als derzeit einzige Möglichkeit bietet sich an dieser Stelle der
Systematisierungsversuch des Historikers Nietzel an, der in dieser
Arbeit methodisch als Taxonomie aufgegriffen wird. Sichtbar wird damit
auch, dass die Forschungsdaten zu den jüdischen Gewerbebetrieben
inhaltlich lediglich einen kleinen Ausschnitt aus dem Gesamtkomplex der
wirtschaftlichen Existenzvernichtung der Juden im NS abbilden, diesen
also nur teilweise repräsentieren. Zudem ist das zugehörige
Forschungsfeld Teil der umfassenden NS-Forschung und knüpft insbesondere
an die Holocaust-Forschung an.

Das Forschungsdatenmanagement ist folglich inhaltlich offen, das heißt
es muss neben der Vernichtung der jüdischen Gewerbetätigkeit
anschlussfähig erstens an alle angrenzenden Untersuchungbereiche im
Forschungsfeld sein und muss zweitens in der Entwicklungsperspektive
auch an benachbarte Forschungsfelder der Verfolgung und Vernichtung im
Nationalsozialismus andocken können.[^114]

### Projektübergreifend

Im Forschungsfeld dominieren lokal- bzw. regionalgeschichtliche
Studien.[^115] Da sich die historische Forschung, wie oben erläutert,
früh auf die Vernichtung der jüdischen Gewerbetätigkeit in Deutschland
konzentriert hat, ist diese Entwicklung wissenschaftlich begründet. Denn
die systematische Vernichtung erfolgte erst ab 1938 mit der Einführung
reichsweiter Gesetze und Regelungen.[^116] Das heißt, dass die jüdische
Gewerbetätigkeit für die nationalsozialistische Wirtschaftspolitik erst
spät auf dem Plan stand.[^117] Anders sah es hingegen in der politischen
Peripherie aus, wo bereits ab 1933 mit den Aprilboykotten jüdische
Gewerbebetriebe gezielt verfolgt wurden und in deren Folge jüdische
Gewerbebetriebe verschwanden. Es waren insbesondere also lokale Akteure
gewesen, die den Vernichtungsprozess vorangetrieben hatten. Auch nach
1938 waren sie es, die die reichsweiten Gesetze und Bestimmungen
umsetzten. Es ist daher wenig überraschend, dass die Wissenschaft
überwiegend den lokalhistorischen Zugang gewählt hat, da in einer
Überblicksdarstellung für Deutschland die Vernichtung der jüdischen
Gewerbetätigkeit unmöglich in der notwendigen Dichte beschrieben und
rekonstruiert werden kann.[^118] In den letzten fünfzehn Jahren sind in
diversen einzelnen lokalen Forschungsprojekten, Publikationen zu Klein-
und Großstädten erschienen und erstmals auch systematisch Daten zu
jüdischen Gewerbebetrieben erfasst worden.

Aus den Interviews sowie aus Nietzels Bericht von 2009 geht jedoch
hervor, dass die einzelnen Lokalstudien gegenseitig kaum Kenntnis
voneinander genommen haben und bisher mehrheitlich nebeneinander stehen
als sich aufeinander zu beziehen.[^119] Wenn man also im Forschungsfeld
von geografisch geschlossenen Studien sprechen kann, dann gilt dies auch
für die zugehörigen Forschungsdaten, welche sich deshalb als Datensilos
charakterisieren lassen. Damit bleiben Aussagen zum Vernichtungsprozess
über lokale/ regionale Grenzen auf der Datenebene bisher noch begrenzt.

Um diese Isolation der Daten aufzubrechen und Datenvernetzung zu
ermöglichen, muss das Forschungsdatenmanagement demnach
projektübergreifend funktionieren.[^120]

### Partizipativ

Neben der wissenschaftlichen Begründung des lokalgeschichtlichen
Zugangs[^121], wird seltener reflektiret, dass viele Forschungsprojekte
dem Bereich der lokalen, insbesondere der städtischen Gedenk- und
Erinnerungskultur entsprungen sind, was zur lokalgeschichtlichen
Dominanz im Forschungsfeld beigetragen hat.[^122] Als Erklärungsansatz
für diese besondere Entwicklung sind die gesellschaftlichen Auf- und
Umbruchszeiten der 1980er Jahre plausibel. In der Tradition der
basisdemokratischen und dezentralen Graswurzelbegewegung (,,Grabe, wo du
stehst")[^123] mit der Etablierung zahlreicher lokaler
Geschichtswerkstätten ab Anfang der 1980er Jahre in der BRD war die
Motivation verbunden, die nationalsozialistische Geschichte des eigenen
Ortes kritisch aufzuarbeiten.[^124] Ab Mitte der 80er Jahre rückten
zunehmend die jüdischen Opfer ins Bewusstsein und es stand ein
angemessenes, innovatives Gedenken sowie die Schaffung von Gedenkorten
im Fokus.[^125] Die Historiker Thomas Lindenberger und Michael Wildt,
beide zum damaligen Zeitpunkt sowohl akademisch tätig als auch in
Geschichtswerkstätten aktiv, haben bereits im Jahr 1989 die Bedeutung
der von den Geschichtswerkstätten praktizierten ,,lokalen Feldforschung"
zur Freilegung von Spuren und Zeugnissen jüdischen Lebens als
mikrohistorischen Zugriff auf die Vergangenheit für die historische
Forschung herausgearbeitet.[^126] Es waren und sind also vor allem auch
diese zivilgesellschaftlichen Akteure, die akribisch Informationen zu
jüdischen Personen, Geschäften und anderen Orten aus unterschiedlichen
Quellen zusammengetragen und veröffentlicht haben.

Das bedeutet für das Forschungsdatenmanagement, dass die Forschungsdaten
zur jüdischen Gewerbetätigkeit und darüber hinaus nicht ausschließlich
im akademischen Umfeld entstanden, sondern gleichermaßen abseits der
traditionellen Wissenschaft aus unterschiedlichsten öffentlichen
Aktivitäten hervorgegangen sind. Es waren die Akteure der
Basisbewegungen, die von einem emanzipatorischen (,,Geschichte von
unten"), einem aufklärerischem (Lernen aus der Geschichte) sowie einem
moralischen (Vergangenheit nicht vergessen) Antrieb geleitet waren und
die etablierte Geschichtsforschung und Erinnerungspolitik durch
Demokratisierung von unten und Pluralismus von Grund auf verändern
wollten.[^127] Lindenberg und Wildt sprechen in Bezug auf die Praxis der
Geschichtswerkstätten schon 1989 von ,,öffentlicher Wissenschaft"[^128]
und zitieren jene mit:

> Wir beanspruchen, unsere Projekte für jede/n - ob ,wissenschaftlich'
> ausgebildet oder nicht - offen zu halten. Das Interesse am Gegenstand,
> an der gemeinsamen Auseinandersetzung mit der Vergangenheit im
> jeweiligen Projekt, sind entscheidend.[^129]

Damit wird sehr deutlich, dass der historischen Forschung im
Forschungsfeld die von der Open Science-Bewegung eingeforderte Offenheit
im Sinne der Partizipation an Wissenschaft keinesfalls fremd ist,
sondern im Gegenteil bereits über Jahrzehnte praktiziert wird. In der
Konsequenz muss auch das Forschungsdatenmanagement partizipativ angelegt
sein.

## Stakeholder

Im vorausgegangenem Kapitel haben sich bereits diverse potentielle
Nutzer\*innen von offenem Forschungsdatenmanagement im Forschungsfeld
herauskristallisiert. Wenn dieses, wie oben zum Ziel erklärt, konsequent
partizipativ sein will, müssen demnach alle Anspruchsgruppen
(Stakeholder) berücksichtigt werden, die ein berechtigtes Interesse an
offenem Forschungsdatenmanagement haben und selbst, wie gezeigt worden
ist, einen Beitrag zur (historischen) Forschung leisten. Nachfolgend
werden deshalb die Beteiligten an offenem Forschungsdatenmanagement noch
einmal aufgeschlüsselt. Freilich sind die Grenzen durchlässig, da sich
die Akteure nicht in feste Kategorien pressen lassen, sondern sich
fluide hin und her bewegen. Dennoch bietet die Einteilung die
Möglichkeit, unterschiedliche Interessen und Ziele aufzuzeigen, die
unberücksichtigt bleiben würden, wenn von vornherein eine Zielgruppe
festgelegt wäre. Dies scheint insbesondere im Zusammenhang mit den sich
im Aufbau befindlichen Infrastrukturen von Bedeutung. Aus der aktuellen
statistischen Übersicht der DFG zu den Antragseingägen für NFDI geht
hervor, dass mit 60 Prozent die Universitäten als antragstellende
Einrichtungen klar in der Mehrheit sind und notwendige Infrastrukturen
demzufolge vorwiegend aus dem Wissenschaftssystem heraus
entstehen.[^130] Es steht die Frage im Raum, inwieweit diese
ausschließlich auf die zugehörigen Akteure ausgerichtet hin entwickelt
werden. Wie die Forschungsdaten zu den jüdischen Gewerbetrieben bereits
gezeigt haben, wäre es unzureichend, außerhalb liegende
Interessengruppen lediglich nachträglich als reine Konsumenten von
Forschungsdaten zu begreifen. Vielmehr sind sie (Mit-)Produzenten von
Forschungsdaten, für die ein gleichberechtigter Zugang zu entsprechenden
Infrastrukturen von Anfang an mitgedacht werden sollte. Im Fall der hier
betrachteten Forschungsdaten liefe man andernfalls Gefahr, essentielle
Gruppen im Forschungsfeld auszuschließen.

### Akademische Wissenschaft

Die größte Interessengruppe stellt die akademische Wissenschaft dar,
denn sie hat systematisch und in Bezug auf die Vernichtung der jüdischen
Gewerbetätigkeit bisher den Großteil der Forschungsdaten produziert.
Dies geschah überwiegend im Rahmen von Dissertations- oder akademischen
Forschungsprojekten.[^131] Zur Gruppe gehören demnach
Wissenschaftler\*innen, die in der Regel aber nicht ausschließlich an
Universitäten angebunden sind und folglich innerhalb des
Wissenschaftssystems agieren. Abgrenzungskriterium ist, dass in dieser
Gruppe kritische Methodenreflexion, Konzeptentwicklungen und analytische
Durchdringung mit dem klaren Ziel des Erkenntnisfortschritts im Zentrum
stehen.

### Gedenk- und Erinnerungskultur

Eine weitere große Interessengruppe stellen die Akteure aus der Gedenk-
und Erinnerunskultur dar. Hier stehen die Daten zu jüdischen
Gewerbebetrieben meist im Kontext von Ausstellungen, Stadtführern,
Gedenkbüchern und anderen öffentlichen, oft städtischen, Aktionen.[^132]
Die Akteure sind vorwiegend zivilgesellschaftliche Initiativen, aber
auch Gedächtniseinrichtungen wie kleinere städtische Museen und Archive,
die nicht primär wissenschaftliche Institutionen sind, werden zu dieser
Gruppe gezählt. Die gemeinsame Klammer bei sämtlichen Aktivitäten ist
die Bewahrung und Vermittlung von vergangener Wirklichkeit sowie ein
sensibles, sinnstiftendes Gedenken und Erinnern.[^133]

### Einzelpersonen

In der dritten Interessengruppe werden all die Akteure zusammengefasst,
die weder institutionell noch an sonstige Infrastrukturen angebunden
sind. Hierbei handelt es sich vorwiegend um Einzelpersonen, deren
intrinsische Interessen und Motive sehr voneinander abweichen können. Es
ist selbst für ein offenes Forschungsdatenmanagement, das sich als
partizipativ versteht, unmöglich, alle Einzelinteressen gleichermaßen zu
berücksichtigen. Hervorzuheben sind allerdings zwei Gruppen. Erstens
sind das die sogenannten Amateur- oder Hobbyforscher sowie
selbstständige Historiker\*innen. Sie haben einerseits ebenfalls
systematisch Daten zu jüdischen Gewerbebetrieben gesammelt und
analysiert.[^134] Andererseits fordern inbesondere diese Akteure den
Zugang zu Forschungsdaten ein.[^135]

Die zweite wichtige Gruppe, die mit Forschungsdatenmanagement nicht
unbedingt assoziiert wird, sind die Nachkommen der Opfer des
Nationalsozialismus. Sie leben heute aufgrund von Flucht und Vertreibung
ihrer Vorfahren aus Deutschland häufig über den gesamten Globus
verstreut. Oft sprechen sie nicht mehr die deutsche Sprache. Wegen
dieser geografischen und sprachlichen Barrieren ist für sie die
Aufarbeitung der eigenen Familiengeschichte vor Ort in Deutschland in
städtischen Archiven besonders schwierig. Deshalb sollten gerade die
Angehörigen der Opfer Zugang zu den Forschungsdaten haben, die Auskunft
geben über das Leben der vertriebenen oder ermordeten Verwandten.[^136]

## Bereitschaft zu Open Science im Forschungsfeld

Damit offenes Forschungsdatenmanagement im Forschungsfeld am Ende
funktioniert, braucht es neben der Erfüllung technischer Voraussetzungen
die grundätzliche Bereitschaft von den diversen Stakeholdern, Open
Science in die eigene Forschungsarbeit zu integrieren. Die für diese
Arbeit geführten Experteninterviews stellen keine repräsentive Umfrage
dazu dar, allein weil sie das Akteursspektrum nicht widerspiegeln, aber
sie vermitteln ein Stimmungsbild. Festzuhalten ist zunächst, dass von
insgesamt acht Interviewanfragen[^137], zwei Personen ein Gespräch mit
der Begründung ablehnten, mit den Themen der Arbeit nicht vertraut zu
sein und daher nicht in der Lage seien, umfassende und fundierte
Auskunft zu erteilen. Ohne diese Selbsteinschätzungen im Einzelnen
beurteilen zu können, deuten sie darauf hin, dass es Berührungsängste
mit der Thematik gibt.

Bei den befragten Personen ist Bereitschaft vor allem in Bezug auf die
universellen Open Science-Grundsätze vorhanden. Schlagwörter wie
Verfügbarkeit, Teilen, Austausch, Vernetzung oder Nachvollziehbarkeit
sind mehrheitlich gefallen. Es wird sogar hervorgehoben, dass sie gerade
im Kontext des Forschungsfelds wichtig seien.[^138] Die konkrete
Realisierung wurde allerdings an Bedingungen geknüpft, die wie folgt
zusammengefasst werden können:

-   Es muss ersichtlich sein, was offenes Forschungsdatenmanagement
    bezwecken will. Offenes Forschungsdatenmanagement ist, jedenfalls in
    der gegenwärtigen Phase, noch kein Selbstzweck, sondern braucht eine
    klare Zielformulierung, die die Benefits deutlich heraushebt.[^139]

-   Offenes Forschungsdatenmanagement im Forschungsfeld kann nicht rein
    wissenschaftlich ausgerichtet sein, sondern braucht eine Kopplung
    zum erinnerungskulturellen Teil des Forschungsfelds.[^140]

-   Um ein offenes Forschungsdatenmanagement steuern und kontrollieren
    zu können, bedarf es gemeinsamer Regeln und Strategieentwicklung
    sowie methodischer Führung.[^141]

-   Es bedarf der Reflektion forschungsethischer Implikationen und der
    Umsetzung entsprechender Richtlinien.[^142]

-   Offenes Forschungsdatenmanagement muss Diskurse im Forschungsfeld
    abbilden können.[^143]

-   Offenes Forschungsdatenmanagement braucht langfristige Betreuung und
    Pflege. Es muss sich stetig an neue Bedarfe im Forschungsfeld
    anpassen lassen können.[^144]

## Rechtliche und ethische Rahmenbedingungen

Die rechtlichen und ethischen Rahmenbedingungen entscheiden maßgeblich
darüber, ob die Forschungsdaten zu jüdischen Gewerbebetrieben in einer
Open Data-Lizenz publiziert werden können. In Bezug auf
nutzungsrechtliche Fragen gingen aus den Interviews keine gesichterten
Antworten hervor.[^145] Daher können pauschal für das Forschungsfeld
keine Aussagen gemacht werden. Eine ansatzweise fundierte Auskunft ist
aber auf der Grundlage der vorliegenden Forschungsdaten zu Berlin
möglich. Hier wurden vier relevante Datenquellen identifiziert. Die
erste Datenquelle, aus der Grunddaten zu Name, Rechtsform, Adresse,
Inhaber und Bilanzen entnommen wurden, stammen aus der
Zentralhandelsregisterbeilage (ZHRB), welche dem Deutschen
Reichsanzeiger und Preußischen Staatsanzeiger täglich beilag.[^146] Bei
diesen Daten handelt es sich um Informationen aus dem Handelsregister,
zu deren Offenlegung Unternehmer nach dem Handelsgesetzbuch (HGB)
verpflichtet waren.[^147] Es handelt sich folglich um amtliche,
öffentliche Informationen, die keiner rechtlichen Einschränkung
unterliegen. Das gilt generell für publiziertes historisches
Material.[^148] Die zweite Datenquelle bildet eine Grauzone. Hierbei
geht es um Daten, die aus externen Online-Datenbanken kommen und wo die
Nachnutzung nicht eindeutig ist. Dies ist zum Beispiel bei dem
,,Gedenkbuch Opfer der Verfolgung der Juden unter der
nationalsozialistischen Gewaltherrschaft in Deutschland 1933 -
1945"[^149] des Bundesarchivs der Fall. Dort ist ein Copyright ,,©
Bundesarchiv" für die gesamte Website zwar vermerkt, aber das Gedenkbuch
erlaubt durch Datenexporte (CSV und PDF) theoretisch, Daten
nachzunutzen. Im Datensatz selbst sowie in den Dateien findet sich
jedoch keinerlei Hinweis darauf, wie die Daten nachgenutzt werden
dürfen.[^150] Hier zeigt sich, dass im Sinne der Creative
Commons-Philosophie eine klare Kommunikation seitens der Datenprovider
notwendig ist.[^151] Die dritte Datenquellen stellen alle in Archiven
vorliegenden, aber nicht veröffentlichten Quellen dar.[^152]. Auch wenn
die darin enthaltenden Daten selbst keinen Schutzfristen mehr
unterliegen, verfügt das Archiv als Besitzer über die Vergabe
Nutzungsrechte. Rechtlich brisant sind die Wiedergutmachungsakten, da
sie sich auf natürliche Personen beziehen und daher besonderen
Schutzfristen unterliegen. Sie werden deshalb hier als vierte
Datenquelle extra gezählt. Das betrifft nicht nur Daten zu Überlebenden,
sondern auch die zu den nichtjüdischen Erwerber\*innen von jüdischem
Eigentum.[^153] Für das offene FDM mit Open Research Data wird eine
offene Lizenz angestrebt. Wichtig wäre also, dass für die Datenquellen,
bei denen die Nachnutzung nicht sicher ist, im Vorfeld eine
entsprechende Veröffentlichung mit den Archiven abgeklärt wird. Das
macht deutlich, dass Open Science im Forschungsfeld auch von der
Bereitschaft anderer Institutionen wie Archiven abhängt. Unabhängig
davon ist generell wichtig für das offene FDM, Nutzungsrechte zum
Beispiel mit einer Creative Commons-Lizenz transparent zu machen.

Aus ethischer Perspektive scheinen die Forschungsdaten auf den ersten
Blick unbedenklich, da es sich vorwiegend um amtliche, öffentliche
Massendaten handelt. Allerdings gibt es im Forschungsfeld sowie in der
Holocaust-Forschung allgemein eine Auseinandersetzung zum Missverhältnis
in der Veröffentlichung von Daten von Holocaust-Opfern gegenüber
deutschen Täter\*innen und Mittäter\*innen. Dass heute Daten über
jüdischen Personen überhaupt in dieser Breite und Tiefe publiziert
werden dürfen, beruht einzig auf der Tatsache, dass diese Menschen vor
80 Jahren ermordet wurden. Zudem waren sie zu Lebzeiten bereits einer
vollständigen Erfassung und Markierung ausgesetzt, die die systematische
bürokratische Verfolgung erst ermöglichte.[^154] Das Recht auf
Anonymität existierte für sie zu Lebzeiten nicht. Im Gegenzug
unterliegen personenbezogene Daten zu deutschen Täter\*innen und
Mittäter\*innen gesetzlichen Schutzfristen über den Tod hinaus, weil
diese Menschen noch leben oder bis vor Kurzem noch gelebt haben.[^155]
Dieses ethische Dilemma kann offenes Forschungsdatenmanagament nicht
auflösen. Festhalten ist jedoch, dass es sich hierbei um eine genuin
deutsche Debatte handelt.[^156] Das internationale Holocaust-Museum *Yad
Vashem* in Israel wiederum sieht in der Online-Veröffentlichung seiner
Daten von über 3 Millionen Personen die Chance, fehlende Informationen
von der Öffentlichkeit zu erhalten, die die Sammlung der Namen der
Ermordeten sukzessive erweitern können[^157]

Letztendlich muss immer abgewogen werden, ob ethische Grenzen dem
öffentliches Interesse an diesen Daten überwiegen. Die Forschungsdaten
zu den jüdischen Gewerbebetrieben werden an dieser Stelle im Großen und
Ganzen als unproblematisch eingestuft, weil es in erster Linie
Verwaltungsdaten sind. Nichtsdestotrotz hat offenes
Forschungsdatenmanagament aufgrund des sensiblen Forschungsthemas
forschungsethische Implikationen, die parallel zur prototypischen
Implementierung im nächsten Kapitel diskutiert werden.

# Prototypische Lösung

## Lösungsansatz

Bei der prototypischen Lösung steht im Zentrum dieser Arbeit die
Wissensdatenbank *Wikidata*[^158] als offener
Forschungsdatenmanagement-Service. Bei Wikidata handelt sich
ursprünglich um ein offenes dankenbankbasiertes Angebot von Wikimedia
für strukturierte Daten im Wiki\*versum, das das Konzept von Linked Open
Data umsetzt. Damit ist es flexibel und sprachenunabhängig einsetzbar,
wodurch es als Modell auch für Forschungsdatenmanagement in der
akademischen Wissenschaft interessant wird. Tatsächlich wird dieser Weg
im Rahmen von NFDI gegenwärtig bestritten. Das *Open Science Lab* am
,,Leibniz-Informationszentrum Technik und Naturwissenschaften und
Universitätsbibliothek"[^159] hat für das Konsortium
*NFDI4Culture*[^160] Wikidata und insbesondere die zugrunde liegende
Software *Wikibase*[^161] auf die Einsetzbarkeit für ein
Forschungsdatenmanagement von Kulturdaten hin evaluiert. Erste
Ergebnisse wurden im März 2022 auf dem TIB-Blog veröffentlicht.[^162]
Parallel führt das NFDI4Culture-Konsortium selbst die Workshop-Reihe
,,Wikibase" durch.[^163]

Auch im Kontext historischer Forschung kommt Wikidata bereits zum
Einsatz. Das Online-Portal ,,Archivführer. Deutsche Kolonialgeschichte"
nutzt Wikidata als zentralen Datenspeicher für strukturierte Daten, die
in Zusammenhang mit dem Thema ,,Deutsche Kolonien und Schutzgebiete"
stehen.[^164] Das Portal führt lediglich die Wikidata-Daten für die
Datenpräsentation zusammen und ermöglicht einen multiperpektivischen
Zugang zu den Daten.[^165] Die Besonderheit ist, dass die
Datenbereitstellung durch Wikidata ermöglicht, über die Projektlaufzeit
hinaus Daten von jeder/jedem erweitern zu lassen sowie diese in gänzlich
anderen Kontexten zu verwenden. Darüber hinaus verfolgt das Projekt das
Ziel, die Daten mit der ,,kolonialen Vergangenheiten anderer
Ländern"[^166] zu verknüpfen und auf diese Weise das Forschungsfeld zum
Deutschen Kolonialismus anschlussfähig an die Forschung zum Europäischen
Kolonialismus zu machen. Die Zusammenarbeit und der kollaborative
Austausch dazu erfolgen ebenfalls global in Wikidata mit dem
,,Wikidata:WikiProject European Colonialism".[^167] Das internationale
Projekt ,,European Holocaust Research Infrastructure" (EHRI), welches im
Rahmen der Open Science-Strategie von der Europäischen Kommission seit
2017 gefördert wird[^168] nutzt Wikidata als zentrales Verzeichnis zur
Erstellung einer Liste von Ghettos aus der Zeit des Holocausts.[^169]
Ziel ist, Daten aus verschiedenen Enzyklopädien, die bisher isoliert
waren, in Wikidata erstmals zusammenzuführen und zu verknüpfen.[^170]

Grundsätzlich ist bei der Implementierung des offenen
Forschungsdatenmanagements mit Wikidata ist zu beachten, dass hier das
Konzept von Linked (Open) Data umgesetzt wird, bei dem es sich, wie in
Kapitel 2.2.2 bereits erläutert wurde, um einen wesentlichen Baustein
des *Semantic Web* handelt. Damit erfolgt offenes FDM in der höchsten
Open Data-Stufe (= 5 Sterne). Vorteil ist, dass auf diese Weise Stärken
dieses Konzepts, welche vor allem in der Verknüpfung und Vernetzung von
Daten liegen, für das Forschungsdatenmanagement ausgenutzt werden
können. Nachteilig ist, dass dieser Ansatz voraussetzungsreicher als
andere Lösungen ist, da zum einen Kenntnisse der allgemeinen
Technologien von Linked Data Web wie RDF (Resource Description
Framework), JSON-LD (JavaScript Object Notation for Linked Data) oder
URI (Uniform Ressource Identifier)[^171] und zum anderen Kenntnisse des
spezifische Metadatenschemas bzw. der Onotologie zugrunde liegenden
Software Wikibase von Wikidata.[^172] für die Umsetzung benötigt werden.

## Erhebung

> \[\...\] Dass dieses methodisches Vorgehen auch transparent und
> nachvollziehbar ist.[^173]

Datenerhebung in der empirischen historischen Forschung geht mit
historischer Quellenanalyse und Quellenkritik einher.[^174] Anders als
in der naturwissenschaftlichen Datenerhebung, wo anhand von
Experimenten, Beobachtungen, Simulationen oder Messungen, Daten in
Echtzeit gewonnen werden und dementsprechend die Erhebungsmethoden an
den Forschungsfragen angepasst werden können, ist die Vorgehensweise bei
den geschichtswissenschaftlichen Disziplinen maßgeblich von der
Überlieferungstruktur und der Quellensituation abhängig.[^175]
Informationen zum Entstehungskontext sowie zur Erhebungsmethode sind
also essentiell, um Forschungsdaten im Sinne einer Datenkritik
kontextualisieren, verstehen und damit letztlich bewerten zu können. Bei
den Forschungsdaten zu jüdischen Gewerbebetrieben sind diese jedoch
nicht hinterlegt und es handelt sich daher bisher um implizites Wissen,
was eine Nachnutzung erschwert oder sogar unmöglich machen kann.
Hinsichtlich der Nachvollziehbarkeit und Transparenz von Forschungsdaten
ist daher Ziel von offenem Forschungsdatenmanagement, das Wissen um den
Entstehungskontext sowie um die geschichtswissenschaftliche
Datenerhebungsmethode explizit zu machen.

### Entstehungskontext

Im Forschungsfeld ist der Großteil der Forschungsdaten zu jüdischen
Gewerbebetrieben in lokalen wissenschaftlichen Forschungsprojekten
erhoben worden. Hinsichtlich des Entstehungskontextes sind also zwei
Informationen relevant: erstens die Forschungsprojekte selbst und
zweitens die projektzugehörigen Personen. In Wikidata werden sie als
eigene *Items* angelegt.[^176] Dadurch erhalten sie einen Identifikator
nach dem Schema *Q* und können eindeutig den zugehörigen Forschungsdaten
zugeordnet werden. In Wikidata erfolgt die Modellierung nach dem Linked
Data-Prinzip auf Basis des Datenmodells der zugrunde liegenden
Wikibase-Software. Im Rahmen dieser Arbeit kann dieses Modell nicht im
Detail

Die Frage, wie die verschiedenen (akademischen) Forschungsaktivitäten
zur semantische Anreicherung von Forschungsdaten konzeptionalisiert und
formalisiert werden können, scheint gegenwärtig noch nicht Gegenstand
des Forschungsdatenmanagements zu sein, denn einen wissenschaftlichen
Standard, nach denen diese beschrieben werden können und sollen, konnte
nicht gefunden werden. Zwar gibt es generische Metadatenstandards wie
*Dublin Core* der *Dublin Core Metadata Initiative*[^177] oder
*DataCite*[^178] des gleichnamigen internationalen Konsortiums. Aber
deren Schemata enthalten kein Konzept ,,Forschungvorhaben" oder
,,Forschungsprojekt". Lediglich das DataCite-Schema enthält dazu
vereinzelt Elemente ,,Funding Reference" , die aber optional sind.

Daher können keine allgemeingültigen Aussagen darüber gemacht werden,
welche Informationen im Rahmen des Enstehungskontexts im Sinne guter
wissenschaftlicher Praxis benötigt werden. Deutlich geworden ist, dass
die Forschungsdaten zu jüdischen Gewerbebetrieben mehrheitlich in
lokalen Forschungsprojekten erhoben wurden. Detaillierte Informationen
sind jedoch unklar.

um Allerdings stellen vereinzelte Einrichtungen zentrale Verzeichnisse,
mit denen sie ihre Forschungsprojekte verzeichnen. standardisiert
erfasst und eindeutig identifizierbar sind, gibt es nicht. Die Deutsche
Forschungsgemeinschaft (DFG) hat immerhin mit dem Informationssystem
,,GEPRIS -- Geförderte Projekte der DFG" (GEPRIS)[^179] in Auszügen ihre
Daten zu allen gegenwärtigen und vergangenen geförderten Projekten
veröffentlicht. Dort ist zum Beispiel auch das Forschungsprojekt
,,Geschichte mittlerer und kleiner jüdischer Unternehmen in Frankfurt am
Main und Breslau 1929/39 bis 1945" verzeichnet mit Informationen über
Antragssteller, Fachliche Zuordnung, Förderzeitraum, Projektkennung,
Projektergebnissen und -beschreibung.

nicht groß diskutieren sondern einfach machen

Zweitens, kann mittels eines eindeutigen Identifikators auf das
Froschungsprojekt referenziert werden. Dieser Ansatz setzt bereits
vorhandene Verzeichnisse voraus, welche . Auf die Forschungsdaten aus
dem Berliner Projekt bezogen, müsste also das zugehörige . Eine
standardisierte und zentrale Projektverzeichnung gibt es dort jedoch
(noch) nicht.[^180] Zudem müsste sichergestellt sein, dass abgelaufene
Projekte archiviert werden.

[^181]

aber sind, lassen sich aus diesen Information extrahieren. Damit stellt
sich abre immer noch die Frage, wie Forschungsprojekte -vorhaben
beschrieben werden könne. Es geht folglich um die formale Erschließung
der Forschungsdaten. Diese Erschließung erfolgt anhand von Metadaten,
die die inhaltserschließenden Daten beschreiben (Daten über Daten). Zu
der Frage also wie Forschungsprojekte oder -vorhaben konzeptionalisert,
formalisiert und spezifisiert werden können, scheint derzeit noch gar
nicht Gegenstand von Forschungsdatenmanagement zu sein. Semantische
Metadaten Schwerpunkt liegt

Das Forschungsdatenmanagement an der Humboldt-Universität zu Berlin
empfiehlt bezüglich des Entstehungskontextes entweder eine schriftliche
Dokumentation in Form einer Readme-Datei oder die Verwendung von
strukturierten Metadaten unter Heranziehung von fachübergreifenden
Metadatenstandards wie zum Beispiel .[^182], die Auffindbarkeit und
Interoperabilität gewährleisten. Da Wikidata vorwiegend strukturierte
Daten hat, können rein textuelle Dokumentationen ausgeschlossenen
werden.

Um , sind hier Metadatenstandards notwendig.[^183] Es braucht einerseits
also deskriptive Metadaten, die die Entstehung der Forschungsdaten
beschreiben, und andererseits bibliografische Metadaten, die
Forschungsdaten den historischen Quellen eindeutig zuordnen.

. Einen Standard zu formalen Beschreibung von Forschungsprojekten oder
-vorhaben gibt es nicht

### Erhebungsmethode

Es braucht zum einen Informationen zum spezifischen Entstehungskontext
der Daten (Datenherkunft).

Aufgenommen werden daher strukturierte Informationen zur Datenherkunft,
da diese essentiell sind bei der eindeutigen Zuordnung der Daten zu den
einzelnen Forschungsprojekten, vor allem wenn das
Forschungsdatenmanagement projektübergreifend ist und außerdem an andere
Forschungsfelder andockt. An Standards orientieren, versuchen zu mappen

Auswertung der historischen Quellen (Datenerhebung) historische
Grundgesamtheit Teilmenge Für die Nachvollziehbarkeit werden zum anderen
Informationen zur Vorgehensweise der Datenerhebung, also zum
methodischen Vorgehen, benötigt. Dafür existieren keine
disziplinübergreifenden Metadatenstandards.[^184] Das heißt, diese
Metadaten sind fachspezifisch. Im naturwissenschaftlichen Bereich und in
der Archäologie gibt es mit der *Research Resource Identification
Initiative* (RRI)[^185] und mit *IANUS*[^186] bereits zentrale Ansätze,
wie Enstehungskontexte und Methodiken anhand von Thesauri oder festen
Vokabularen formal beschrieben werden können.[^187] Allerdings sind sie
nicht übertragbar auf den geschichtswissenschaftlichen Bereich. Offenes
Forschungsdatenmanagement ist hier mit zwei Herausforderungen
konfrontiert. Erstens existiert ein fachspezifischer Standard für die
Geschichtswissenschaften noch nicht. Zweitens ist fraglich, inwiefern
sich die Forschungsdesigns im Forschungsfeld formalisieren lassen. Als
essentiell wurden drei Informationen herausgearbeitet: Datenquellen,
Erhebungsmethode, Bias. Die Datenquellen lassen sich wie folgt
strukturieren:

1.  Datenquelle: Gedruckte Verzeichnisse und Listen sowie
    Karteisammlungen, in denen Gewerbebetriebe dezidiert als jüdisch
    markiert und veröffentlicht wurden[^188] Sie enthalten die
    wesentlichen Grunddaten der Gewerbebetriebe wie Name, Inhaber,
    Branche und Adresse.

2.  Datenquelle: Verschiedene zeitgenössische Aktenbestände, die den
    Vorgang der Verfolgung einzelner Gewerbebetriebe verwaltungsseitig
    dokumentieren.

3.  Datenquelle: Eine wichtige Quelle im Forschungsfeld stellen die
    Wiedergutmachungsakten, insbesondere der Rückerstattungsverfahren,
    nach 1945 dar, welche seit den 90er Jahren der historischen
    Forschung zugänglich sind und oft eine Ersatzüberlieferung für die
    vernichteten und zerstörten zeitgenössischen Quellen darstellen. Der
    Nachteil is

Zu den ersten beiden Datenquellen ist generell festzustellen, dass die
Überlieferung als disparat und lückenhaft bezeichnet wurde, da viele
Bestände teilweise oder überwiegend von den Nationaloszialisten
vernichtet wurden, um Spuren zu verwischen, oder in den letzten
Kriegstagen unwiederbringlich zerstört wurden. Oft sind nur Überreste
und Splitter erhalten, was die Datenerhebung der Studien maßgeblich
beeinflusste. Hierbei lassen sich zwei wesentliche Vorgehensweisen
unterscheiden:

1.  Erhebungsmethode: Datenquelle 1 ist überliefert und bildet den
    Ausgangspunkt, mit der ein Sample von jüdischen Gewerbebetrieben
    zusammengestellt wurde. Dieses Sample mit den Grunddaten wurde
    anschließend mit den Datenquellen 2 und 3 abgeglichen und um Daten
    angereichert, die signifikante Veränderungen des Betriebs zeigten.

2.  Erhebungsmethode: Datenquelle 1 ist nicht überliefert, weshalb
    alternative Wege für eine Stichprobenziehung gefunden werden
    mussten. In Hamburg kamen in erster Linie die Wiedergutmachungsakten
    sowie Bestände der Devisenstelle zum Einsatz.[^189] In Berlin hat
    man ein gänzlich anderen Ansatz verfolgt. Dort wurden ein Sample
    anhand der Zentralhandelsregisterbeilage (ZHRB), welche dem
    Deutschen Reichsanzeiger und Preußischen Staatsanzeiger täglich
    beilag, erstellt und bis 1945 alle Firmenveränderungen aufgenommen.
    Damit wurde die ZHRB zwischen 1930 und 1939 einmal komplett
    digitalisiert. Erst danach wurden nacheinander die Gewerbebetriebe
    mit überlieferten Quellen und anderen Hinweisen abgeglichen und bei
    einer klaren Indizienlage als jüdisch identifiziert.[^190]

Jede Erhebungsmethode geht mit Verzerrungen einher, die sich aufgrund
der Quellensituation vor Ort nicht vermeiden ließen und notgedrungen in
Kauf genommen werden mussten. Umso wichtiger ist, diese Fehlstellen oder
Lücken zu reflektieren und zu dokumentieren:

1.  Bias: Die Datenquelle 1 setzen zeitlich überwiegend erst mit den
    reichsweiten Gesetzen ab 1938 ein. Die frühe Phase der Vernichtung
    der jüdischen Gewerbetätigkeit bleibt damit oft unterrepräsentiert,
    weil schlichtweg Daten dazu fehlen.

2.  Bias: Bei der Verwendung von überwiegend Wiedergutmachungsakten,
    insbesondere aus Rückerstattungsverfahren wie in Hamburg, liegt der
    Schwerpunkt automatisch auf den größeren Unternehmensverkäufen und
    den ehemaligen Eigentümern, die den Nationalsozialismus meist durch
    Emigration überlebt haben. Liquidationen bleiben in diesem Ansatz
    unterrepräsentiert.

3.  Bias: In Berlin wiederum ist der Fokus auf den handelsregisterlich
    eingetragenen Firmen und damit auf mittelständischen
    Gewerbebetriebe, wodurch vor allem kleinere Unternehmen
    unterrepräsentiert bleiben.

Die hier vorgeschlagenen Informationen können den Ausgangspunkt für die
weitere Entwicklung eines spezifischen Metadatenstandard im
Forschungsfeld bilden. Mangels existierender Standards wird für die
prototypische Lösung aber ein pragmatischer Ansatz verfolgt. Im Sinne
einer offenen Methodik (Open Methodology) ist das Hauptanliegen,
methodische Vorgehensweisen überhaupt erst einmal transparent zu machen.
Daher wird auf existierende Open Sciene-Angebote wie das Open Science
Framework oder Zenodo verwiesen, mit denen sich die Informationen zum
Stichprobendesign in rein textueller oder in einer semistrukturierten
dokumentierter Form veröffentlichen lassen und die über DOI oder PID im
Forschungsdatenmanagement angesprochen werden können.

## Aufbereitung

während dieser Phase Kollaboration und Diskursabbildung

solide Datengrundlage für die weitere Auswertung schaffen

inhaltliche Erschließung

Daten aus den verschiedenen Projekten kompatibel machen und Datenmodell
so generisch und damit offenen für anderre Forschungsfelder halten

### Problem Arisierung und *Jüdischer* Gewerbebetrieb

Wikidata:WikiProject Destruction of the Economic Existence of the Jews
Research bildet Grundlage im Kern darum Arisierung und jüdischen
Gewerbebtrieb in Wikidata zu modellieren methodisches Problem hier
herausgehoben

> Test Test

Als Untersuchungsgegenstand für die statistische Auswertung sind
,,Jüdische Gewerbebetriebe" oder ,,Jüdische Unternehmen". Hieraus ergibt
sich eine grundlegende methodische Schwierigkeit im Forschungsfeld. Da
die Zugehörigkeit zu einer Konfession bei einem Gewerbebetrieb oder
Unternehmen generell keine Rolle spielt, ist schon der Begiff
,,jüdischer Gewerbebetrieb" unlogisch und ohne Kontext unbrauchbar. Dies
wird auch in fast allen Studien reflektiert und klar gestellt, dass es
sich um eine antisemitische Zuschreibung und Konstruktion handelte.
Diese Kennzeichnung und Diffamierung bildete den Ausgangspunkt für alle
weiteren Verfolgungspraktiken. Zur einfacheren Handhabung wurde der
Begriff als Quellenbegriff jedoch von allen Studien beibehalten. Hierbei
fallen zwei unterschiedliche Verwendungen auf:

1.  Der Begriff ,,jüdischer Gewerbebetrieb" wird ausschließlich auf die
    jüdischen Besitzer\*innnen bezogen und angewandt. Damit wird jedoch
    das methodische Problem nicht wirklich aufgelöst, sondern verlagert
    sich nur auf den Begriff ,,jüdische Person" oder ,,Jude", bei dem es
    sich im nationalsozialistischen Kontext ebenfalls um eine
    rassistische Zuschreibung handelte und nichts mit dem
    Selbstverständnis der Betroffenen zu tun hatte.[^191] Darüber hinaus
    werden in dieser Verwendung systematisch Gewerbebetriebe
    vernachlässigt, deren Besitzer zum Beispiel nichtjüdisch waren, die
    aber einen hohen Anteil jüdischer Mitarbeiter\*innen aufwiesen und
    daher verfolgt wurden.

2.  Der Begriff ,,jüdischer Gewerbebetrieb" wird mit ,,als jüdisch
    betrachtet/ verfolgt" gleichgesetzt. Mit dieser Verwendung ist die
    jüdische Eigentümerschaft eines Gewerbebetriebs zunächst
    unerheblich, das heißt sie wird nicht vorausgesetzt, sondern es
    werden alle Gewerbebetriebe gezählt, die im nationalsozialistischen
    Kontext diffamiert wurden. Damit wird einerseits der
    Konstruktioncharakter des Begriff hervorgehoben und andererseits dem
    Umstand Rechnung getragen, dass die rassistischen Zuschreibungen
    grundsätzlich jeglicher rationalen Begründung entbehrten und aus
    diesem Grund willkürlich erfolgen konnten. Zudem konnten auch
    unterschiedliche Verfolgungskontexte erfasst werden, die in der
    ersten Verwendung ausgeschlossen blieben.

Auch wenn in allen Studien der selbe Untersuchungsgegenstand genannt
wird, so zeigt sich erst in der konkreten Verwendung, dass dieser
unterschiedlich interpretiert wurde, was jedoch so im Forschungsfeld
noch nicht diskutiert wurde. Maßgeblich liegt das daran, dass der
Begriff an sich nicht widerspruchsfrei ist. Aus forschungsethischer
Perspektive ist es zudem problematisch, dass ein rassistisch
konnotierter Begriff in der wissenschaftlichen Forschung beibehalten
wird. Umso wichtiger ist eine krititsche (Selbst)Reflexion in der
eigenen Forschungsarbeit. Für das Forschungsdatenmanagement wird
versucht, den Zuschreibungs- und Konstruktionscharakter abzubilden und
auf diese Weise den Begriff ,,jüdischer Gewerbebetrieb" zu vermeiden.
Dafür scheint die Verwendung ,,als jüdisch betrachtet" ein geeigneter
Ansatz zu sein.

### Zusammenführung der Quellen

Formale Beschreibung jüdischer Gewerbebetriebe, Relationen, Datensätze
zu diesen erstellen --\> gibt vor, welche Daten erfasst werden

Siehe zur Pipeline Open Refine --\> Wikibase/Wikidata Verananstaltung
<https://nfdi4culture.de/news-events/events/jcdl-workshop-open-refine-to-wikibase-a-new-data-upload-pipeline.html>

##### Datenmodell

, Modellierunghier konkret zum Datenmodell, jeder sein eigenes
Datenmodell, stand mehr oder weniger von Anfang an fest Bei der
Erfassung im Klaren sein, welche Daten ich für Forschungsfrage benötige
und welche kassiert werden können Grunddaten --\> Name, Inhaber,
Branche, Adresse weitere ortsbezogene Daten --\> Geodaten, mehrere
Adressen ermöglichen, wenn es Filialien gab oder bei Umzügen Eventdaten
--\> Veränderungen (Prozess der Vernichtung),
Namens-Rechtsformveränderungen, Besitzerwechsel, Liquidationen

Herausforderung: Bisher keine festes Vokabular zur Beschreibung, jedes
Projekt für sich

Datenmodell entwickeln, dass für alle Projekte funktioniert, also
Kompabilität --\> Top-Level-Ontologie (stellt Austauschbarkeit sicher)
Inhaltserschließende Metadaten EntitySchema items, properties,
qualifiers und references

##### Quellennachweise

bibliografische DatenQuellennachweis für Einzeldaten Nachweis, der einen
Gewerbebtrieb als jüdisch identifiziert hat, aus den Interviews ist auch
hervorgegangen, dass das nicht immer so eindeutig ist und es keine feste
Kriterien gibt. Dies ergibt sich aus bereits erläuterten der
methodischen Schwierigkeit in der Verwendung des Begriffs, die sich auch
mit einem Forschungsdatenmanagement nicht vollständig auflösen lässt, es
scheint aber eben an dieser Stelle umso wichtiger, transparent und
nachvollziehbar für jeden zu machen, warum ein Unternehmen als jüdisch
identifiziert wurde, dann ist man zumindest in der Lage Grenzfälle,
anders als gegenwärtig, wo man den Autoren einfach glauben muss, zu
diskutieren bzw. gemeinsam Kriterien zu entwickeln, falls das überhaupt
möglich ist. Verlinkung zu Digitalisaten um hier gemeinsame
Qualitätskontrolle zu erhalten, die es bisher ja noch gar nicht gibt

Bibliotheken oder Archiven bei der Katalogisierung

Es gibt für die einheitliche Beschreibung bereits Metadatenstandards mit
fachübergreifende Schemata, Im wissenschaftlichen Kontext ist ein Trend
zu ,,DataCite" erkennbar.[^192] Problematisch ist, das beide Standards
zum gegenwärtigen Zeitpunkt nicht als sogenannte Identifiers in Wikidata
integriert sind. Daher muss eine Zwischenlösung gefunden werden. Da in
Wikidata teilweise auf ,,Dublin Core" referenziert wird, wird dieses
Schema als Orientierung für die formale Beschreibung der
projektbezogenen Datenherkunft herangezogen und versucht, auf Entitäten
in Wikidata abzubilden (Tabelle ). DataCite ermöglicht seit 2021 ein
Mapping des DublinCore-Schemas auf eigene Entitäten, wodurch eine
Kompabilität beider Standards gewährleistet ist.[^193]

Es werden also Metadaten zum Forschungsvorhaben sowie bibliografische
Metadaten benötigt.

Für die bibliografischen Daten zur quellenbezogenen Datenherkunft wurde
der bibliothekarische Metadatenstandard FRBR herangezogen:

##### Verlinkung von Gewerbebetrieben

Gemeinsame Normdaten vor allem für Personen- und Ortsnamen notwendig

### Erfassung von jüdischen Gewerbebtrieben

Linked Open Data Interface von Wikidata --\> manuell oder über Open
Refine integrieren Bulk Import Funktion

### Verknüpfung von Sample, Fallbeispielen und Digitalisaten

Verknüpfung strukturierter und unstrukturierter Daten --\> gängige
Praxis im Wiki\*versum Textuelle Daten WikiCommons Möglichkeit
Digitalisate zu hinterlegen und mit Wikidata zu verknüpfen

Daneben sind für das Forschungsdatenmanagement nur die Datenquellen
relevant, in denen nachweislich Forschungsdaten zu jüdischen
Gewerbebetrieben existieren. Das sind erstens vor allem die empirischen
Studien, die Teilbereiche wie die Vernichtung der jüdischen
Gewerbetätigkeit auf der Basis von Stichproben mit einer (deskriptiven)
statistischen Datenanalyse ausgewertet haben. Mit dieser Methode konnten
erstmals allgemeinere Aussagen zum Vernichtungsprozess gewonnen
werden.[^194]. Zum zweiten sind das Veröffentlichungen in analoger oder
digitaler Form, die einen stark dokumentarischen Charakter aufweisen,
der sich vorwiegend in einem deskriptiven Zusammentragen von verteilten
Informationen zu jüdischen Gewerbebetrieben und jüdischen Unternehmern
niedergeschlagen hat.[^195] Hierunter zählen auch jene
Veröffentlichungen, die nicht primär auf Daten zu jüdischen
Gewerbebetrieben fokussiert sind, sondern wo diese eher als anreichernde
Daten verstanden werden können.[^196]

Demzufolge existieren zwei Arten von Forschungsdaten zur Vernichtung der
jüdischen Gewerbetätigkeit:

1.  Es handelt es sich um **quantitative (Massen-)Daten**, die
    strukturiert, entweder als Rohdaten oder in aggregierter Form,
    vorliegen. Sie besitzen eine statistische Aussagekraft.

2.  Es handelt es sich überwiegend um **qualitative Daten**, die in der
    Regel textuell und damit unstrukturiert oder semistruktiert
    vorliegen.

Die textuellen Daten waren für eine wissenschaftlich analytische
Auswertung bislang zu unsystematisch.[^197] Umgekehrt fehlt den
statistischen Daten ihres Umfang wegens oft die entsprechende Datentiefe
und die Einzelschicksale und -geschichten hinter der Statistik sind
nicht sichtbar.[^198] Das macht diese Daten vor allem außerhalb der
wissenschaftlichen Forschung weniger greif- und nutzbar.

## Analyse

explorativ

### Gewerbestruktur

##### Verteilung nach Branchen

##### Verteilung im Stadtraum

braucht Geodaten

##### Geschäftsfrauen

braucht Gender-Angabe

### Vernichtung

Anzahl Besitztransfer und Liquidationen (mit Liquidation ab bis
Gelöscht) im Vergleich, Entwicklung über die Zeit (Zeitreihen-Analyse)

##### 

### Abwehrstrategien

##### Namen- und Rechtsformveränderungen

##### Umzüge

## Archivierung

Möglichkeiten des Datenexports in Wikidata --\> kann in Zenodo
hochgeladen werden, dort mit doi versehen werden

## Veröffentlichung und Nachnutzung

Wikidata in der offenen Lizenz, die es gibt nämlich jede Nutze ohne
Namensnennung Fraglich, inwiefern das zumindest im akademischen Bereich
funktioniert, wo Zitation essentiell für Reputations sind. Für
Regierungsdaten in Deutschland wurde die ,,Datenlizenz Deutschland"
entwickelt die zwei Varianten hat Namensnennung Zero von

<https://www.govdata.de/lizenzen>

Es wäre hier wünschenswert,

##### Teamarbeit

bei der Erfassung und nachträglichen Bearbeitung von Daten (vor allem
Anreicherung von Quellendaten) Sowohl Datenfelder als auch Eingabe

aber auch in Hinblick auch Partizipationsgedanke wurde hier mit
aufgegriffen, der in Kapitel 3.2.3 bereits als Kriterium von offenem FDM
festgelegt wurde, findet sich auch in den Interviews wieder. Alle
grundsätzlich positiv gegenüber Citizen Science eingestellt und sehen es
nicht als Behinderung für die wissenschaftliche Forschung

Strategieentwicklung

##### Diskussionsforum

bringt Kollaboration mit sich, dass Diskurs ermöglicht wird, wo Regeln
vereinbart werden können, verständigt sich auf Vokabular, Normdaten
etc., Weiterentwicklung des Datenmodells

##### Dynamische Anpassungen

Flexible und stetige Dateneditierebene als auch auf Datenmodellebene
Datenmodell steht nicht von Anfang fest, sondern ist dynamisch, hängt
mit den Erhebungsmethoden zusammen

##### Multiperspektivischer Datenzugang

Heusler

##### Datentransfer und Nachnutzung

Recherche in Datensammlungen Daten für Erinnerungsinitiativen zur
Verfügung stellen, verschiedene Visualisierungmöglichkeiten

##### Dauerhafte Kuratierung und -pflege

keine tote Daten produzieren

##### Test- und Evaluationsphasen

der Forschungsdatenumgebung, Mitsprache bei neuen Funktionalitäten,
Involvierung in den Entwicklungsprozess

# Diskussion und Empfehlungen

Wie kann Schnittstelle zwischen Wissenschaft und öffentlichem Wissen/
Öffentlichkeit funktionieren (Fellow-Programm Wikimedia)

hier auf Desiderate aus den Interviews eingehen

##### Benefits

##### Drawbacks

Datenqualität in Wikidata nicht perfekt, aber bei Christoph auch nicht
Datenkonsistenz und -integrität

##### Sideeffects

Datenqualität der Wikidata verbessern und Informationen auf der
Wikipedia nachweislich stärker kontextualisieren als bisher --\> am
Beispiel von
<https://de.wikipedia.org/w/index.php?title=Wodka_Gorbatschow&oldid=222273519>
und Q2587685

Abschließend zur Forschungsfeldbetrachtung ist festzustellen, dass das
dieses inhaltlich mit steigender Anzahl von Lokalstudien in den letzten
20 Jahren enorm voranschritt, aber im Vergleich auf konzeptueller Ebene
die Weiterentwicklung überraschend stagnierte. Wenn mehrheitlich in den
Studien der Begriff ,,Arisierung" (oder ,,Entjudung") kritisch und
problemorientiert hinterfragt wird, in der Konsequenz aber nicht aus der
wissenschaftlichen Arbeit verbannt, sondern entgegen der eigenen
Argumentation als Untersuchungsbegriff beibehalten wird, dann herrscht
ein offensichtlicher Mangel an einer breiteren konzeptionellen und
methodischen Auseinandersetzung im Forschungsfeld. Dafür spricht auch,
dass es bis heute keine einheitliche Definition des Begriffs gibt.[^199]
Einerseits wird darunter speziell der Transfer von jüdischem Eigentum,
insbesondere Firmeneigentum, in nicht-jüdischen Besitz und andererseits
generisch der gesamte Prozess der wirtschaftlichen Existenzvernichtung
der Juden gefasst, wobei dieser unterschiedlich ausgedehnt wurde[^200]
Einen allgemeingültigen wissenschaftlichen Konsens scheint es auf der
methodischen Ebene im Forschungsfeld nicht zu geben. Unklar ist, warum
nach den eindeutig nachvollziehbaren Gegeneinwänden und alternativen
Vorschlägen aus dem Forschungsfeld selbst sich diese methodische
Schwäche bis heute hartnäckig hält.

Die Herausforderung besteht darin, zentrale sowie einheitliche
Infrastrukturen zu schaffen, die von den überwiegend einzelgeförderten
Forschungsprojekten - bei der DFG immerhin mehr als ein Drittel im Jahr
2020 projektbezogener Einzelförderung -- nicht allen Forschungsvorhaben
ein nachhaltiges Forschungsdatenmanagement inhärent ist. Da es
entsprechende Forschungsgebiete in der Vergangenheit schlichtweg noch
nicht gab, war der Umgang mit Forschungsdaten mehr von individuellen
digitalen Kenntnissen und Kompetenzen des oder der Wissenschaftler\*in
abhängig als von allgemeingültigen wissenschaftlichen Kriterien sowie
technischen Standards. Zeitökonomisch betrachtet bedeutet der
wissenschaftliche Umgang mit digitalen Forschungsdaten zudem
Arbeitsaufwand, der zu den routinierten Abläufen hinzukommt. Erst recht,
wenn sich ganz neu mit dieser Thematik auseinandergesetzt werden muss.
Das wirft die berechtigte Frage nach dem Kosten-Nutzen-Verhältnis für
die eigene Forschungsarbeit auf.

Eine Synthese dieser bisher nebeneinander existierenden
Forschungsergebnisse gibt es noch nicht.[^201]

# Fazit und Ausblick

Drei wesentliche Erkenntnisse:

1\. Interviews haben gezeigt, dass Bedarfe adhoc nicht eindeutig
formuliert werden (können), was aber nicht bedeutet, dass diese nicht
vorhanden sind oder das Wissenschaftler diese nicht sehen (es braucht
Übersetzungszeit) sondern unterschiedliche Sprachwelten aufeinander
prallen, Kommunikation essenziell --\> hier braucht es Übersetzer, wie
es mit dieser Masterarbeit unternommen wurde. Erkenntnis, die persönlich
aus dieser Arbeit mitgenommen wird, dass Fragen teilweise viel zu
technisch gestellt waren, würde heute anders gestellt werden, d.h.
Versuch der Übersetzungen, Bedarfsformulierung scheitert nicht an
mangelnden Bedarfen sondern wegen der Kommunikation

2\. Gerade für verteilte projektbasierte Forschungsvorhaben zu einem
Themenkomplex wie der Vernichtung der wirtschaftlichen Existenz sind
zentralere Services notwendig, Projekte institutionell unterschiedlich
angebunden, welche jeweils ihre eigenen Dienste und Infrastrukturen
haben. Für das Forschungsfeld kann es konzeptionell ein immenser
Fortschritt bedeuten, projektübergreifend kollaborativ zu arbeiten.
Reichen Datenrepositorien Fortschritt, wären aber für das Forschungsfeld
nicht ausreichend, braucht auf der Ebene der Datenmodellierung
Infrastrukturen

3\. Forschung ist nicht auf die akademische Wissenschaft allein
beschränkt wie das hier betrachtete Forschungsfeld besondern deutlich
macht, die Frage ist, wie bekommt man die unterschiedlichen Akteure
zusammen bzw. welche Akteure werden einbezogen und welche ausgeschlossen

4\. Wenn entsprechende Infrastrukturen vorhanden und genutzt werden, das
zeigt die prototypische Implementierung, Open Science erweitert
Erkenntnismöglichkeiten, welche im Ergebnis zu einem
Erkenntnisfortschritt führen können. Verschiebt Erkenntnisgrenzen

Denn was Open Science am Ende ist, ist - wenn man der Open-Bewegung
konsequent folgt - keine Frage von einzelnen Akteuren, sondern ein
andauernder demokratischer Aushandlungsprozess vor allem aber nicht
ausschließlich auf der wissenschaftlichen Ebene

Sichtbarkeit der Forschungsarbeit erhöhen, nicht nur auf
Publikationsebene, Projekt und Forschungsdatenebene

# Literatur

# Abbildungen

# Tabellen

# Forschungsdaten

## Transkripte

## Codepoints

## Anforderungskatalog

Beschreibung der Forschungsdaten zur Vernichtung der jüdischen
Gewerbetätigkeit mit den Anforderungen an offenes FDM

-   im Kontext des Forschungsfeld zur Vernichtung der wirtschaftlichen
    Existenz der Juden im Nationalsozialismus

-   Bilden inhaltlich nur einen Ausschnitt aus dem Gesamtkomplex

-   Sie sind räumlich begrenzt.

-   können in strukturierter als statistische Daten oder als
    unstrukturierte textuelle Daten

-   wurden sowohl im akademischen als auch im öffentlichen Umfeld
    generiert

::: tabular
L5cm\|L5cm Forschungsdaten zur Vernichtung der jüdischen
Gewerbetaetigkeit & Anforderung\
& Arisierung in Hamburg\
:::

## Datenmodell mit Beispielerfassung

## SPARQL-Beispielabfragen

[^1]: Genau genommen ist das Konzept von Open Science, also im Kern
    eigene Forschungsmethoden, -praktiken und -ergebnisse transparent
    für andere zu machen, schon älter und findet Anwendung bereits in
    der Renaissance. Für das Thema dieser Arbeit ist eine longue durée
    letztlich wissenschaftlicher Praxis jedoch nicht relevant. Daher
    wird sich auf die aktuelle Bewegung und deren direkte Ursprünge
    begrenzt. Siehe auch Paul A. David: Common Agency Contracting and
    the Emergence of ,,Open Science" Institutions, in: The American
    Economic Review (Hrsg.), 2. Ausgabe, 1998, S. 15--21, URL (stable):
    <http://www.jstor.org/stable/116885.>.

[^2]: Vgl. ayway media (Hrsg.): Das digitale Handbuch, Kapitel C.15 Die
    ,,Open-Bewegung", Vettelschloss 2016, S. 252

[^3]: Als erste Replikationsstudie dieser Art wird jene des
    Medizinwissenschaftlers und Statistiskers John Ioannidis aus dem
    Jahr 2005 gezählt, mit der er erstmals systematisch versuchte,
    veröffentlichte Untersuchungsergebnisse nachträglich zu replizieren/
    reproduzieren. Siehe John P.A. Ioannidis: Why Most Published
    Research Findings Are False, PLoS Med 2(8): e124, 2005,
    doi:10.1371/journal.pmed.0020124. Es folgten eine Reihe weiterer
    Replikationsstudien auch in anderen Fächern wie den
    Sozialwissenschaften. Siehe zum Beispiel Marjan Bakker, Annette van
    Dijk, Jelte M. Wicherts: The Rules of the Game Called Psychological
    Science, in: Perspectives on Psychological Science, 7(6), 2012, S.
    543-554, doi:10.1177/1745691612459060; Thomas Herndon, Michael Ash,
    Robert Pollin: Does high public debt consistently stifle economic
    growth? A critique of Reinhart and Rogoff, in: Cambridge Political
    Economy Society (Hrsg.), Cambridge Journal of Economics, Band 38, 2.
    Ausgabe, Oxford 2014, S. 257-279, URL (stable):
    <https://www.jstor.org/stable/24694929>; Jeremy Freese, David
    Peterson: Replication in Social Science, in: Annual Reviews (Hrsg),
    Annual Review of Sociology, Band 43, San Mateo 2017, S. 147-165,
    doi:10.1146/annurev-soc-060116-053450

[^4]: Diskutiert wurden insbesondere, wie das Institut für Psychologie
    an der Humboldt-Universität zu Berlin konzis berichtete,
    \"p-hacking, selektives Berichten von (abhängigen) Variablen,
    Hypothesizing After the Results are Known (HARKING), nur
    signifikante Ergebnisse berichten, mehr Daten sammeln nachdem die
    bestehenden Daten keine positiven Ergebnisse hervorgebracht haben,
    Publikations Bias\". Methodengruppe Berlin (Autorengruppe): Die
    Replikationskrise und Open Science, Blog Post, Humboldt-Universität
    zu Berlin, Lebenswissenschaftliche Fakultät Institut für
    Psychologie, Lehrstuhl für Psychologische Methodenlehre (Hrsg), URL:
    <http://methods-berlin.com/de/replikationskrise_open_science/>
    (letzter Zugriff am 21.04.2022). Siehe auch Klaus Fiedler, Norbert
    Schwarz: Questionable Research Practices Revisited, in: SAGE
    Publishing (Hrsg.), Social Psychological and Personality Science,
    Band 7, 1. Ausgabe, 2016, S. 45-52, doi:10.1177/1948550615612150;
    Annie Franco, Neil Malhotra, Gabor Simonovits: Publication bias in
    the social sciences. Unlocking the file drawer, in: American
    Association for the Advancement of Science (Hrsg.), Science, Band
    345, Ausgabe 6203, Washington 2014, S. 1502-1505,
    doi:10.1126/science.1255484.

[^5]: Vgl. Deutsche Forschungsgemeinschaft (Hrsg.): Replizierbarkeit von
    Forschungsergebnissen. Eine Stellungnahme der Deutschen
    Forschungsgemeinschaft, Stand: April 2017, URL:
    <https://www.dfg.de/download/pdf/dfg_im_profil/geschaeftsstelle/publikationen/stellungnahmen_papiere/2017/170425_stellungnahme_replizierbarkeit_forschungsergebnisse_de.pdf>
    (letzter Zugriff am 21.04.2022).

[^6]: Entsprechend der Internationalität der Open Science-Bewegung,
    existieren weltweit Open Science Initiativen, von denen allein in
    Deutschland hier nur eine Auswahl wiedergegeben werden kann: Berlin
    School of Public Engagement and Open Science als
    Kollaborationsprojekts des Museums für Naturkunde Berlin, der
    Humboldt-Universität zu Berlin und der Robert-Bosch-Stiftung, URL:
    <https://www.museumfuernaturkunde.berlin/de/future/wissenschaftscampus/berlin-school-public-engagement-and-open-science>;
    Open Science Working Group an der FU Berlin, URL:
    <https://www.fu-berlin.de/sites/open-science>; Open Science Center
    an der LMU München; Initiative für Offene Wissenschaft und
    Innovation des Stifterverbands, URL:
    <https://www.stifterverband.org/open-science-innovation-netzwerke>.

[^7]: Zu dessen Hauptakteuren gehören u.a. Berlin University Alliance,
    das Helmholtz Center (Open Science), das LMU Open Science Center
    (OSC), das Netzwerk der Open Science Initiativen (NOSI), die
    Deutsche Gesellschaft für Psychologie (DGPs), u.a. Siehe Ankündigung
    der Berlin University Alliance: German Reproducibility Network
    gestartet, News vom 01.02.2021, URL:
    <https://www.berlin-university-alliance.de/news/items/2021/210201-grn.html>.
    Homepage des GRN unter URL: <https://reproducibilitynetwork.de/>
    (alle letzter Zugriff am 27.04.2022).

[^8]: URL: <https://www.cos.io/?hsLang=en> (letzter Zugriff am
    21.04.2022).

[^9]: Brian A. Nosek, Johanna Cohoon, Mallory C. Kidwell, Jeffrey R.
    Spies: Estimating the reproducibility of psychological science, in:
    American Association for the Advancement of Science (Hrsg.),
    Science, Band 349, Ausgabe 6251, Washington 2015,
    doi:10.1126/science.aac4716.

[^10]: Wikimedia Deutschland e. V., Open Knowledge Foundation
    Deutschland e. V. (Hrsg.): ABC der Offenheit, Berlin 2019, S. 4f.,
    URL:
    [https://commons.wikimedia.org/wiki/File:ABC_der_Offenheit\_-\_Broschüre\_(2019).pdf](https://commons.wikimedia.org/wiki/File:ABC_der_Offenheit_-_Broschüre_(2019).pdf){.uri}
    (letzter Zugriff am 26.04.2022).

[^11]: Ebd. sowie siehe auch Open Knowledge Foundation (Hrsg.): Why open
    data? URl: <https://okfn.org/opendata/why-open-data/> (letzter
    Zugriff am 26.04.2022).

[^12]: Veröffentlichung des ersten Webbrowsers Netscape in offener
    Lizenz, die Personen auf der ganzen Welt mit PC und
    Internetverbindung ermöglichte, frei im Web ,,zu surfen"

[^13]: Erfunden wurde das WWW vom Physiker und Informatiker Tim
    Berners-Lee, der 1989 am CERN in Genf arbeitete und technischen
    Lösungen suchte, wie unter Forschern schnell und einfach
    kommuniziert werden kann. Die grundlegenden Technologien des WWW
    waren und sind es bis heute: HTML zur Darstellung und Verlinkung von
    Informationen (Hyper Text Markup Language), URI/ URL (Unified
    Ressource Identifier bzw. Locator) zur Lokalisierung einer Ressource
    z.B. eines HTML-Dokuments im Rechnernetz, HTTP (Hyper Text Transfer
    Protocol) zur Übertragung dieser Ressource im Rechnernetz. Zur
    detaillierten Historie, Funktionsweise und weiteren Entwicklung des
    WWW siehe zum Beispiel Tim Berners-Lee, Mark Fischetti: Weaving the
    web. The original design and ultimative destiny of the World Wide
    Web by its inventor, New York 2011. Niels Brügger: Web history, New
    York, Bern 2010. James Gilles, Robert Cailliau: How the Web was
    born. The story of the World Wide Web, Oxford University Press,
    2000.

[^14]: Vgl. Benedikt Fecher, Sönke Friesike: Open Science. One Term,
    Five Schools of Thought, Springer, 2014, S.11,
    doi:10.1007/978-3-319-00026-8_2.

[^15]: Der Begründer Tim Berners-Lee hat sich von Anfang dafür
    eingesetzt das WWW offen zu halten. Er gründete 2012 in London das
    gemeinnützige Open Data Institute (ODI) mit, wodurch er selbst ein
    (einflussreicher) Vertreter der Open-Bewegung ist. URL:
    <https://theodi.org/> (letzter Zugriff am 27.04.2022).

[^16]: Siehe Erklärung der ,,Budapest Open Access Initiative" vom
    14.02.2002, URL:
    <https://www.budapestopenaccessinitiative.org/read/> sowie
    ,,Berliner Erklärung über den offenen Zugang zu wissenschaftlichem
    Wissen" vom 22. Oktober 2003, abgerufen auf der Website der Max
    Planck Gesellschaft, URL:
    <https://openaccess.mpg.de/Berliner-Erklaerung> (alle letzter
    Zugriff am 02.05.2022)

[^17]: Vgl. Birgit Schmidt, Astrid Orth, Gwen Franck, Iryna Kuchma, Petr
    Knoth, José Carvalho: Stepping up Open Science Training for European
    Research, in: Publications (Hrsg), 2 Ausgabe, 2016, S. 3,
    doi:10.3390/publications4020016. Eine konzise Übersicht aller
    Bereiche siehe auch WMK, OKF (2019), ABC der Offenheit, S. 14-54

[^18]: URL: <https://wikimediafoundation.org/de/> (letzter Zugriff am
    22.04.2022)

[^19]: Vgl. den Wikipedia-Eintrag zur Wikimedia Foundation, Seite
    ,,Wikimedia Foundation". In: Wikipedia -- Die freie Enzyklopädie.
    Bearbeitungsstand: 31. März 2022, 20:07 UTC. URL:
    <https://de.wikipedia.org/w/index.php?title=Wikimedia_Foundation&oldid=221669459.>
    (letzter Zugriff am 22.04.2022) In Deutschland vertreten durch den
    Verein Wikimedia Deutschland e. V., vgl. ebd.

[^20]: URL: <https://de.wikipedia.org/wiki/Wikipedia:Hauptseite>
    (letzter Zugriff am 22.04.2022)

[^21]: Zum Beispiel das Wörterbuch Wictionary (2002), URL:
    <https://de.wiktionary.org/>; die Text- und Quellensammlung
    Wikisource (2003), URL: <https://de.wikisource.org/wiki/Hauptseite>;
    die Mediensammlung Wikimedia Commons (2004), URL:
    <https://commons.wikimedia.org/wiki/Hauptseite>; die
    Wissensdatenbank Wikidata (2012), URL:
    <https://www.wikidata.org/wiki/Wikidata:Main_Page> (alle letzter
    Zugriff am 22.04.2022). Eine Auflistung aller Wikimedia-Projekte ist
    auf der Homepage zu finden unter
    <https://www.wikimedia.de/projekte/> (letzter Zugriff am 22.04.2022)

[^22]: Eine Übersicht ist auf der Website zu finden unter URL:
    <https://doc.wikimedia.org/> (letzter Zugriff am 22.04.2022)

[^23]: URL: <https://okfn.org/> (letzter Zugriff am 22.04.2022).

[^24]: URL: <https://okfn.de/> (letzter Zugriff am 22.04.2022).

[^25]: URL: <https://ckan.org/>. GitHub URL:
    <https://github.com/ckan/ckan> (alle letzter Zugriff am 15.05.2022).

[^26]: Siehe Website der AG Open Science, URL:
    <https://ag-openscience.de/netzwerk/> (letzter Zugriff am
    03.05.2022).

[^27]: Vgl. Open Science AG (Hrsg.): Mission Statement. Science - Open
    by default, Verison 1.0, Oktober 2014, URL:
    <https://ag-openscience.de/mission-statement/> (letzter Zugriff am
    03.05.2022).

[^28]: Wikimedia Deutschland (Hrsg.): Freies Wissen und Wissenschaft,
    Blogreihe, Teil 01-07, URL:
    <https://blog.wikimedia.de/2015/04/20/freies-wissen-und-wissenschaft-teil-01-science-2-0-die-digitalisierung-des-forschungsalltags/>
    (letzter Zugriff am 03.05.2022).

[^29]: Sarah Behrens, Christopher Schwarzkopf, Anna-Katharina Gödeke,
    Dr. Dominik Scholl, Nico Schneider (2022): Fellow-Programm Freies
    Wissen 2016 - 2021, Zenodo, doi:10.5281/zenodo.5788379. Siehe auch
    Informations- und Kommunikationskanäle des Fellow Programms auf
    de.wikimedia.org, URL's:
    <https://www.wikimedia.de/projects/fellow-programm-freies-wissen/>,
    <https://de.wikiversity.org/wiki/Wikiversity:Fellow-Programm_Freies_Wissen>,
    <https://blog.wikimedia.de/c/fellow-programm-freies-wissen-de/>
    (alle letzter Zugriff am 03.05.2022)

[^30]: Vgl. Moritz Schubotz, Isabella Peters, Benedikt Fecher, Dominik
    Scholl (2020): Lessons Learned aus dem Fellow-Programm Freies
    Wissen. Open-Access-Tage 2020 (OAT2020), Bielefeld, Germany, Zenodo,
    doi:10.5281/zenodo.4009144

[^31]: Bestätigt wird diese Aussage von dem öffentlichen Wiki
    ,,forschungsdaten.org" der Universität Koblenz, welches seit 2019
    von der Universität betrieben wird (vorher vom Helmholtz-Zentrum
    Potsdam und Deutschem GeoForschungsZentrum GFZ), in dem allein 11
    Definitionen vorgstellt werden, vgl. URL:
    <https://www.forschungsdaten.org/index.php/Open_Science> (letzter
    Zugriff am 30.04.2022).

[^32]: Siehe zum Beispiel Freie Universität Berlin (Hrsg.): FDM Glossar.
    Open Science Open Research Open Scholarship, URL:
    <https://www.fu-berlin.de/sites/forschungsdatenmanagement/glossar/open-science-open-research-open-scholarship.html>,
    Ben Kaden: Drei Gründe für Forschungsdatenpublikationen, Blogartikel
    auf eDissPlus, DFG-Projekt: Elektronische Dissertationen Plus,
    29.09.2016, URL:
    <https://www2.hu-berlin.de/edissplus/2016/09/29/gruende-fuer-forschungsdatenpublikationen/>
    (alle letzter Zugriff am 30.04.2022).

[^33]: Vgl. Ina Friebe: Forschungsqualität durch Open Science
    verbessern, veröffentlicht auf der Website der Berlin University
    Alliance (Hrsg.) am 12.05.2021, URL:
    <https://www.berlin-university-alliance.de/impressions/210512-lecture-series-o3/index.html>
    (letzer Zugriff am 27.04.2022).

[^34]: Vgl. CODATA Coordinated Expert Group, Paul Arthur Berkman, Jan
    Brase, Richard Hartshorn, Simon Hodson, Wim Hugo, Sabina Leonelli,
    Barend Mons, Hana Pergl, Hans Pfeiffenberger: Open Science for a
    Global Transformation: CODATA coordinated submission to the UNESCO
    Open Science Consultation. Zenodo 2020, Version 1, S. 13
    doi:10.5281/zenodo.3935461.

[^35]: Siehe Abschnitt ,,Infrastrukturen".

[^36]: Horizon Europe startete 2020 und läuft noch bis 2027 mit einem
    Förderungsumfang von insgesamt 95,5 Milliarden Euro (Phase 2021-27),
    URL:
    <https://ec.europa.eu/info/research-and-innovation/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe_en>
    (letzter Zugriff am 03.05.2022)

[^37]: Siehe zum Beispiel die Citizen Science-Plattform ,,Bürger
    schaffen Wissen", URL: <https://www.buergerschaffenwissen.de/>
    (letzter Zugriff am 03.05.2022).

[^38]: URL: <https://osf.io/> (letzter Zugriff am 28.04.2022).

[^39]: URL:
    <https://osf.io/sc9yf/?view_only=aa5eb53a48ba4eaab512d049712d704a>,
    hier nur mit lesendem Zugriff auf das Projekt.

[^40]: Vertrauensvorschuss erhält das COS vor allem durch eine
    konsequent transparente Politik wie zum Beispiel der
    Veröffentlichung aller Finanzberichte, URL:
    <https://www.cos.io/about/finances> (letzter Zugriff am 28.04.2022).

[^41]: Zum Beispiel Princeton University, New York University, George
    Washington University, u.a. Siehe <https://osf.io/institutions>
    (letzter Zugriff am 21.04.2022).

[^42]: Gemeint sind hier Social-Media-Plattformen wie Facebook, Twitter,
    Google, Amazon, etc., wo die momentane Plattformökonomie
    Monopolstellung und Machtzentrierung fördert. Siehe zu dieser
    Problematik Justus Haucap: Plattformökonomie. Neue Wettbewerbsregeln
    -- Renaissance der Missbrauchsaufsicht, in: Wirtschaftsdienst 100
    (Hrsg.), 2020, S. 20-29, doi:10.1007/s10273-020-2611-9. Siehe auch
    das jüngste Urteil des Europäischen Gerichtshofs (EuGH) zu
    Verbandsklagen gegen Facebook und dessen Datenschutzpraktiken, vgl.
    Alexander Fanta: EU-Gericht erlaubt Verbandsklagen gegen Facebook,
    netzpolotik.org, 28.04.2022, URL:
    <https://netzpolitik.org/2022/dsgvo-eu-gericht-erlaubt-verbandsklagen-gegen-facebook/>
    (letzter Zugriff am 30.04.2022). Zur Zeit in den Schlagzeilen und
    kontrovers diskutiert ist der Kauf von Twitter durch den
    Tech-Milliardär Elon Musk, vgl. Alexander Fanta: Der EU droht die
    Kraftprobe mit Elon Musks Twitter, netzpolitik.org, 26.04.2022, URL:
    <https://netzpolitik.org/2022/digitale-dienste-gesetz-der-eu-droht-die-kraftprobe-mit-elon-musks-twitter/>
    (letzter Zugriff am 30.04.2022)

[^43]: Positiv hervorzuheben ist zudem, dass das COS alle seine
    Softwareprodukte auf GitHub in Open Source veröffentlicht. Siehe
    URL: <https://github.com/CenterForOpenScience> (letzter Zugriff am
    30.04.2022).

[^44]: URL: <https://zenodo.org/> (letzter Zugriff am 28.04.2022)

[^45]: Siehe Upload-Seite in Zenodo, URL:
    <https://zenodo.org/deposit/new> (letzter Zugriff am 30.04.2022)

[^46]: Zum Beispiel die Community ,,Deutsch-jüdische Geschichte", URL:
    <https://zenodo.org/communities/djg> (letzter Zugriff am 28.04.2022)

[^47]: Siehe URL: <https://zenodo.org/account/settings/github/> (letzter
    Zugriff am 28.04.2022)

[^48]: Dies kann über die Versionsnummer der Ressource identifiziert
    werden. URL der Suchanfrage am 29.04.2022:
    <https://zenodo.org/search?page=1&size=20&type=dataset&type=publication&subtype=article&sort=mostrecent>
    Viele Artikel und Datensätze existieren häufig nur in einer Version
    (v1), was dafür spricht, dass insbesondere die finalen Ergebnisse
    auf Zenodo veröffentlicht werden. Es wäre an dieser Stelle
    interessant gewesen, einmal systematisch und mit computationalen
    Methoden zu evaluieren, wie Zenodo von Wissenschaftler\*innen
    verwendet wird und empirisch gesicherte Aussagen zu treffen, bis zu
    welchem Grad Open Science tatsächlich praktiziert wird. Dies könnte
    zum Beispiel mit der von Zenodo bereitgestellten öffentlichen
    REST-API oder dem OAI-PMH Protokoll realisiert werden, URL:
    <https://developers.zenodo.org/> (letzter Zugriff am 29.04.20222).
    Diese Auswertung konnte im Rahmen der Arbeit nicht mehr geleistet
    werden.

[^49]: URL: <https://eosc-portal.eu/> (letzter Zugriff am 27.04.2022)

[^50]: Europäische Kommission (Hrsg.): European Open Science Cloud, URL:
    <https://digital-strategy.ec.europa.eu/en/policies/open-science-cloud>
    (letzter Zugriff am 28.04.2022).

[^51]: URL: <https://eosc-portal.eu/> (letzter Zugriff am 28.04.2022).

[^52]: Auch hier wurde testweise ein Projekt für die Masterarbeit
    angelegt. Eigene Ressourcen konnten nicht hochgeladen/ eingebunden,
    sondern nur in der Cloud registrierte Open Science Angebote in einer
    privaten Liste gespeichert werden..

[^53]: In Commons digitalisiert
    (<https://commons.wikimedia.org/w/index.php?title=Category:Gartenlaube_(Magazine)&oldid=334192328&uselang=de>),
    mit Wikisource transkribiert
    (<https://de.wikisource.org/w/index.php?title=Die_Gartenlaube&oldid=4048963>)
    und in Wikidata strukturiert erfasst und ausgewertet. Siehe zum
    Projekt auch das öffentliche Repositorium auf GitHub, URL:
    <https://github.com/DieDatenlaube> sowie das Blog, URL:
    <http://diedatenlaube.github.io>. Ein Überblick über das Projekt ist
    auf das Wikimedia-Blog veröffentlicht, siehe Christopher
    Schwarzkopf: Hilfe für die Datenlaube: mit
    \[\[Wikisource+Wikidata\]\] die freie Quellensammlung verbessern,
    Wikimedia Deutschland, 16. Oktober 2019, URL:
    <https://blog.wikimedia.de/2019/10/16/hilfe-fuer-die-datenlaube-mit-wikisourcewikidata-die-freie-quellensammlung-verbessern/>
    (letzter Zugriff am 01.05.2022).

[^54]: Siehe Vorstellung des Projekts auf der Website der Universität
    Bamberg, URL: <https://www.uni-bamberg.de/islamwissenschaft/bie/>
    (letzter Zugriff am 01.05.2022). Beispielartikel in der Wikipedia
    *Fādilīya*, URL:
    [https://de.wikipedia.org/w/index.php?title=Fādilīya&oldid=202323908.](https://de.wikipedia.org/w/index.php?title=Fādilīya&oldid=202323908.){.uri}

[^55]: Dies wird auch in den beiden vorgestellten wissenschaftlichen
    Wiki\*versum-Projekten so reflektiert.

[^56]: Vgl. Dawei Lin, Jonathan Crabtree, Ingrid Dillo, u.a.: The TRUST
    Principles for digital repositories, in: Scientific Data, Ausgabe
    144, 2020, S. 6ff., doi:10.1038/s41597-020-0486-7.

[^57]: Dieser Entwicklung entsprechend haben sich mittlerweile
    Lehrstühle wie der für Digital History an der Humboldt-Universität
    zu Berlin etabliert, die sich auf ,,digitale Methoden, Techniken und
    Standards für die Geschichtswissenschaften" sowie auf ,,den
    digitalen Transformationsprozess im Fach" fokussiert haben, URL:
    <https://www.geschichte.hu-berlin.de/de/bereiche-und-lehrstuehle/digital-history/profil>
    (letzter Zugriff am 03.05.2022).

[^58]: Vgl. Johannes Fournier: Komplexität und Vielfalt gestalten, in:
    Markus Putnings, Heike Neuroth, Janna Neumann (Hrsg.),
    Praxishandbuch Forschungsdatenmanagement, Berlin/Boston 2021, S. 3,
    doi:10.1515/9783110657807.

[^59]: So zum Beispiel im Zusammenhang mit der unter Kapitel 2.1.3.
    vorgestellten EOSC. Vgl hierzu Achim Streit und Jos van Wezel:
    Deutschland in der European Open Science Cloud, in: Praxishandbuch
    Forschungsdatenmanagement, 2021, S. 31-52. Am Helmholtz-Zentrum ist
    FDM direkt an das dortige Helmholtz Open Science Office angebunden.
    Siehe N. L. Weisweiler, R. Bertelmann, J. Bumberger, K. Elger, M.
    Fiedler, P. Fuhrmann, O. Knodel, R. Krahl, Ö. Özkan, F. Rhiem, I.
    Schmahl, S. Servan, A. Upmeier, K. Wedlich-Zachodin (2022):
    Helmholtz Open Science Briefing. Helmholtz Open Science Praxisforum
    Forschungsdatenmanagement: Report, (Helmholtz Open Science
    Briefing), Potsdam : Helmholtz Open Science Office,
    doi:10.48440/os.helmholtz.044. Auch im Open Science-Thesaurus des
    Institut de l'information scientifique et technique in
    Vandoeuvre-lès-Nancy (Frankreich) erscheint FDM,
    doi:10.13143/lotr.9297.

[^60]: Nationale Forschungsdateninfrastruktur, BMBF, URL:
    [https://www.bmbf.de/de/nationale-forschungsdateninfrastruktur-8299.html (letzter Zugriff am 04.05.2022).](https://www.bmbf.de/de/nationale-forschungsdateninfrastruktur-8299.html (letzter Zugriff am 04.05.2022).){.uri}

[^61]: Bund-Länder-Vereinbarung zu Aufbau und Förderung einer Nationalen
    Forschungsdatenin-frastruktur (NFDI) vom 26. November 2018. URL:
    <https://www.gwk-bonn.de/fileadmin/Redaktion/Dokumente/Papers/NFDI.pdf>
    (letzter Zugriff am 04.05.2022).

[^62]: Nationale Forschungsdateninfrastruktur, DFG, URL:
    <https://www.dfg.de/foerderung/programme/nfdi/> (letzter Zugriff am
    04.05.2022).

[^63]: URL: <https://www.nfdi.de/verein/> (letzter Zugriff am
    04.05.2022).

[^64]: DFG (Hrsg.): Nationale Forschungsdateninfrastruktur. Statistische
    Übersichten zum Antragseingang (Dritte Ausschreibungsrunde, November
    2021), Stand: 26.11.2021, Version: 1.0, S. 18, URL:
    <https://www.dfg.de/download/pdf/foerderung/programme/nfdi/statistik_antragseingang_nfdi_3_runde_20211202.pdf>
    (letzter Zugriff am 04.05.2022).

[^65]: Siehe VHD (Hrsg.): Geschichtswissenschaft im digitalen Zeitalter:
    NFDI4Memory, veröffentlicht am 10.09.2019, URL:
    <https://www.historikerverband.de//verband/nfdi.html> (letzter
    Zugriff am 04.05.2022).

[^66]: Vgl. DFG (Hrsg.): Zeitplan für das Entscheidungsverfahren zur
    Förderung von Basisdiensten in der Nationalen
    Forschungsdateninfrastruktur, Stand 7. Dezember 2021, URL:
    <https://www.dfg.de/download/pdf/foerderung/programme/nfdi/zeitplan_nfdi_basisdienste_20211208.pdf>
    (letzter Zugriff am 05.05.2022).

[^67]: Vgl. S. Blumesberger (2021): Forschungsdaten in den
    Geisteswissenschaften. Bereits selbstverständlich oder doch noch
    etwas exotisch?, O-Bib. Das Offene Bibliotheksjournal / Herausgeber
    VDB, 8(4), S. 1--8, doi:10.5282/o-bib/5739.

[^68]: Siehe M. Wilkinson, M. Dumontier, I. Aalbersberg, u.a.: The FAIR
    Guiding Principles for scientific data management and stewardship.
    Sci Data 3, 160018 (2016). https://doi.org/10.1038/sdata.2016.18.

[^69]: Vgl. The Future of Research Communications and e-Scholarship
    (FORCE 11), The FAIR Data Principles, URL:
    <https://force11.org/info/the-fair-data-principles/> (letzter
    Zugriff am 06.05.2022).

[^70]: Bis März 2019 am Helmholtz-Zentrum Potsdam, Deutsches
    GeoForschungsZentrum GFZ, URL: <https://www.forschungsdaten.info/>
    (letzter Zugriff am 05.05.2022).

[^71]: Ebenfalls von der Uni Koblenz betrieben, URL:
    <https://www.forschungsdaten.org/index.php/Hauptseite> (letzter
    Zugriff am 05.05.2022).

[^72]: Go Fair, URL: <https://www.go-fair.org/> und FORCE11, Guiding
    Principles for Findable, Accessible, Interoperable and Re-usable
    Data Publishing version b1.0, URL:
    <https://force11.org/info/guiding-principles-for-findable-accessible-interoperable-and-re-usable-data-publishing-version-b1-0/>(alle
    letzter Zugriff am 05.05.2022).

[^73]: Wie wichtig diese Form der Wissenschaftskommunikation und
    Vermittlung ist, macht auch die aktuelle Ankündigung der DFG
    ,,Aktualisierung des Förderprogramms Informationsinfrastrukturen für
    Forschungsdaten" deutlich, in der ,,umfangreichen Maßnahmen zu
    Aufbau und Weiterentwicklung von Informationsinfrastrukturen für
    Forschungsdaten" geplant sind, Information für die Wissenschaft Nr.
    32 vom 3. Mai 2022, URl:
    <https://www.dfg.de/foerderung/info_wissenschaft/info_wissenschaft_22_32/>
    (letzter Zugriff am 05.05.2022).

[^74]: Vgl. ebd.

[^75]: URL: <https://5stardata.info/en/> (letzter Zugriff am
    06.05.2022).

[^76]: Vgl. Tim Berner-Lee: Linked Data, digitales Paper veröffentlicht
    am 27.07.2006, URL:
    <https://www.w3.org/DesignIssues/LinkedData.html> (letzter Zugriff
    am 06.05.2022). Siehe auch Günther Neher, Bernd Ritschel:
    Semantische Vernetzung von Forschungsdaten, in: Stephan Büttner,
    Hans-Christoph Hobohm, Lars Müller (Hrsg.), Handbuch
    Forschungsdatenmanagement, Bad Honnef 2011, S. 169-190.

[^77]: Siehe Informationsportal des WWW-Konsortium (w3c) zum Semantic
    Web, URL: <https://www.w3.org/standards/semanticweb/> (letzter
    Zugriff am 06.05.2022).

[^78]: Open Knowledge Open Definition Group: Open Definition. DEFINING
    OPEN IN OPEN DATA, OPEN CONTENT AND OPEN KNOWLEDGE, Version 2.1,
    URL: <https://opendefinition.org/od/2.1/en/> (letzter Zugriff am
    06.05.2022).

[^79]: Vgl. Creative Commons, URL:
    <https://creativecommons.org/share-your-work/public-domain/>
    (letzter Zugriff am 18.05.2022).

[^80]: URL: <https://creativecommons.org/> (letzter Zugriff am
    18.05.2022).

[^81]: Diese Arbeit zum Beispiel wurde in einer CC-BY-SA Lizenz auf
    GitHub veröffentlicht, siehe URL:
    <https://github.com/sopheck/offenes-fdm-fuer-historische-fd>
    (letzter Zugriff am 18.05.2022).

[^82]: Definition vom 17.02.2015, Version 1.1, URL (stable):
    <https://freedomdefined.org/index.php?title=Definition&oldid=19268>

[^83]: URL:
    <https://creativecommons.org/share-your-work/public-domain/freeworks>
    (letzter Zugriff am 18.05.2022).

[^84]: Vgl. Creative Commons (2022): Understanding Free Cultural Works,
    URL:
    <https://creativecommons.org/share-your-work/public-domain/freeworks>
    (letzter Zugriff am 18.05.2022).

[^85]: Immerhin hat die aktuelle Regierungskoalition der BRD allgemein
    einen Rechtsanspruch auf Open Data zum Ziel erklärt, dessen
    unkonkrete Umsetzungsziele aber von der Wikimedia Deutschland
    kritisiert werden. Vgl. John Weitzmann, Justus Dreyling:
    Rechtsanspruch auf Open Data. Jetzt muss es endlich losgehen,
    Blogbeitrag auf Wikimedia Deutschland vom 17. März 2022, URL:
    <https://blog.wikimedia.de/> (letzter Zugriff am 06.05.2022).

[^86]: Open Data Handbook der OKF: What is Open Data? Abschnitt What
    Data are You Talking About?, URL:
    <http://opendatahandbook.org/guide/de/what-is-open-data/> (letzter
    Zugriff am 06.05.2022).

[^87]: Hierzu gehören in erster Linie sensible Daten in der
    Gesundheitsforschung. Vgl. FAIR4Health Consortium (Hrsg.): Improving
    Health Research in EU through FAIR Data, D2.3. Guidelines for
    implementing FAIR Open Data policy in health research.pdf, Version
    1, 2019, URL: <https://osf.io/3u7dt/>.

[^88]: Peter Murray-Rust, Cameron Neylon, Rufus Pollock, John Wilbanks:
    Panton Principles, Principles for open data in science,
    veröffentlicht am 19 Februar 2010, URL:
    <https://pantonprinciples.org/> (letzter Zugriff am 06.05.2022). Es
    handelt sich dabei nicht wie bei den FAIR Data Principles um
    handfeste Kriterien, sondern um Empfehlungen.

[^89]: Im Jahr 1966 erschien die Pionierstudie von Helmut Genschel. Erst
    20 Jahre später folgte die nächste grundlegende Studie des
    israelischen Historikers Avraham Barkai, der an Gentschels
    Ergebnisse anknüpfte. Vgl. Benno Nietzel: Die Vernichtung der
    wirtschaftlichen Existenz der deutschen Juden 1933-1945. Ein
    Literatur und Forschungsbericht, in: Friedrich-Ebert-Stiftung (Hg.),
    Archiv für Sozialgeschichte, Band 49, Bonn 2009, S. 561-613.

[^90]: Als wegweisend wird regelmäßig die Lokalstudie zu Arisierung in
    Hamburg des Historikers Frank Bajohr aus dem Jahr 1997/98 gewertet.
    Siehe zum Beispiel Nietzel 2009, S. 561 oder Christiane Fritsche:
    Ausgeplündert, zurückerstattet und entschädigt. Arisierung und
    Wiedergutmachung in Mannheim, 2. Aufl., Ubstadt-Weiher, Heidelberg,
    Neustadt a. d. W., Basel 2013, S. 21. Frank Bajohr: ,,Arisierung" in
    Hamburg. Die Verdrängung der jüdischen Unternehmer 1933-1945, 2.
    Aufl., Hamburg 1998 (zuerst 1997). Auf Ursachen des Forschungsbooms
    kann im Rahmen dieser Arbeit nicht eingegangen werden. Siehe dazu
    auch Christoph Kreutzmüller, Vernichtung der jüdischen
    Gewerbetätigkeit im Nationalsozialismus. Abläufe, Blickwinkel und
    Begrifflichkeiten, Version: 2.0, in: Docupedia-Zeitgeschichte,
    12.3.2020, URL:
    <http://docupedia.de/zg/Kreutzmueller_vernichtung_der_juedischen_Gewerbetaetigkeit_v2_de_2020>

[^91]: Siehe zu den unterschiedlichen Deutungen und Perspektiven
    (insbesondere Intentionalismus vs. Strukturalismus) Bajohr 1998, S.
    10-14

[^92]: Vgl. Ludolf Herbst, Christoph Kreutzmüller, Ingo Loose u.a.,
    Einleitung, in: Ludolf Herbst, Christoph Kreutzmüller, Thomas Weihe
    (Hg.): Die Commerzbank und die Juden 1933-1945, München 2004, S.
    10-13. Diese Selbstkritik war ohne Zweifel richtig und auch
    notwendig, da sie grundlegende konzeptionelle Probleme im
    Forschungsfeld aufdeckte. Dennoch ist die einseitige Perspektive auf
    Täter, Mittäter und Mitwisser vor dem Hintergrund des
    jahrzehntelangen Verdrängens in der deutschen Nachkriegs- und
    Tätergesellschaft bis hin zu Geschichtsrevisionismus und
    Opfer-Umkehrung ein verständliches Anliegen gewesen. Letztlich
    leistete die Geschichtswissenschaft damit zwar einen späten aber
    nicht weniger wichtigen Beitrag zur historischen Aufarbeitung der
    NS-Verbrechen.

[^93]: Vgl. Nietzel 2009, S. 562-565. Mitunter wird der Begriff bis in
    die Zwangsarbeit hinein ausgeweitet. Siehe Britta Bopf:
    ,,Arisierung" in Köln. Die wirtschaftliche Existenzvernichtung der
    Juden 1933-1945, Köln 2004, S. 11.

[^94]: Siehe zum Beispiel Barbara Händler-Lachmann/Thomas Werther:
    Vergessene Geschäfte, verlorene Geschichte. Jüdisches
    Wirtschaftsleben in Marburg und seine Vernichtung im
    Nationalsozialismus, Marburg 1992; Alex Bruns-Wüstefeld: Lohnende
    Geschäfte. Die ,,Entjudung" der Wirtschaft am Beispiel Göttingens,
    Hannover 1997; Bajohr 1997/98, Einleitung, S. 9f.; Marian Rappl:
    ,,Arisierung" in München. Die Verdrängung der jüdischen
    Gewerbetreibenden aus dem Wirtschaftsleben der Stadt 1933-1939, in:
    Kommission für bayerische Landesgeschichte bei der Bayerischen
    Akademie der Wissenschaften in Verbindung mit der Gesellschaft für
    fränkische Geschichte und der Schwäbischen Forschungsgemeinschaft
    (Hrsg.), Zeitschrift für bayerische Landesgeschichte, Bd. 63, Heft
    1, München 2000, S. 82-123, hier S. 125; Heinz-Jürgen Priamus
    (Hrsg.): Was die Nationalsozialisten ,,Arisierung" nannten.
    Wirtschaftsverbrechen in Gelsenkirchen während des ,,Dritten
    Reiches", Essen 2007, S. 11ff.

[^95]: Vgl. Nietzel 2009, S. 565.

[^96]: Kreutzmüller 2016/2020, URL:
    <http://docupedia.de/zg/Kreutzmueller_vernichtung_der_juedischen_Gewerbetaetigkeit_v2_de_2020.>

[^97]: Vgl. Nietzel 2009, S. 564 und Herbst/Weihe, Commerzbank, 2004, S.
    10ff..

[^98]: Pionierarbeit leistet hier u.a. das Forschungsprojekt
    ,,Geschichte der Commerzbank von 1870 bis 1958" am Lehrstuhl für
    Zeitgeschichte an der Humboldt-Universität zu Berlin unter Leitung
    von Prof. Dr. Ludolf Herbst sowie das Forschungsprojekt zur
    Vernichtung der jüdischen Gewerbetätigkeit im Nationalsozialismus in
    den drei Großstädten Berlin, Breslau, Frankfurt am Main, ebendort.
    Siehe Ludolf Herbst/Thomas Weihe (Hg.), Die Commerzbank und die
    Juden 1933-1945, München 2004; Christoph Kreutzmüller, Ausverkauf.
    Die Vernichtung der jüdischen Gewerbetätigkeit in Berlin 1930-45,
    Berlin 2012; Benno Nietzel, Handeln und Überleben: jüdische
    Unternehmer aus Frankfurt am Main 1924-1964, Göttingen 2012

[^99]: Unwissenschaftlich insofern, als dass es sich um rassistisch
    konnotierte Begriffe handelt, die selbst eigentlich zu historisieren
    wären, anstatt diese in die Wissenschaftssprache aufzunehmen. Vgl.
    Nietzel 2009, S. 563.

[^100]: Raul Hilberg: Die Vernichtung der europäischen Juden, Band 1,
    Frankfurt am Main 1990 (zuerst englisch 1961), S. 85-163. Eine
    wichtige Ergänzung zu Hilbergs Thesen war, dass die wirtschaftliche
    Existenzvernichtung der Juden der Teilprozess, war, der ,,am
    längsten -- nämlich über den Tod der Opfer hinaus -- dauerte und
    demzufolge in alle anderen Prozesse hineinreichte". Kreutzmüller
    2012, S. 378.

[^101]: Exemplarisch wurden erstmals alle Teilprozesse systematisch im
    Rahmen der Erforschung der Geschichte der Commerzbank betrachtet.
    Siehe Herbst/Weihe, Commerzbank, 2004.

[^102]: Vgl. Kreutzmüller 2016/2020.

[^103]: Vgl. Nietzel 2012, S. 164 und Kreutzmüller 2012, S. 250.

[^104]: Systematisch untersucht von Kreutzmüller, Ausverkauf, 2012,
    Kapitel IV. Abwehrstrategien jüdischer Gewerbetreibender, S.
    257-357; Nietzel, Handeln und Überleben, 2012, Kapitel II.2
    Erwartungen, Anpassung und Selbstbehauptung, S. 99-150.

[^105]: Vgl. ebd. S. 562-565.

[^106]: Ebd. S. 564.

[^107]: Vgl. Nietzel 2009, S. 562.

[^108]: Nietzel 2009, S. 562. Nietzel greift außerdem die Beteiligung
    von nichtjüdischen Unternehmen mit auf aber explizit nicht als eine
    eigene Kategorie sondern als Querschnittaspekt, weshalb dieser hier
    nicht berücksichtigt wird, da er strenggenommen zum Forschungsfeld
    der Unternehmensgeschichte gehört. Siehe zu Unternehmensgeschichte
    Ralf Ahrens, Unternehmensgeschichte, Version: 1.0, in:
    Docupedia-Zeitgeschichte, 1.11.2010, URL:
    <http://docupedia.de/zg/Ahrens_unternehmensgeschichte_v1_de_2010.>.

[^109]: Vgl. ebd. S. 273.

[^110]: Vgl. ebd. S. 602-608.

[^111]: Aus Literaturrecherche und Interviews ging nicht hervor, dass
    Nietzels Systematik nachträglich kontrovers diskutiert oder
    weiterentwickelt wurde.

[^112]: Siehe Kreutzmüller 2016/2020, URL:
    <http://docupedia.de/zg/Kreutzmueller_vernichtung_der_juedischen_Gewerbetaetigkeit_v2_de_2020.>

[^113]: Siehe Maren Janetzko: Die ,,Arisierung" mittelständischer
    jüdischer Unternehmen in Bayern 1933-1939. Ein interregionaler
    Vergleich, Ansbach 2012, S. 17f; Claudia Flümann: ,,\... doch nicht
    bei uns in Krefeld!\". Arisierung, Enteignung, Wiedergutmachung in
    der Samt- und Seidenstadt 1933-1963, Krefeld 2015, S. 13 oder jüngst
    bei Monika Juliane Gibas: ,,Arisierung" der Wirtschaft in Thüringen:
    Das Beispiel Arnstadt, in: Schlossmuseum Arnstadt (Hrsg.): Jüdische
    Familien aus Arnstadt und Plaue. Katalog zur Sonderausstellung im
    Schlossmuseum Arnstadt, Arnstadt 2021, S. 108-148..

[^114]:

[^115]: Zwar wurde das Thema auch in Form von Überblicks- oder
    Gesamtdarstellungen zum Deutschen Reich (in den Grenzen von 1937)
    abgehandelt, dies jedoch nur vereinzelt und vor allem in den
    Anfangsjahren der wissenschaftlichen Auseinandersetzung mit dem
    Thema. Siehe zum Beispiel die bereits erwähnten grundlegenden
    Studien von Genschel 1966 und Barkai 1987. Danach erschienen sind
    noch: Günter Plum, Wirtschaft und Erwerbsleben, in: Wolfgang Benz
    (Hrsg.), Die Juden in Deutschland 1933-- 1945. Leben unter
    nationalsozialistischer Herrschaft, München 1988, S. 268--313.
    Dieter Ziegler, Die wirtschaftliche Verfolgung der Juden im »Dritten
    Reich«, in: Heinz-Jürgen Priamus (Hrsg.), Was die
    Nationalsozialisten ,,Arisierung" nannten. Wirtschaftsverbrechen in
    Gelsenkirchen während des »Dritten Reiches«, Essen 2007, S. 17--40.
    Für die Literaturanalyse wurden vier Überblicks- bzw.
    Gesamtdarstellungen und fünfzehn Lokalstudien erfasst. Es ist
    natürlich nicht auszuschließen, dass es mehr Darstellungen zum
    Deutschen Reich oder zu Europa gibt, aber eine Tendenz im
    Forschungsfeld hin zu lokalhistorischen Studien ist nichtsdestotrotz
    deutlich erkennbar.

[^116]: Darunter fiel auch die antisemitische Definition, was unter
    einem \"jüdischen Gewerbebetrieb\" verstanden werden sollte.

[^117]: Vgl. Nietzel 2009, S. 562, 565 und 576.

[^118]: Programmatisch war hier wieder die Lokalstudie zu Hamburg von
    Frank Bajohr Ende der neunziger Jahre. Siehe Bajohr 1997/98.

[^119]: Die einzige vergleichend angelegte Studie, allerdings nur auf
    regionaler Ebene, stammt aus dem Jahr 2012 von der Historikerin
    Maren Janetzko, erschien also nach Nietzels Literaturbericht. Vgl.
    Nietzel 2009, S. 562. Janetzko, Die ,,Arisierung" Mittelständischer
    jüdischer Unternehmen in Bayern 1933-1939. Ein interregionaler
    Vergleich 2012. Vgl. Interview B3_Transkript: ,,\[\...\] dass
    esviele Einzelstudien zur verschiedenen Städten gibt, zu Hamburg, zu
    München, zu Berlin ansatzweise - ist natürlich eine ganz andere
    Dimension in Berlin. Zu Göttingen, dann eben zu Mannheim, aber das
    sind ja alles so einzelne Bausteine.".

[^120]: Vgl. zu den Datensilos Interview B4_Transkript: ,,\[\...\] dass
    diese Vernetzungsansätze nicht nur punktuell stattfinden, weil sie
    dann auch wieder nur Fragment bleiben, sondern dass sie tatsächlich
    auch übergreifend funktionieren \[\...\]".

[^121]: Siehe Bajohr 1997, S. 12f., Rappl 2000, S. 123f., Nietzel 2009,
    S. 17

[^122]: Siehe zum Beispiel das Netzwerk ,,Jüdisches Leben Erfurt",
    Informationen zu jüdischen Unternehmen in Erfurt zusammenträgt, URL:
    <https://juedisches-leben.erfurt.de/jl/de/19jh/jgemeinde/junternehmen/index.html>.
    Bisher erschienen ist daraus die Miniatur von Christoph
    Kreutzmüller, Eckart Schörle (Hg.): Stadtluft macht frei? Jüdische
    Gewerbebetriebe in Erfurt 1919 bis 1939, Berlin 2013. Das Jüdische
    Museum Berlin (JMB) hat im Jahr 2020 die Citizen Science Plattform
    ,,Jewish Places" online geschalten, auf der Orte zu jüdischem Leben
    europaweit kollaborativ gesammelt werden können, darunter auch
    Gewerbe, URL:
    [https://www.jewish-places.de/map?term=&filter\[type\]\[0\]=facility&filter\[facility_category_facet\]\[0\]=Gewerbe\~Geschäft&filter\[location\]\[center\]=52.829120842815996,13.830385954234998&rows=100000](https://www.jewish-places.de/map?term=&filter[type][0]=facility&filter[facility_category_facet][0]=Gewerbe~Geschäft&filter[location][center]=52.829120842815996,13.830385954234998&rows=100000){.uri}.
    (alle letzter Zugriff am 07.05.2022). Oft sind Informationen zu
    jüdischen Gewerbebetrieben und Unternehmern in Form von
    Gedenkbüchern gesammelt erschienen, siehe zum Beispiel: Wolfram
    Selig: ,,Arisierung" in München. Die Vernichtung jüdischer Existenz
    1937-1939, München 2004.

[^123]: Programmatisch war das gleichnamige Handbuch des schwedischen
    Literaturhistorikers Sven Lindqvist aus dem Jahr 1978, deutsch 1989:
    Grabe wo du stehst. Handbuch zur Erforschung der eigenen Geschichte,
    Bonn 1989.

[^124]: Siehe zur Geschichte und zum Einfluss der Bewegung: Jenny
    Wüstenberg, Zivilgesellschaft und Erinnerungspolitik in Deutschland
    seit 1945, Berlin Münster 2020, Kapitel 4 Grabe, wo stehst: Die
    Geschichtsbewegung und die Graswurzel-Erinnerungskultur S. 147-200
    und Kapitel 5 Memorialästhetik und die Erinnerungsbewegungen der
    1980er, S. 201-230.

[^125]: Das bekannteste Projekt ist wahrscheinlich das
    Stolperstein-Projekt des Künstlers Gunther Demnig. Vgl. Wüstenberg
    2020, S. 209. Die erste Verlegung in Berlin-Kreuzberg im Jahr 1996
    war von den Behörden noch nicht genehmigt worden und wurde erst
    später legalisiert. Siehe Projektwebsite, URl:
    <http://www.stolpersteine.eu/start/> (Letzter Zugriff am
    26.01.2022).

[^126]: Thomas Lindenberger, Michael Wildt: Radikale Pluralität.
    Geschichtswerkstätten als praktische Wissenschaftskritik, in:
    Friedrich-Ebert-Stiftung (Hrsg.), Archiv für Sozialgeschichte, Band
    29, Bonn 1989, S. 393-411 (hier S. 395), URL (stable):
    <http://library.fes.de/jportal/receive/jportal_jparticle_00013422>.

[^127]: Diese Entwicklung hatte natürlich auch Auswirkung auf die
    akademische Geschichtswissenschaft, die sich von einer
    sozialhistorischen Ausrichtung hin zu einer *Alltagsgeschichte*, als
    neuen Forschungsansatz, weiterentwickelte. Siehe dazu Lindenberg/
    Wildt 1989, S. 393f., 405-409.

[^128]: Lindenberg/ Wildt 1989, S. 394.

[^129]: Ebd.

[^130]: DFG 2021, S. 13.

[^131]: Dissertationen: Hamburg (Bajohr 1998), Köln (Bopf 2004),
    Mittelfranken (Janetzko 2012), Mannheim (Fritsche 2013); Akademische
    Forschungsprojekte: Berlin (Kreutzmüller 2012), Frankfurt am Main
    (Nietzel 2012), Breslau (2012).

[^132]: Nürnberg und Fürth (Matthias Henkel u.a.: Entrechtet,
    entwürdigt, beraubt. Die Arisierung in Nürnberg und Fürth, hrsg. für
    d. Museen d. Stadt Nürnberg, 2012/2013), Erfurt (Christoph
    Kreutzmüller, Eckart Schörle: Stadtluft macht frei? Jüdische
    Gewerbebetriebe in Erfurt 1919 bis 1939, Leipzig 2013), jüngst
    Arnstadt (Schlossmuseum Arnstadt (Hrsg.): Jüdische
    Gewerbeansiedlungen in Arnstadt von 1874 bis 1929 und ,,Arisierung"
    der Wirtschaft in Thüringen: Das Beispiel Arnstadt, in: Jüdische
    Familien in Arnstadt und Plaue, Begleitband zur Ausstellung,
    Arnstadt 2021) ).

[^133]: Vgl. Interview B4_Transkript: ,,\[\...\] und da habe ich
    vielleicht einen anderen Zugang, als ein reiner Wissenschaftler -
    mir geht es auch immer um die erinnerungskulturelle Bedeutung oder
    die erinnerungskulturelle Sinnstiftung hier in diesem Gemeinwesen
    München, die steht für mich - nicht an erster Stelle, aber sie steht
    für mich sehr prominent weit vorne \[\...\]".

[^134]: Für Krefeld immerhin 135 jüdische Gewerbebetriebe, vgl. Flümann
    2015. Die Autorin hat der Verfasserin dieser Arbeit
    dankenswerterweise ihre Daten zur Verfügung gestellt.

[^135]: Vgl. Interview B2_Transkript: ,,\[\...\] weil ich immer wieder
    Anfragen bekomme und weiß, dass Leute sich mit all möglichen
    Unternehmensschicksalen oder Schicksalen jüdischer Bürger in ihrer
    Stadt, in ihrem Viertel auseinandersetzen und dazu auch
    Informationen suchen.".

[^136]: Vgl. Interview B1_Transkript: ,,Und das ist auch wirklich
    erstaunlich, dass ich auch nach wie vor immer noch Anfragen von
    Nachkommen erhalte, die mich fragen, was ich noch mehr zu ihren
    Vorfahren rausfinden kann.", Pos. 39.

[^137]: Ausgewählt für die Interviews wurden insgesamt 14 Personen, von
    denen acht erreichbar waren.

[^138]: Vgl. Interview B3_Transkript, Pos. 67.

[^139]: Vgl. Interview B2_Transkript, Pos. 47.

[^140]: Vgl. Interview B4_Transkript, Pos. 61.

[^141]: Vgl. Interview B3_Transkript, Pos. 83.

[^142]: Vgl. Interview B4_Transkript, Pos. 19.

[^143]: Vgl. Interview B4_Transkript, Pos. 87.

[^144]: Vgl. Interview B2_Transkript, Pos. 47.

[^145]: Vgl. Interviews B2_Transkript, Pos. 35 und B3_Transkript, Pos.
    51.

[^146]: Heute Bundesanzeiger. Die ZHRB liegt inzwischen als Scan
    vollständig digitalisiert vor, URL:
    <https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/>
    (letzter Zugriff am 18.05.2022). Siehe zur Geschichte des Deutschen
    Reichsanzeigers und Preußischen Staatsanzeigers Christoph Kling:
    ,,Deutscher Reichsanzeiger und Preußischer Staatsanzeiger.
    Einleitung zur Veröffentlichung der Digitalausgabe", Mannheim, 2016.

[^147]: Die Veröffentlichungs-, Offenlegungs- und
    Bekanntmachungspflichten bestehen bis heute. Siehe Bundesamt für
    Justiz, URL:
    <https://www.bundesjustizamt.de/DE/Themen/Ordnungs_Bussgeld_Vollstreckung/Jahresabschluesse/Offenlegung/Offenlegungspflichten/Offenlegungspflichten_node.html>.
    Das Handelsregister kann jedoch heute online eingesehen werden, URL:
    <https://www.handelsregister.de/rp_web/welcome.xhtml> (alle Zugriff
    am 18.05.2022).

[^148]: Für Berlin zum Beispiel Zeitschriften wie die ,,Jüdische
    Rundschau" oder ,,Der Stürmer" sowie öffentliche
    Vereinsmitgliederverzeichnisse, Jüd. Gemeindeblätter, Jüd.
    Adressbücher, etc. Informationen basieren auf einer
    SQL-Datenbankabfrage vom 18.05.2022.

[^149]: URL:<https://www.bundesarchiv.de/gedenkbuch/>.

[^150]: Siehe am Beispiel des Datensates de1086146, URL:
    <https://www.bundesarchiv.de/gedenkbuch/de1086146>.

[^151]: Das gleiche gilt im Übrigen auch für die ,,Zentrale Datenbank
    der Namen der Holocaustopfer" der Gedenkstätte Yad Vashem. Siehe
    Datensatz 11536340 zu selben Person wie oben, URL:
    <https://yvng.yadvashem.org/index.html?language=de&s_id=&s_lastName=Kann&s_firstName=Marion&s_place=Berlin&s_dateOfBirth=&cluster=true>
    (letzter Zugriff am 18.05.2022).

[^152]: Dazu gehören sogenannte Arisierungslisten, Entjudungsakten,
    Handelsregisterakten, etc.

[^153]: Hier gilt mitunter noch die Einschränkung nach dem
    Bundesarchivgesetz § 11 Abs. 2, dass nach Ablauf der allgemeinen
    Schutzfrist (für die Wiedergutmachungsakten in den 90er Jahren),
    personenbezogene Akten entweder mit Erlaubnis der betroffenen
    Personen oder frühestens 10 Jahre nach Tod der Person benutzt werden
    dürfen. Vgl. Bundesarchivgesetz vom 10. März 2017, URL:
    <https://www.bundesarchiv.de/DE/Navigation/Meta/Ueber-uns/Rechtsgrundlagen/Bundesarchivgesetz/bundesarchivgesetz.html>
    (letzter Zugriff am 18.05.2022).

[^154]: Vgl. Götz Aly, Karl Heinz Roth: Die restlose Erfassung.
    Volkszählen, Identifizieren, Aussondern im Nationalsozialismus,
    Berlin 1984, S. 67-105.

[^155]: Bajohr spricht sogar von ,,umfassenden Täterschutz", Bajohr
    1998, S. 24.

[^156]: Sie hat sich auch in den Interviews widergespiegelt, vgl.
    Interview B1_Transkript, Pos. 123, 125, 127, 129.

[^157]: The Central Database of Shoah Victims' Names, URL:
    <https://yvng.yadvashem.org/> (letzter Zugriff am 18.05.2022).

[^158]: URL: <https://www.wikidata.org/wiki/Wikidata:Main_Page> (letzter
    Zugriff am 20.05.2022).

[^159]: URL: <https://www.tib.eu/de/> (letzer Zugriff am 20.05.2022).

[^160]: URL: <https://nfdi4culture.de/index.html> (letzter Zugriff am
    20.05.2022).

[^161]: URL: <https://wikibase.consulting/what-is-wikibase/> (letzter
    Zugriff am 20.05.2022).

[^162]: Siehe Lozana Rossenova (2022): Examining Wikidata and Wikibase
    in the context of research data management applications,
    veröffentlicht am 16.03.2022 auf dem TIB-Blog, URL:
    <https://blogs.tib.eu/wp/tib/2022/03/16/examining-wikidata-and-wikibase-in-the-context-of-research-data-management-applications/>.

[^163]: URI: <https://nfdi4culture.de/resource/E2261/about.html>.

[^164]: Das Projekt wurde 2017 an der Fachhochschule Potsdam initiiert
    und ist vom Auswärtigen Amt gefördert worden, URL:
    <https://archivfuehrer-kolonialzeit.de/> (letzter Zugriff am
    20.05.2022).

[^165]: Zum Beispiel Georeferenzierung der Orte anhand historischen
    Kartenmaterials, URL: <https://archivfuehrer-kolonialzeit.de/map>
    (letzter Zugriff am 20.05.2022).

[^166]: URL: <https://archivfuehrer-kolonialzeit.de/about> (letzter
    Zugriff am 20.05.2022).

[^167]: URL:
    [Wikidata:WikiProject European Colonialism](Wikidata:WikiProject European Colonialism){.uri}
    (letzter Zugriff am 20.05.2022).

[^168]: Im EU-Programm ,,Horizon Europe", das bis 2027 läuft, URL:
    <https://ec.europa.eu/info/research-and-innovation/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe_en>.
    Projektwebsite von EHRI, URL: <https://www.ehri-project.eu/> (alle
    letzter Zugriff am 20.05.2022).

[^169]: Nancy Cooey (2018): Using Wikidata to build an authority list of
    Holocaust-era ghettos, veröffentlicht am 12.02.2018 auf dem EHRI
    Document Blog, URL:
    <https://blog.ehri-project.eu/2018/02/12/using-wikidata/#Selecting_Wikidata_as_a_Tool>
    (letzter Zugriff am 20.05.2022).

[^170]: Vgl. ebd. Zentrale Enzyklopädien sind ,,The Yad Vashem
    Encyclopedia of the Ghettos During the Holocaust" von Yad Vashem
    (Israel) und ,,USHMM Encyclopedia of Camps and Ghettos" des United
    States Holocaust Memorial Museum (USA).

[^171]: Im Rahmen dieser Arbeit können diese Technologien nicht
    detailliert vorgestellt werden, daher wird auf Grundlagenliteratur
    verwiesen. Siehe zum Beispiel Christian Stein: Linked Open Data --
    Wie das Web zur Semantik kam, in: Bibliothek Forschung und Praxis
    (Hrsg.), Band 38, Nr. 3, 2014, S. 447-455,
    doi:10.1515/bfp-2014-0055; Patrick Danowski, Adrian Pohl: (Open)
    Linked Data in Bibliotheken, Berlin, Boston, 2013,
    doi:10.1515/9783110278736; Gradmann, Steffen Hennicke, Marlies
    Olensky: Linked Data, in: Digitale Dienste für die Wissenschaft
    (Hrsg.), 2012, S. 18-22, doi.org/10.18452/6627;

[^172]: Siehe Mediawiki (2022): Wikibase/DataModel,
    URL:<https://www.mediawiki.org/wiki/Wikibase/DataModel> (letzter
    Zugriff am 22.05.2022).

[^173]: B4_Transkript, Pos. 67.

[^174]: Vgl. W. H. Schröder: Historische Sozialforschung:
    Forschungsstrategie - Infrastruktur - Auswahlbibliographie.
    Historical Social Research, in: Supplement (Hrsg.) 1988, Nr. 1, S.
    1-109, hier S. 15ff., URN:
    <https://nbn-resolving.org/urn:nbn:de:0168-ssoar-286038>

[^175]: Was zu einem ,,Quellenproblem" führen kann, siehe dazu ebd. S.
    19f.

[^176]: Ausführlich zum Konzept der Wikidata-Items siehe URL:
    <https://www.wikidata.org/wiki/Help:Items> (letzter Zugriff am
    21.05.2022).

[^177]: URL:
    <https://www.dublincore.org/specifications/dublin-core/dcmi-terms/>
    (letzter Zugriff am 15.05.2022)

[^178]: URL: <https://datacite.org/> (letzter Zugriff am 15.05.2022)

[^179]: URL: <https://gepris.dfg.de/gepris/OCTOPUS?task=showAbout>
    (letzter Zugriff am 21.05.2022).

[^180]:

[^181]: Diese Informationen konnten anhand der Publikation extrahiert
    werden, siehe Kreutzmüller 2012, S. 7-13.

[^182]: HU Berlin (2022): Dokumentation und Metadaten, URL:
    <https://www.cms.hu-berlin.de/de/dl/dataman/teilen/dokumentation/metadaten>
    (letzter Zugriff am 21.05.2022).

[^183]: Vgl. forschungsdaten.info (2022): Metadaten und
    Metadatenstandards, URL:
    <https://www.forschungsdaten.info/themen/beschreiben-und-dokumentieren/metadaten-und-metadatenstandards/>
    (letzter Zugriff am 21.05.2022).

[^184]: Vgl. forschungsdaten.info, URL:
    <https://www.forschungsdaten.info/themen/beschreiben-und-dokumentieren/metadaten-und-metadatenstandards/>
    (letzter Zugriff am 15.05.2022).

[^185]:

[^186]: URL: <https://ianus-fdz.de/>. Der Support war nach Auslaufen der
    DFG-Projektförderung 2017 allerdings eingeschränkt. So konnten neue
    Datensammlungen bis 2022 nicht aufgenommen werden, siehe URL:
    <http://datenportal.ianus-fdz.de/pages/information.jsp#dateneigentuemer>
    (alle letzter Zugriff 15.05.2022).

[^187]: Siehe zum Beispiel die Thesauri des Deutschen Archäologischen
    Instituts, URL: <http://thesauri.dainst.org/de.html> mit der
    Kollektion zu den Methoden, URL:
    <http://thesauri.dainst.org/de/collections/_203bcc05.html> (alle
    letzter Zugriff am 15.05.2022).

[^188]: In München übernahm diese Aufgabe das städtische Gewerbeamt,
    vgl. Rappl 2000, S. 145f. In Frankfurt am Main war der zentrale
    Akteur die Industrie- und Handelskammer.

[^189]: Vgl. Bajohr 1998, S. 21ff.

[^190]: Der Autor beschreibt dieses eher unkonventionelle Vorgehen im
    Forschungsfeld sehr detailliert in der Einleitung seiner Studie,
    vgl. Kreutzmüller 2012, S. 29-38.

[^191]: Das wird in der Studie zu Hamburg auch ausführlicher
    reflektiert. Vgl. Bajohr 1997, S. 9.

[^192]: Siehe forschungsdaten.info (2022): DataCite-Best-Practice-Guide,
    URL:
    <https://www.forschungsdaten.info/themen/beschreiben-und-dokumentieren/metadaten-und-metadatenstandards/>
    sowie Julian Schulz, Sonja Kümmet, Stephan Lücke, Martin Spenger,
    Tobias Weber (2020): Standardisierung eines Standards: Warum und wie
    ein Best-Practice-Guide für das Metadatenschema DataCite entstand,
    Version 1 (20.01.2020, 13:49). In: Korpus im Text, Serie A,
    42800Absatz 15. URL:
    <http://www.kit.gwi.uni-muenchen.de/?p=42800&v=1#p:15> (alle letzter
    Zugriff am 15.05.2022).

[^193]: DataCite Metadata Working Group. (2021). DataCite to Dublin Core
    Mapping 4.4. DataCite e.V., doi:10.14454/qn00-qx85.

[^194]: Daneben gibt es noch die rein qualitativen oder
    Einzelfall-Studien, die hier aber nicht näher betrachtet werden, da
    ihr Anteil an Forschungsdaten zu jüdischen Gewerbebetrieben gering
    ist.

[^195]: Nietzel hebt hier die akribisch recherchierte Textsammlung zu
    jüdischen Unternehmen in München des Archivars und Historikers
    Wolfgang Selig aus dem Jahr 2004 hervor, vgl. Nietzel 2009, S. 583.

[^196]: Hier vor allem die zahlreichen Gedenkbücher zu jüdischen
    Personen, die mittlerweile online zugänglich sind und wo sich Daten
    zu jüdischen Gewerbebetrieben in den Biogrammen der Personen
    ,,verstecken". Siehe zum Beispiel ,,Biografisches Gedenkbuch der
    Münchner Juden 1933--1945" der Stadt München, URL:
    <https://gedenkbuch.muenchen.de/> (letzter Zugriff am 12.05.2022).
    Bei der Biografie von Max Hofman ist unter ,,Weitere Informationen"
    vermerkt: ,,Max Hofmann war Inhaber der Fa. Max Hofmann, einem
    Großhandel und Versand von Manufaktur- und Textilwaren, in der
    Paul-Heyse-Straße 28/I. Das Gewerbe wurde am 17.10.1938 für den
    15.10.1938 abgemeldet.", URL (stable):
    <https://gedenkbuch.muenchen.de/index.php?id=gedenkbuch_link&gid=5722>.

[^197]: Ebd.

[^198]: Allein für Berlin hat die Stichprobe einen Umfang von ca. 8.000
    jüdischen Gewerbebetrieben. Auch für Frankfurt am Main sind es in
    der Stichprobe über 2.500 jüdische Gewerbebtriebe. Vgl. Kreutzmüller
    2012, URL: <https://www2.hu-berlin.de/djgb/www/find> (letzter
    Zugriff am 07.05.2022) und Nietzel 2012, S. 15.

[^199]: Und die es auch in der Geschichte des Begriffs nie gegeben
    hat.**Vgl. Nietzel und Kreutzmüller**

[^200]: Nachweis

[^201]: Vgl. Nietzel S.
