---
author:
- |
  vorgelegt von:\
  Sophie Eckenstaler
date: am 07.06.2022
publishers: |
  Erstbetreuer: Prof. Dr. Rüdiger Hohls, Institut für
  Geschichtswissenschaften, HU Berlin\
  Zweitbetreuer: Prof. Dr. Michael Wildt, Institut für
  Geschichtswissenschaften, HU Berlin\
  Studiengang: Master of Arts, Geschichtswissenschaften, Schwerpunkt:
  Digital History\
  Matrikelnr.: 596272\
  E-Mail: sophie.eckenstaler@hu-berlin.de\
  Eberswalde, den 7. Juni 2022
subject: Masterarbeit
subtitle: Konzeption eines offenen Forschungsdatenmanagements am
  Beispiel von Forschungsdaten zu jüdischen Gewerbebetrieben im
  Nationalsozialismus
title: Open Science in den Geschichtswissenschaften?
titlehead: |
  Humboldt-Universität zu Berlin\
  Philosophische Fakultät\
  Institut für Geschichtswissenschaften
---

# Einleitung

Forschungsdatenmanagement in Verbindung

Die große Menge an Open Science Initiativen Anwendern von Open Science
Angeboten zeigt, dass Open Science in der Wissenschaft angekommen und in
Begriff ist, sich dort zu etablieren. Aufschwung erlebte Open Science
zuletzt im Zusammenhang mit der COVID-19-Pandemie, wo der als Mangel und
damit letzten Endes Leben zu retten angesehen Den Bedarf von Open
Science verstärkt.

Im Kern geht es auch darum, die Integrität von wissenschaftlicher
Forschung zu wahren, sie gerade im sogenannten postfaktischen Zeitalter
zu stärken, das heißt sie weniger anfällig für Betrug und Fälschung in
einer digitalen Welt zu machen.

Auch bei wissenschafts- wie gesellschaftspolitischen Entscheidungen
gewinnt Open Science auf Bundes- sowie auf EU-Ebene an Relevanz, wobei
zu konstatieren ist, dass der Schwerpunkt zumindest in Deutschland

Wenn auch noch nicht die volle Bandbreite von Open Science, so
unterstützt die Deutsche Forschungsgemeinschaft (DFG) immerhin offiziell
gezielt Open Access-Publikationen finanziell.

Die Europäische Union hat Open Science zu einem von insgesamt drei
Grundsatzzielen für die Forschungsarbeit in Europa erklärt und die
Deutsche UNESCO-Kommission betont in ihrer Empfehlung für Open Science:

,,Darüber hinaus besteht mit Open Science eine Chance auf die praktische
Umsetzung von seit Langem bestehenden politischen Forderungen: Mit Open
Science kann Teilhabe an und Zugang zu wissenschaftlichen Erkenntnissen
als Gemeingut und Menschenrecht praktisch umgesetzt werden, wie es
bereits seit Ende des Zweiten Weltkriegs in der Allgemeinen Erklärung
der Menschenrechte gefordert war." Und auch auf der EU-Ebene

## Ausgangspunkt

Berliner Forschungsdaten zu jüdischen Gewerbebetrieben, Transformation
von Access-DB in Online-DB liegen detailliert vor

Für die technische Implementierung des offenen
Forschungsdatenmanagements braucht es geeignete Infrastruktursoftware
bzw. -dienste, die sich allerdings im wissenschaftlichen Kontext derzeit
noch im Aufbau befinden, wie in Kapitel 2 gezeigt worden ist.
Festzuhalten ist also, dass es eine standardisierte Nutzung von
Forschungsdatenemanagement in der historischen Forschung noch nicht
gibt. Diese offene Situation wird in dieser Arbeit vor allem dazu
genutzt, explorative Wege im Forschungsdatenmanagement zu bestreiten, um
Chancen und Grenzen für die historische Forschung auszuloten.

## Fragestellung und Zielsetzung

Was kann Open Science für die geschichtswissenschaftliche Forschung
bringen. Zeigen, was hinsichtlich FDM und Open Science heute möglich
ist.

Implementierbarkeit von offenem FDM exemplarisch untersuchen, indem
prototypische Lösung implementiert wird und Möglichkeiten sowie Grenzen
dieser Implementierung herausgearbeitet werden.

FDM offen bezüglich: - technisch offen ist, das heißt das offene
Technologien verwendete Damit läuft die Konzeption auf eine
prototypische Lösung von offenem FDM hinaus, die übertragbar auch auf
andere zeitgeschichtliche Forschungsfelder ist. Versuch unternommen
werden Open Science auf Forschungsdatenmanagement anzuwenden. über den
gesamten Research Data Lifecycle hinweg, die Forschungsdaten offen sind.
Am beispiel des Forschungsfeld untersuchen, welchen Mehrgewinn das
insbesondere für die historische Forschung bringen kann.

hier Fokus klar machen, der auf Lokalstudien liegt, die systematisch
Forschungsdaten gesammelt haben, weil 1. sie die meisten Daten gesammelt
haben und 2. zum Zweck gesammelt, Erkenntnisprofit zu erzielen

## Methodisches Vorgehen

hier erwähnen, dass Open Science Framework verwendet wurde --\> dort
sind auch alle Materialien enthalten (public)

Strukturiert an einen idealtypischen Forschungsprozess. Nicht alle
möglichen Anwendungsfälle abgedeckt werden. Aber Abdeckung gesamten
Forschungsdatenlebenszyklus sicher stellen

Mit den Open Science-Grundsätzen sowie den Konzepte Open und FAIR Data
steht das Gerüst von offenem Forschungsdatenmanagement vor allem
hinsichtlich der Qualitätssicherung weitgehend fest.

prototypische Lösung --\> an idealtypischen Forschungsdatenlebenszyklus
entlang entwickelt und orientiert sich am empirischen Forschungsprozess

Beim Forschungsdatenmanagement geht es im Kern darum,
phasenübergreifende Workflows nach gängigen Standards oder Best
Practises zu entwickeln, die den wissenschaftlichen Umgang mit den
Forschungsdaten in jeder Phase des Forschungsprozesses sicher stellen
sowie darüber hinaus den gesamten Forschungsdatenlebenszyklus abdecken.
Die Open Science-Grundsätze sowie die Strategie der Open Research Data,
die Open Data und FAIR Data Principles verbindet, geben die
Qualitätseigenschaften vor, während mit den in Kapitel 3
herausgearbeiteten Kriterien, Stakeholdern, rechtlichen und ethischen
Rahmenbedingungen die spezifischen funktionalen Anforderungen des
Forschungsfelds feststehen. Damit kann im Anschluss eine erste
Implementierung des offenen FDM am Beispiel der Forschungsdaten zu
jüdischen Gewerbebetrieben prototypisch erfolgen.

Strukturiert an einen idealtypischen Forschungsprozess. Nicht alle
möglichen Anwendungsfälle abgedeckt werden. Aber Abdeckung gesamten
Forschungsdatenlebenszyklus sicher stellen und für jede Phase
herausarbeiten, wan an funktionalen Anforderungen für offenes FDM
gebraucht werden

# Grundlagen

nicht-funktionale Anforderungen, Qualitätseigenschaften von offenem FDM

## Open Science

Was das Schlüsselwort ,,Open" im Kontext von Wissenschaft aussagt,
erschließt sich nicht sofort. Um zu verstehen, was Open Science ist und
warum diese als notwendig für die traditionelle Wissenschaft gewertet
wird, wird die gleichnamige Bewegung in den Blick genommen und deren
Ursprünge überblickt.[^1] Zudem wird der Versuch unternommen, den
Begriff Open Science für eine Anwendung in dieser Arbeit zu definieren.
Anhand von existierenden Konzepten und Infrastruktuen wird abschließend
herausgearbeitet, wo Open Science gegenwärtig steht, woraus sich
wiederum Konsequenzen für die Implementierung eines offenen
Forschungsdatenmanagements ergeben.

### Ursprünge der Open Science-Bewegung

Hinsichtlich der Entstehung der Open Science-Bewegung können zwei
Entwicklungsstränge verfolgt werden. Zum einen lässt sie sich auf ein
konkretes Ereignis innerhalb der Wissenschaft zurückverfolgen, nämlich
auf die sogenannte Replikationskrise. Hier bezieht sich Open Science
explizit auf die Transformation wissenschaftlicher Forschungsmethoden
und -praktiken, um Forschung noch robuster zu machen. Zum anderen ist
Open Science Teil der breiteren sozialen Open-Bewegung, welche von der
Do-it-yourself-Bewegung, der Hacker-Bewegung der 1960/ 70er sowie der
Freie-Software-Bewegung der 1980er Jahre (Vorgänger der Open
Source-Bewegung) stark beeinflusst ist.[^2]

##### Replikationskrise

Ab Mitte der 2010er Jahre erhielten in der Wissenschaft, vordergründig
in der Psychologie sowie in den Lebens- und Naturwissenschaften,
zunehmend Replikationsstudien Aufmerksamkeit. Diese konnten in
sogenannten Replikationsversuchen eine statistisch signifikante Anzahl
publizierter empirischer Forschungsergebnisse entweder falsifizieren
oder nicht replizieren, weil die Daten nicht zur Verfügung standen.[^3]
Das löste die vielfach diskutierte ,,Replikationskrise" in den
betroffenen Fächern aus. Zum einen ging es, hinsichtlich der
Falsifizierungen, nachträglich um Ursachenforschung, die sich auf
Defizite insbesondere bei den Forschungsmethoden und in der
Publikationspraxis wissenschaftlicher Journals fokussierte.[^4] Aber
auch die Replikationsstudien selbst wurden kritisch betrachtet.[^5] Zum
anderen war, hinsichtlich der Nichverfügbarkeit von Daten, eine
wesentliche Eigenschaft von robuster evidenzbasierter Forschung, nämlich
die Nachvollziehbarkeit ihrer Ergebnisse durch Replikation (als
Bestandteil von Qualitätssicherung), nicht mehr gegeben und damit in der
Konsequenz auch ein gesellschaftlicher Bedeutungsverlust von
Wissenschaft bei der Wissensproduktion zu befürchten.

Kurzum ging es um die existenzielle Frage, wie Wissenschaft praktiziert
werden muss, damit wissenschaftliche Forschung, insbesondere die
statistisch empirische, reliabel ist. Als Antwort auf diese Krise hat
sich in den vergangenen Jahren die internationale Open Science-Bewegung
formiert[^6], die in den Anfangsjahren stark auf die Frage nach
Replizierbarkeit von Forschungsstudien fokussiert war.

In Deutschland hat sich zuletzt das *German Reproducibility Network*
(GRN) gegründet, das fachübergreifend gezielt Replikationsstudien und
Open Science Praktiken unterstützen möchte.[^7] Auf internationaler
Ebene ist vor allem das interdisziplinäre *Center for Open Science*
(COS) zu nennen, welches in direkter Reaktion auf die Replikationskrise
2013 in den USA gegründet wurde[^8]. Eine der ersten Aktivitäten des COS
war das mit der University of Viginia gemeinsam großangelegte
*Reproducibility Project*, in dem sich eine Autorengruppe, welche sich
,,Open Science Collaboration" nannte, systematisch mit der
Reproduzierbarkeit von 100 Forschungsstudien in der Psychologie
auseinandersetzte.[^9]. Nach der Bestandsaufnahme, bei der die Rate
nichtreplizierbarer Forschungsstudien wie bei vorausgegangenen
Replikationsstudien signifikant hoch war, widmete sich das COS verstärkt
den Strategien zur Überwindung der Replikationskrise, die im Kern
ebenfalls als eine methodische Krise identifiziert wurde sowie
zweifelhafte Forschungspraktiken aufdeckte.

##### Open-Bewegung

Die Open Science-Bewegung ist Teil der breiten sozialen Open-Bewegung,
welche unter den Begriffen ,,Open", ,,Openness" beziehungsweise ,,Free"
subsumiert, ,,Daten, Entwürfe, Fotos, Musikstücke oder sonstige Inhalte
und Wissen" [^10] aus allen gesellschaftlichen Bereichen zur
Weiterverbreitung sowie Wiederverwendbarkeit schrankenlos zur Verfügung
stellen und dadurch Teilhabe als demokratisches Prinzip in einer
freiheitlichen Gesellschaft stärken will. Außerdem sieht sie in dieser
Kultur der Offenheit Potenzial für neue Innovationen[^11] Diese
Forderungen sind zwar nicht grundsätzlich neu, bekamen aber mit der
Verbreitung des World Wide Web (WWW) ab Mitte der 1990er Jahre[^12]
einen neuen Schub. Dies ist in der Natur des WWW selbst begründet. Denn
dessen Schlüsseleigenschaft ist es - seit seiner Entstehung 1989 -
Informationen system- und plattformunabhängig in einer gemeinsamen
Netzwerkinfrastruktur zu übertragen und auszutauschen.[^13] Damit
eignete es sich auch, die Forderungen der Open-Bewegung technisch zu
implementieren. Folglich werden überwiegend webbasierte Technologien in
der Open-Bewegung eingesetzt, insbesondere die des Web 2.0, welche die
Interaktionsmöglichkeiten im digitalen Raum erheblich erweiterten.[^14]
Eine wichtige Voraussetzung für viele heutige Open (Science) Projekte
war zudem, dass die Technologien hinter dem WWW selbst von Anfang an
offen waren, diese also (kosten)frei für jeden zur Verfügung standen und
von jedem genutzt werden konnten.[^15]

Die Open Science-Bewegung kann in diesem Kontext als Weiterentwicklung
der vor 20 Jahren gegründeten Open Access-Bewegung gesehen werden, in
der sich Wissenschaftler\*innen 2002/2003 zusammengeschlossen haben, um
offenen Zugang zu wissenschaftlichen Forschungsergebnissen zu
fördern.[^16] Daneben umfasst die Open-Bewegung unter anderem Open
Knowledge, Open GLAM, Open Government, Open Design, Open Innovation,
wobei es eine trennscharfe Abgrenzung nicht gibt. So lässt sich Open
Data auch als Querschnittsbereich auffassen, der in andere Bereiche wie
Open Science hineinreicht.[^17]. Eine Vertreterin der ersten Stunde der
Open-Bewegung und die wohl populärste ist die gemeinnützige Wikimedia
Foundation, Inc. (WMF)[^18] mit Sitz in den USA.[^19] Bereits seit 2001
stellt sie digitale Dienste kostenfrei zur Verfügung, mit denen Wissen
offen ausgetauscht und geteilt werden kann. Ihr bekanntestes und
ältestes Projekt ist die freie Enzyklopädie *Wikipedia*[^20]. Die WMF
engagiert sich aber nicht ausschließlich mit der Wikipedia in der
Open-Bewegung, sondern hat inzwischen eine Vielzahl an digitalen
,,Schwesternprojekten"[^21] Daneben stellt sie eine Reihe ihrer
MediaWiki Software-Komponenten in Open Source zur Verfügung.[^22] Eine
weitere und mit der WMF koopierende Organisation in der Open-Bewegung
ist die Open Knowledge Foundation (OKF), die 2005 in London gegründete
wurde[^23] und von der es seit 2011 auch einen deutschen Ableger in
Berlin gibt.[^24]. Die OKF hat unter anderem das Open
Source-Datenmanagementsystem *ckan*[^25] entwickelt, mit dem
Datenkollektionen verwaltet und als Open Data-Portale veröffentlicht
werden können. Der Fokus liegt hierbei auf Politik, öffentlichen
Verwaltungen und (privatwirtschaftlichen) Unternehmen.

Beide hier vorgestellten Initiativen engagieren sich ebenfalls in der
Open Science. An der deutschsprachige OKF hat sich die Arbeitsgruppe
Open Science gegründet, die wiederum von der Wikimedia Deutschland
unterstützt wird.[^26] In der offenen AG kommen unterschiedliche Akteure
aus der Wissenschaft zusammen, die gemeinsam Open Science-Ziele für die
Wissenschaft formulieren.[^27] Die Wikimedia Deutschland gibt die
Blogreihe „Freies Wissen und Wissenschaft" heraus, in der bisher Stärken
und Vorteile von Open Science für die traditionelle Wissenschaft
herausgearbeitet wurden.[^28] Außerdem hat sie zwischen 2016 und 2021
das interdisziplinäre Fellow-Programm *Freies Wissen* durchgeführt, mit
dem Nachwuchswissenschaftler\*innen bei der Integration von Open Science
in das eigene Forschungsprojekt gefördert wurden.[^29] Mit diesem
Zugriff auf die Wissenschaft war der Effekt des Programms auch, dass
Open Science-Multiplikatoren ausgebildet wurden, die die Idee und Praxis
von Open Science in wissenschaftlichen Einrichtungen und Communities
verbreiten und festigen.[^30]

### Definition

Eine allgemeingültige Definition von Open Science, die hier eins zu eins
übernommen werden kann, existiert nicht.[^31] Erschwerend kommt hinzu,
dass ebenfalls die Begriffe Open Research oder Open Scholarship oft,
aber nicht immer synonym verwendet werden.[^32] Hieraus ergibt sich ein
Definitionsproblem für diese Arbeit, das sich aus dem IST-Stand von Open
Science ergibt. Denn entsprechende Verfahren und Strukturen sowohl auf
der technischen als auch auf der organisatorischen Ebene haben sich
schlichtweg noch nicht etabliert. Zwar gibt es - wie der vorherige
Abschnitt gezeigt hat - ein großes Bekenntnis zu Open Science, doch die
feste Verankerung in das bestehende Wissenschaftssystem ist noch nicht
erfolgt. Erst aber in diesem Prozess wird sich Open Science abschließend
konsolidieren.

Daher wird sich in dieser Arbeit in erster Linie an den sogenannten Open
Science-Grundsätze orientiert, die den Handlungsrahmen vorgeben. Auf
diese berufen sich auch die recherchierten Initiativen. Sie können wie
folgt zusammengefasst werden: Während von wissenschaftlicher Seite
insbesondere Transparenz, offene Kommunikation, Kollaboration,
Reproduzierbarkeit und Wiederverwendbarkeit in der Forschung betont
wird, ist es von der Open-Bewegung her vor allem öffentliche
Partizipation, die zentral ist. Open Science wird als moderne
Wissenschaftspraxis gesehen, die traditionelle Wissenschaft dort
transformiert, wo es - wie die Replikationskrise gezeigt hat - notwendig
ist. Das primäre Ziel ist es, durch Open Science Reliabilität von
Wissenschaft zu stärken, Qualität von Forschung im digitalen Zeitalter
zu steigern und Wissenschaft selbst zu demokratisieren.[^33] Eine
wichtige Eigenschaft dieser Grundsätze ist zudem, dass sie generisch,
das heißt über alle wissenschaftlichen Domänen hinweg gültig sind.[^34]
Von daher spricht Open Science nicht allein die lebens- und
naturwissenschaftlichen Bereiche, sondern gleichermaßen auch die
geisteswissenschaftlichen an und deren Grundsätze sind folglich auch auf
die hier betrachteten Forschungsdaten zu jüdischen Gewerbebetrieben
anwendbar.

Es wird abschließend deutlich, dass es *die* Open Science nicht gibt und
in welcher konkreten Form Open Science sich am Ende durchsetzen wird,
muss in dieser Arbeit offen bleiben. Letztendlich hängt diese
Entwicklung stark vom Selbstverständnis der jeweiligen Initiatve,
Einrichtung oder des jeweiligen Wissenschaftsbereichs sowie von anderen
Variablen wie rechtliche oder forschungsethische Rahmenbedingungen ab.
Es ist vorstellbar, dass sich Open Science unter der gemeinsamen Klammer
der Open Science-Grundsätze zukünftig weiter ausdifferenzieren wird und
unterschiedliche Grade nebeneinander existieren werden. Für das offene
Forschungsdatenmanagement bedeutet diese Situation, dass mit Open
Science keine globale Spezifikation vorliegt, die umgesetzt werden muss,
sondern Spielraum bei der Integration von Open Science-Ansätzen besteht.
Umso mehr ist diese vom konkreten Kontext der Forschungsdaten abhängig
und weniger.

### Konzepte und Infrastrukturen

##### Konzepte

In Bezug auf Konzepte von Open Science wird häufig der *Umbrella Term*
herangezogen, um die verschiedenenen Handlungsfelder in der Wissenschaft
zu veranschaulichen and damit die Dimensionen von Open Science zu
verdeutlichen (Abb. 2.1.).

Die Europäische Kommission zum Beispiel definiert für das große
EU-Infrastrukturprojekt ,,European Open Science Cloud" (EOSC)[^35],
welche im Rahmen des Langzeitprogramms *Horizon Europe* aufgebaut
wird[^36], sechs Handlungsfelder - wie aus der Abbildung 2.1.
hervorgeht. Dabei kombinieren die Handlungsfelder Praktiken aus der
traditionellen Wissenschaft mit den Open Science-Grundsätzen und
entwickeln daraus Lösungskonzepte für die wissenschaftliche Forschung
nach Schwerpunkten. Open Data-Konzepte unter dem Dach der Open Science
zum Beispiel konzentrieren sich auf den wissenschaftlichen Umgang mit
den im Forschungsprozess anfallenden digitalen Forschungsdaten, während
sich Open Access-Konzepte mit Fragen des freien Zugangs zu diesen und
sonstigen wissenschaftlichen Materialen beschäftigen. Citizen
Science-Konzepte entwickeln Lösungen, wie unter Beibehaltung
wissenschaftlicher Integrität Partizipation an Wissenschaft gestärkt
werden kann.[^37]

Die Handlungsfelder können voneinander abweichen, wie ein Blick auf die
Abbildung 2.2 zeigt. Die Abweichungen zwischen beiden Abbildungen lassen
den Schluss zu, dass es ganz ähnlich zum Open Science-Grad letztlich vom
konkreten (wissenschaftlichen) Kontext abhängt, welche Handlungsfelder
unter Open Science definiert werden und es hier folglich eine strenge
Vorgabe nicht gibt. Schließlich hängt diese Definition auch davon ab, wo
und ob überhaupt Handlungsbedarf für Open Science gesehen wird. Dass die
Replikationskrise dringenden Handlungsbedarf vorwiegend in den Lebens-
und Naturwissenschaften offenbart hat, heißt nicht, dass dieser
gleichermaßen auch in geisteswissenschaftlichen Fächern gesehen wird, wo
vorwiegend hermeneutische Forschungsmethoden angewandt werden, die sich
fundamental von den statistisch empirschen der Naturwissenschaften
unterscheiden. Das bedeutet im Umkehrschluss, dass Handlungsbedarf
gegebenenfalls erst noch geschaffen werden muss.

##### Infrastrukturen

Anhand der gegenwärtigen fachübergreifenden Anwendungsmöglichkeiten von
Open Science in der eigenen Forschung können grob drei Gruppen von
Infrastrukuren unterschieden werden: 1. zentrale, 2. dezentrale und 3.
nachgenutzte Infrastrukturen:

1.  Begleitend zur Reproduzierbarkeitsstudie des COS wurde das *Open
    Science Framework* (OSF)[^38] entwickelt, das im Hintergrund eine
    zentrale IT- Infrastruktur über eine Plattform bereitstellt, die
    bekannte Open Science Verfahren wie Präregistrierung, Preprints und
    Generierung von Permalinks ermöglicht. Zum Funktionsumfang gehören
    außerdem Projektversionierung sowie ein generisches Repositorium zum
    Speichern und Aggregieren multipler Inhalte unterschiedlicher
    Formaten. Im veröffentlichten, diese Arbeit von Beginn an
    begleitenden, OSF-Projekt ,,Master thesis: Open Science in
    History?"[^39] wurde zum Beispiel die LaTex-Version der
    schriftlichen Arbeit, welche mit Git versioniert und auf GitHub
    zugänglich ist, und die Zotero-Library mit der verwendeten Literatur
    über die Add-ons-Funktionalität sowie die prototypische
    Wikidata-Lösung für offenes Forschungsdatenmanagement als Komponente
    dem Projekt hinzugefügt. Lokal gespeicherte Materialien wie die
    Interviewtranskripte (.pdf), der Fragebogen (.pdf) und die
    Literaturauswertung (.csv) wurden manuell hochgeladen. Dafür stehen
    verschiedenen Server zur Verfügung, darunter auch in Deutschland
    (Frankfurt am Main). Heterogene Dienste und verteilte Ressourcen
    können also im OSF zusammengeführt und dort synchron gehalten
    werden. Damit ist das OSF im Kern ein Projektmanagement-Tool, das
    durch eine homogen gestaltete kollaborative Arbeitsumgebung
    Wissenschaftler\*innen dabei unterstützt, ihr methodisches Vorgehen
    transparent zu machen sowie Workflows zu automatisieren und dadurch
    systematisch Open Science über den gesamten Forschungsprozess zu
    praktizieren.[^40] Dass das OSF steigende Anwenderzahlen
    insbesondere durch akademische Einrichtungen in den USA
    verzeichent,[^41], weist darauf hin, dass es das Potential hat, sich
    zu einem Standard zu entwickeln. Eine mögliche negative Nebenfolge
    dieser Entwicklung ist die Entstehung einer Plattformabhängikeit,
    die anderen gesellschaftlichen Bereichen inzwischen kritisiert wird
    und gegen die sich Widerstand regt.[^42] Freilich steht hinter der
    Plattformökonomie selbst kein Automatismus und es nicht gesagt, dass
    das OSF irgendwann in einer Reihe mit den großen US-amerikanischen
    Digitalkonzernen[^43] stehen wird. Dennoch bleibt festzuhalten, dass
    das COS, als zentraler Akteur hinter dem OSF, mit seiner Plattform
    Gestaltungsmacht in der Frage hat, was Offenheit in der Wissenschaft
    bedeutet. Diese Macht wird mit steigenden Nutzerzahlen wachsen.

2.  Eine etwas andere Entwicklung ist derzeit auf europäischer Ebene zu
    beobachten, wo es ein zentrales und globales Infrastrukturangebot,
    wie das OSF, nicht gibt. Zwar existieren einzelne fachübergreifende
    Projekte wie zum Beispiel das Repositorium *Zenodo* (seit
    2016)[^44], doch ist dieses Infrastrukturangebot funktional auf die
    Archivierung und Zugänglichkeit einzelner digitaler Ressourcen
    zugeschnitten[^45], die wiederum von ,,Communities" kuratiert werden
    können[^46]. Auf die Masterarbeit angewandt, konnte das
    GitHub-Repositorium mit der Versionierung hier nicht - analog zum
    OSF - eingebunden und synchronisiert werden. Zenodo bietet aber die
    Möglichkeit, automatisiert den jeweils aktuellen Repo-Release von
    GitHub als verpackte .zip-Archivdatei hochzuladen und zu
    veröffentlichen.[^47] Der erste Release dieser Arbeit erfolgte aber
    üblicherweise erst mit deren Abgabe und damit in der finalen Phase
    des Enstehungsprozesses. Das ist kein Beleg, aber ein Indiz dafür,
    dass der Schwerpunkt in Zenodo auf *publizierbaren* Ressourcen
    liegt. Diese Vermutung wird auch von einer Stichprobenauswertung zur
    Nutzung von Zenodo in dessen globaler Suche nach ,,Datasets" und
    ,,Publications \| Articles" gestützt.[^48] Auf GitHub bezogen,
    besteht der Hauptunterschied zum OSF darin, dass Zenodo bis auf
    Releases keine Services zur Integration automatisierter Workflows im
    Portfolio hat. Wer mit Zenodo konsequent Open Science
    phasenübergreifend praktizieren will, muss dies über manuell
    iteratives Hochladen von Ressourcen machen. Mit der *European Open
    Science Cloud* (EOSC, seit 2018)[^49] gibt es allerdings aktuell ein
    großes europäisches Infrastrukturprojekt, das zum Ziel hat, Dienste,
    Daten und andere Ressourcen ,,from a wide range of national,
    regional and institutional public research infrastructures across
    Europe"[^50] über das *EOSC Portal*[^51] zentral zu verzeichnen, die
    wiederum von EOSC-Nutzer\*innen in eigenen Projekten verwaltet
    werden können. Der Unterschied zum OSF besteht hauptsächlich darin,
    dass die EOSC kein Infrastrukturangebot ist, auf der individuell
    Open Research praktiziert werden kann. Die EOSC ist selbst nur
    Aggregator bereits existierender Angebote, registriert und vernetzt
    diese miteinander. Sie ist mehr Verzeichnes als Plattform, das
    Sichtbarkeit und Recherchierbarkeit dezentraler Infrastrukturen
    ermöglicht. Die Möglichkeiten der Interkation sind daher auf diese
    Zwecke beschränkt.[^52]

3.  Neben dem Aufbau neuer Infrastrukturen für die Wissenschaft gibt es
    außerdem den Ansatz, bestehende und etablierte Infrastrukturen aus
    der weiter gefassten Open-Bewegung nutzbar zu machen. Hervorzuheben
    sind die Angebote der Wikimedia Foundation, die sich, wie in Kapitel
    2.1.1 beschrieben, mit dem ,,Fellow-Programm Freies Wissen" bereits
    aktiv in die Open Science-Bewegung eingebracht hat. Aktuell laufen
    unterschiedliche Projekte, die das sogenannte Wiki\*versum in der
    wissenschaftlichen Forschungsarbeit nutzen. Aus dem Fellow Programm
    stammt das Wiki\*versum-Projekt *Die Datenlaube*, wo das Massenblatt
    ,,Die Gartenlaube -- Illustrirtes Familienblatt" aus dem 19.
    Jahrhundert mittels Commons, Wikisource und Wikidata kollaborativ
    erschlossen und analysiert wurde.[^53] Ein weiteres, nicht aus dem
    Fellow Programm stammendes Projekt ist die *Bamberger
    Islam-Enzyklopädie*. Bei diesem wurde wissenschaftlich betreut in
    der deutschsprachigen Wikipedia eine Enzyklopädie zum Themenbereich
    Islam aufgebaut und wird in der Fortsetzung kollaborativ
    ergänzt.[^54] Vorteilhaft bei den Wiki\*versum-Lösungen ist die
    Ausnutzung von Synergieeffekten. Die Wissenschaft kann die
    langjährigen Erfahrungen der Wikimedia bei der Implementierung von
    Offenheitskriterien für sich nutzen und deren Tools frei verwenden.
    Umgekehrt können dadurch gleichzeitig fundierte Erkenntnisse aus der
    wissenschaftlichen Forschung effizient in die Öffentlichkeit
    transferiert und das Wissen im Wiki\*versum dadurch für alle
    verbessert werden. Die Projekte zeigen schließlich auch, dass
    vorhandene offene Infrastrukturen für die wissenschaftliche
    Forschung adaptiert und damit nutzbar gemacht werden können. Mit dem
    großen Angebotsspektrum bietet sich zudem für viele Open
    Sciene-Handlungsfelder eine Nutzungsoption. Auch wenn sich die WMF
    im Bereich der Open Science engagiert, bleibt alledings abschließend
    anzumerken, dass deren Angebote nicht auf die Bedürfnisse der
    Wissenschaft zugeschnitten sind, sondern in erster Linie dem
    Grundsatz des freien Wissens für alle folgen. Daher muss für jedes
    Projekt individuell evaluiert werden, inwiefern hier ein oder
    mehrere Wikimedia-Angebote für die eigene Forschungsarbeit in Frage
    kommen.[^55]

Der Blick auf die Infrastrukturebene zeigt, dass die Möglichkeiten von
offener Wissenschaft stark von den Infrastrukturen im Hintergrund
abhängen. Letztendlich manifestiert sich in ihnen der Grad an Open
Science, der am Ende von Forschenden praktiziert werden kann. Daher ist
es nicht nur auf der Konzept-, sondern auch auf der Infrastrukturebene
wichtig, Bedarfe und Standards für die wissenschaftliche Forschung zu
formulieren. Seitens der Anbieter von Open Science-Infrastrukturen
müssen diese Anforderungen aufgenommen und umgesetzt werden. Sie stehen
hier in der Verantwortung, mögliche Machtgefälle und Abhängikeiten
fortlaufend zu reflektieren und zu kommunizieren, das heißt sich die
Frage nach Vertrauenswürdigkeit und Legitimation immer wieder neu zu
stellen. In diesem Zusammenhang wurden bereits die *TRUST Principles*
formuliert, die Transparency, Responsibility, User focus, Sustainability
and Technology als Rahmenbedingungen bei der Infrastrukturentwicklung
vorgeben.[^56]

## Forschungsdatenmanagement

Die historischen Daten zu jüdischen Gewerbebetrieben zeigen
exemplarisch, dass digitale Forschungsdaten längst Bestandteil auch in
der Forschungsarbeit von Historiker\*innen geworden sind. Mit ihnen
rücken in den Geschichtswissenschaften (neue) computergestützte
qualitative wie quantitative Analyse- und Auswertungsverfahren in den
Fokus.[^57]

Wenn aber Forschungsdaten epistemologisch an Bedeutung für die
Wissenschaft im Allgemeinen und für die Geschichtswissenschaften im
Besonderen gewinnen, dann stellen sich unweigerlich Fragen nach dem
wissenschaftlichen Umgang mit ihnen. Daraus wurde sowohl auf
wissenschaftlicher als auch auf politischer Ebene bereits die
Notwendigkeit eines nachhaltigen Forschungsdatenmanagements (FDM)
abgeleitet, welches sich mit der Gestaltung wissenschaftlicher
Standards, Workflows und Best Practices zur Handhabung von digitalen
Forschungsdaten im Forschungsprozess und darüber hinaus auf
methodischer, konzeptioneller, organisatorischer und technischer Ebene
beschäftigt.[^58] FDM ist dabei kein Selbstzweck, sondern will
phasenübergreifende Qualität von Forschung auch im digitalen Zeitalter
weiterhin sicher stellen. Ziel von FDM ist es zudem, Datentransfer und
Datennutzung zu fördern. Damit rekurriert es direkt auf Open
Science-Grundsätze der Transparenz, Kollaboration und
Wiederverwendbarkeit. Auch wenn Forschungsdatenmanagement den
,,Openess"-Gedanken nicht im Namen trägt, so sind die Anknüpfungspunkte
an Open Science offentsichtlich, die sich auch in den *FAIR Principles*
manifestieren, die in Kapitel 2.2.2 näher erläutert sind. Von daher ist
es naheliegend Forschungsdatenmanagement und Open Science
zusammenzudenken, was im wissenschaftlichen Diskurs und in der Praxis
bereits passiert.[^59]

Klar ist, dass diese Aufgabe allein auf individueller Ebene nicht
bewältigt werden kann, sondern dafür entsprechende Infrastrukturen und
Dienste bereitgestellt werden müssen. Aktuell gibt es nationale
Anstrengungen wie die ,,Nationale Forschungsdateninfrastruktur (NFDI)"
am Bundesministerium für Bildung und Forschung (BMBF), die in dieser
offenen Situation die Entwicklung von Lösungsstrategien massiv fördern
und dadurch vorantreiben wollen.[^60] Diese deutsche Initiative geht
zurück auf die Bund-Länder-Vereinbarung zu Aufbau und Förderung einer
Nationalen Forschungsdateninfrastruktur (NFDI) vom 26. November 2018, in
der ein Förderzeitraum von 2019 bis 2028 und eine jährlich Fördersumme
von 90 Millionen Euro für jährlich 30 Forschungsverbünde (sogenannte
Konsortien) vorgesehen sind.[^61] Mit der Durchführung wurde die
Deutsche Forschungsgemeinschaft (DFG) beauftragt.[^62] Zur
organisatorischen Koordination auf der wissenschaftlichen Ebene hat sich
2020 der Verein Nationale Forschungsdateninfrastruktur (NFDI) e.V.
gegründet.[^63] Aus der aktuell veröffentlichten statistischen Übersicht
der DFG geht hervor, dass in der dritten Antragsrunde, die zum Zeitpunkt
des Verfassens dieser Arbeit noch lief, auch geschichtswissenschaftlich
arbeitende Fachdisziplinen mit dem Titel ,,NFDI4Memory - Konsortium für
historisch arbeitende Geisteswissenschaften" vertreten sind.[^64] Zudem
ist seit 2019 die Website <https://4memory.de/> online, auf der zum
Vorhaben und über aktuelle Aktivitäten informiert wird. Auch der
*Verband der Historiker und Historikerinnen in Deutschland* (VHD)
engagiert sich in NFDI4Memory.[^65], das - sollte es positiv beschieden
werden - im Januar 2023 an den Start gehen könnte.[^66]

Festzuhalten bleibt abschließend, dass Handlungsbedarf für
Forschungsdatenmanagement mehrheitlich auf allen Eben erkannt und die
Weichen zur Umsetzung von FDM gestellt wurden. Deutlich geworden ist
jedoch auch, dass sich die notwendigen Infrastrukturen dafür gegenwärtig
noch im Aufbau befinden.

### Forschungsdaten und Forschungsdatenlebenszyklus

Gegenstand von Forschungsdatenmanagement sind Forschungsdaten. Generell
sind damit digitale Ressourcen gemeint, die im Zuge wissenschaftlicher
Forschungsarbeit erzeugt werden. Aber nicht alle Daten aus dem
Forschungsprozess sind Forschungsdaten. Als Abgrenzungskriterium gilt,
dass Forschungsdaten Grundlage von Forschungsergebnissen bilden, also
einen epistemologischen Wert für die wissenschaftliche Forschung haben.
Welche Daten genau darunter fallen, ist in jedem Forschungsvorhaben
indiviuell zu definieren.[^67] Im Zusammenhang mit dieser Arbeit sind
zum Beispiel die Audiodateien der Experteninterviews, die zugehörigen
Transkripte und das Codesystem eindeutig als Forschungsdaten zu
klassifizieren, wohingegen die E-Mail-Nachrichten mit den
Terminabsprachen für die Interviews nicht darunter gezählt werden
würden, da sie für die Erkenntnisgenerierung nicht relevant waren. Das
bedeutet aber nicht, dass E-Mails per se keine Forschungsdaten sein
können. Wie nun schon mehrfach festgestellt, ist diese Einstufung
kontextabhängig.

Forschungsdaten durchlaufen in der Regel einen mehrstufigen Prozess der
Erhebung/ Erfassung, Verarbeitung, Analyse und Visualisierung sowie
Veröffentlichung. Um eine wissenschaftlich korrekte Handhabung in jeder
dieser Phasen zu garantieren, orientiert sich FDM an einen
idealtypischen Forschungsdatenlebenszyklus (Abb. 2.3).

An sich hält dieser Zyklus keine fundamental neue Information für die
Wissenschaft bereit. Vor allem die ersten vier Phasen entsprechen den
vertrauten und etablierten Phasen im Forschungsprozess. Neu hingegen
sind die letzten zwei Phasen der Datenarchivierung und -nachnutzung,
denn hier geht FDM über den traditionellen Forschungsprozess hinaus.
Forschungsdaten sollen über die Laufzeit von Forschungsprojekten hinaus
langfristig verfügbar und nachnutzbar gehalten werden, sodass sie
Ausgangspunkt wieder neuer Forschungsvorhaben sein können. Dieses
,,Zurückspielen" in den Forschungsprozess als iterativer Vorgang stellt
ein zentrales Merkmal von Forschungsdatenmanagement dar.

### FAIR Data Principles und Open Data

Qualitätskriterien zum wissenschaftlichen Umgang mit Forschungsdaten
werden durch die
***F**(indable)**A**(ccessible)**I**(nteroperable)**R**(e-usable)
Principles* klar definiert. Sie wurden im Jahr 2016 erstmals
veröffentlicht[^68] und gehen auf einen Workshop des *Lorentz Workshop
Centers* an der Universität Leiden (Niederlande) aus dem Jahr 2014
zurück.[^69] Die FAIR Data Principles haben sich seitdem zu einem Best
Practice im Umgang mit Forschungsdaten in der Wissenschaft entwickelt.
Zentral bei deren Umsetzung sind die sogenannten Metadaten, welche die
inhaltlichen Daten formal beschreiben (Daten über Daten). Sie sind
insofern essentiell, als dass sie erstens den inhaltlichen Daten den
notwendigen Kontext für eine nachträgliche Quellenkritik geben und sie
zweitens die technische Ausgangslage zur besseren Auffindbarkeit und
Interoperabilität der inhaltlichen Daten bilden.

Wie FAIR Data technisch funktioniert, ist in der Literatur und in
anderen (digitalen) Formaten inzwischen hinreichend besprochen worden
und wird im Rahmen dieser Arbeit daher nicht im Einzelnen wiederholt.
Stattdessen wird auf die bereits existenten Informationsplattformen zu
Forschungsdatenmanagement verwiesen, die auch in dieser Arbeit genutzt
wurden: Im deutschsprachigen Raum ist vor allem das Portal
forschungsdaten.info hervorzuheben, das an der Universität Koblenz
gehosted wird[^70] sowie auf das öffentliche Wiki
forschungsdaten.org[^71]. Auf internationaler Ebene gibt es die *GO Fair
Initiative* sowie das Institut *The Future of Research Communications
and e-Scholarship* (USA), welche jeweils ebenfalls eine ausführliche
Informationsplattformen zur Implementierung von FAIR Data Grundsätzen
bereitstellen.[^72]. Ziel dieser Angebotsformate ist es, praxisnah und
für unterschiedliche Wissenschaftsbereiche FDM und FAIR Data Principles
zu vermitteln.[^73]

Interessanter scheint an dieser Stelle die Frage, in welchem Verhältnis
FAIR Data zu Open Data stehen. Denn wie in Kapitel 2.1.3 gezeigt wurde,
rekurriert Open Science nicht auf FAIR sondern auf Open Data als
Lösungskonzept. Welcher Unterschied besteht also zwischen beiden
Konzepten beziehungsweise warum ist es notwendig, neben Open Data, auch
noch FAIR Data zu formulieren. Und die entscheidenede Frage ist: Sind
die FAIR Data Principles Open Science?

Für einen Abgrenzungsversuch werden zwei Kerneigenschaften von Open Data
herangezogen. Erstens steht bei Open Data Interoperabiltät von Daten im
Zentrum. Damit verbunden ist die Hoffnung, dass durch Austausch und
Teilen konsequent offener Daten, Datensätze gänzlich neu kombiniert,
aggregiert oder verknüpft werden können, woraus wiederum neue offene
Werke jeglicher Art geschaffen werden können.[^74] Neben offener
Lizenzierung ist Voraussetzung dafür, dass die Daten in einem offenen
Format vorliegen, welche nach dem 5-Sterne-Modell des WWW-Erfinders und
Linked-Data-Initiators Tim Berners-Lee klassifiziert sind.[^75] Diese
Modell gibt zum einen eine basale Orientierung darüber, welche Formate
als ,,offen" gelten. Darunter werden vor allem nicht-proprietäre Formate
gezählt. Gleichzeitig bildet es eine Abstufung und repräsentiert damit
die möglichen Open Data-Grade. Im höchsten Grad (= 5 Sterne) können
Daten aus dezentralen Datenquellen im gesamten Web maschinell
identifiziert und verknüpft werden. Dieses Konzept wird als *Linked
(Open) Data* bezeichnet und ermöglicht, nicht mehr nur Daten, sondern
Informationen maschinell zu verarbeiten.[^76] Die Vision dahinter ist,
vom ursprünglichen Web of Documents, über ein Web of Data hin zu einem
Web of Linked Data oder auch Semantic Web zu kommen, mit Wissen digital
abgebildet, gespeichert und abgefragt werden kann.[^77] Die in FAIR Data
separat formulierten Kriterien der Auffindbarkeit, Zugänglichkeit und
Wiederverwendbarkeit von Daten werden bei Open Data vorausgesetzt, um in
der höchsten Stufe Interoperabilität zu erreichen. Allerdings können
Daten, die nicht interoperabel sind, nach dem 5-Sterne-Modell trotzdem
Open Data sein, wenn sie zum Beispiel als PDF- (= 1 Stern) oder
CSV-Files (= 2 Sterne) vorliegen. Diese Variabilität lassen die FAIR
Data Principles an dieser Stelle nicht zu. Hier reicht es streng
genommen nicht aus, wenn (Meta)Daten in Form eines PDF's oder einer CSV
für andere zugänglich aber nicht gleichzeitig für den maschinellen
Datenaustausch geeignet sind. Es ist klar, dass mit dieser Einschränkung
seitens der FAIR Data Principles in erster Linie Standards des
wissenschaftlichen Arbeitens sichergestellt werden sollen. Für diese
Arbeit ist daher zu beachten, dass Forschungsdaten Open Data sein können
ohne dabei gleichzeitig die wissenschaftlichen Kriterien der FAIR Data
Grundsätze zu erfüllen.

Zweitens geht Open Data im Allgemeinen über Open Access hinaus, zielt
also nicht nur darauf ab, freien (lesenden) Zugang zu Daten zu schaffen,
sondern dass diese gleichzeitig universell geteilt, modifiziert und neu
publiziert werden können. Das setzt eine offene Lizenz der Daten voraus,
wie sie in der ,,Open Definition" der Open Knowledge Foundation
eingefordert wird:

> The work must be in the public domain or provided under an open
> license \[\...\]. Any additional terms accompanying the work (such as
> a terms of use, or patents held by the licensor) must not contradict
> the work's public domain status or terms of the license.[^78]

Unter offener Lizenz wird demnach in erster Linie die Veröffentlichung
ohne jegliche Restriktionen oder sonstige Vorgaben verstanden. Dies
entspricht einer Veröffentlichung in Public Domain (CC0 ,,No Rights
Reserved")[^79]. Als ,,offen" gelten auch jene Lizenzen, die als einzige
Einschränkung die Namensnennung haben, aber die freie Nutzung von Daten
erlauben (CC-BY und CC-BY-SA). Alle Lizenzen, welche die Nachnutzung in
irgendeiner Form einschränken, zählen strenggenommen nicht mehr zu Open
Data,wie sie von der OKF definiert wurden.

Einen Standard für offene Lizenzen einzuführen, war und ist das
Hauptanliegen des globalen Netzwerks *Creative Commons* (CC).[^80]. Mit
den *Creative Commons licenses* stellt es allgemeingültige Lizenzen zur
Verfügung, die für eigene Inhalte einfach verwendet werden können.[^81]
Anders als die OKF nehmen sie in der Frage der Offenheit eine Abstufung
vor und kategorisieren die ,,Most Open" als *Free Cultural Works*[^82],
die mit Open Data gleichgesetzt werden können.[^83] Es werden jedoch
auch wesentlich limitiertere Lizenzen zur Verfügung gestellt. Damit
verfolgt die CC vor allem das Ziel, die ,,all rights reserved"-Lizenz,
die jegliche Nachnutzung von vornherein ausschließt, vermeidbar zu
machen und Lizenzgeber zu ermutigen, frei lizensierbare Inhalte
eindeutig zu kommunizieren.[^84]

Open Data ist demnach mit seiner Kultur der offene Lizensierung
radikaler. Damit verfolgt die Open-Bewegung vor allem auch ein
politisches Ziel. Mit steuerlich finanzierten Mitteln entstandene Daten
aus dem öffentlichen Sektor (Wetter-, Verkehrs- oder Geodaten) sollen
als Allgemeingut anerkannt und in der Konsequenz die Grundsatzziele der
Partizipation und Bürgerbeteiligung als Paradigma in der Politik
ausgestaltet werden.[^85] Die Open-Bewegung stellt sehr klar, dass
darunter personenbezogene Daten nicht gezählt werden:

> The key point is that when opening up data, the focus is on
> non-personal data, that is, data which does not contain information
> about specific individuals.[^86]

Hervorzuheben ist also, dass es ausschließlich um rechtlich
unbedenkliche Daten geht, die in der Vergangenheit kaum oder gar nicht
zugänglich waren und deren Öffnung Open Data vorantreiben will. Folgt
man dieser Argumentation weiter, müssten demnach auch alle
Forschungsdaten, die aus öffentlich finanzierten Forschungsprojekten
stammen, in offener Lizenz veröffentlicht werden. Hier wiederum sind es
die FAIR Data Principles, die in der Lizenzfrage Spielraum lassen und
dazu explizit keine Vorgabe machen. Denn aus Sicht der Wissenschaft ist
es möglich, dass forschungsethische Abwägungen oder eine eventuelle
Gefährdung der wissenschaftlichen Integrität die Veröffentlichung von
Forschungsdaten in einer Open Data-Form nicht erlauben.[^87] Daher hat
sich bei den FAIR Data Principles die Regel durchgesetzt, Daten ,,so
eingeschränkt wie nötig und so offen wie möglich" zu halten. Damit
können Forschungsdaten, deren Zugriff auf eine exklusive Gruppe oder
Domäne beschränkt ist, die FAIR Data Grundsätze vollumfänglich erfüllen
und gleichzeitig niemals Open Data sein. Dennoch kann diese Praxis zu
Open Science gezählt werden, da FAIR Data grundsätzlich
wissenschaftliche Forschung öffnet, auch wenn dies nur für eine fest
definierte Gruppe gilt. Aber auch in der Wissenschaft ist ein Trend zu
Open Data erkennbar. Mit den *Pantom Principles*, welche von der Open
Knowledge Foundation in Zusammenarbeit mit Wissenschaftlern aus den USA
und der UK initiiert wurden, soll in der Wissenschaft dafür sensibiliert
werden, Open Data systematisch auch in der wissenschaftlichen Kontext
mitzudenken.[^88]

Dieser Gedanke soll in der in dieser Arbeit aufgegriffen und eine
Strategie der Open Research Data verfolgt werden, die Konzepte FAIR Data
und Open Data kombiniert.

# Kontextualisierung und Parametrisierung

## Einordnung der Forschungsdaten

Inhaltlich sind die hier exemplarisch betrachteten Forschungsdaten zur
Vernichtung der jüdischen Gewerbetätigkeit in den größeren Themenkomplex
der wirtschaftlichen Verfolgung, Verdrängung und Vernichtung der Juden
im Nationalsozialismus eingebettet. Die ersten grundlegenden,
wissenschaftlichen Auseinandersetzungen dazu erfolgten zwar schon früh
in der BRD im Nachkriegsdeutschland.[^89] Allerdings blieben diese
vereinzelt und ohne größere Resonanz. Erst Ende der 1990er Jahren trat
in Deutschland eine längere Forschungswelle zum Thema auf, die eine
Bandbreite an Studien hervorgebracht hat. In deren Folge etablierte sich
ein eigenes Forschungsfeld zur wirtschaftlichen Existenzvernichtung der
Juden im Nationalsozialismus, in dem vor allem lokal- und
regionalgeschichtliche Zugänge dominieren.[^90] Es lieferte innerhalb
der NS-Forschung weitere Erklärungsansätze zur antisemitischen
Verfolgungs- und Vernichtungspolitik, deren Antriebskräfte in der
Vergangenheit unterschiedlich interpretiert wurden.[^91] Hierbei waren
lange nationalsozialistische Akteure, kommunale Verwaltungsinstanzen und
nicht-jüdische Nutznießer sowie deren Strategien, Verhalten und
Handlungsoptionen Schwerpunkt der Forschung. Diese Fokussierung wurde in
zunehmendem Maß als zu einseitig kritisiert, da insbesondere die
jüdischen Betroffenen ganz ausgeblendet oder sie ausschließlich als
passive Opfer gezeigt worden seien. Zudem entwickelte sich langsam ein
wissenschaftlicher Diskurs über die Anwendung historischer
Begrifflichkeiten in der Forschung.[^92] Im Zentrum stand hierbei die
Kritik, dass die meisten Studien die Bandbreite und Komplexität des
Forschungsthemas unter dem diffusen Begriff ,,Arisierung" untersuchten
und diesen dabei unterschiedlich ausdehnten.[^93] Häufig lag der
Schwerpunkt der Untersuchung jedoch auf jüdischen Unternehmern und der
Übernahme deren Eigentums[^94], wodurch die historische Forschung
zuweilen Schlagseite erlitt, da andere Aspekte der wirtschaftlichen
Existenzvernichtung wie zum Beispiel die Verdrängung von Juden aus ihren
Berufen unterbelichtet blieben.[^95] Zusammengefasst war der Einwand,
dass die bisher verwendeten Untersuchungsbegriffe ,,engführend"[^96]
dahingehend seien, das Geschehene nur einseitig zu rekonstruieren, zu
dessen gesamtheitlicher Analyse folglich nicht taugen.[^97]

Ab Mitte der 2000er Jahre lässt sich daraufhin eine Weiterentwicklung
beobachten, die vor allem von größeren universitären Forschungsprojekten
vorangetrieben wurde und die mit der Verschiebung in der
Forschungsperspektive sowie der begrifflichen Ausdifferenzierung einher
ging.[^98] Die neueren Studien unterschieden sich im Wesentlichen
dadurch, dass sie die jüdischen Betroffenen als handelnde Akteure
begriffen und deren *agency* in den Blick nahmen. Außerdem versuchten
sie erstmals mit den Begriffen ,,Arisierung" oder ,,Entjudung" zu
brechen[^99] und Phänomene des Forschungsthema durch eine
wissenschaftliche Terminologie zu benennen. Dabei wurde ein
prozessorientierter Zugang gewählt, der an die Holocaust-Forschung des
US-amerikanischen Historikers Raul Hilberg anknüpfte. Hilberg
analysierte den Massenmord an den Juden wegweisend als einen Prozess,
der über Definition, Kennzeichnung, Enteignung, Konzentration und Mord
mehrstufig verlief.[^100] Als integraler Bestandteil dieses Prozesses
wurde die Vernichtung der wirtschaftlichen Existenz der Juden im
Nationalsozialismus als ein mehrschichtiger Gesamtprozess analysiert,
der sich aus den abgrenzbaren, aber überlagernden und in
Wechselbeziehung stehenden Teilprozessen Verdrängung, Besitztransfer,
Liquidation und Vermögensentzug zusammensetzte. Diese schlossen folglich
die Verdrängung der Juden aus dem Berufsleben, die Vernichtung der
jüdischen Gewerbetätigkeit durch Besitzübernahme oder Liquidation sowie
die Entziehung des Vermögens der Juden ein.[^101]

Mit diesem Forschungsansatz konnte zum einen anhand der drei deutschen
Großstädte Berlin, Frankfurt am Main und Breslau empirisch gezeigt
werden, dass die als jüdisch verfolgten Unternehmen nicht - wie bisher
durch die Schwerpunktsetzung der historischen Forschung suggeriert -
größtenteils in den Besitz nichtjüdischer Erwerber\*innen übergingen,
sondern schlichtweg liquidiert wurden.[^102] Diesbezüglich lag der
Erkenntnisfortschritt in der Freilegung des Teilprozess der Vernichtung
der jüdischen Gewerbetätigkeit als ein ,,großangelegtes
Liquidationsprogramm", das bisher kaum als solches von der historischen
Forschung reflektiert worden war.[^103] Des Weiteren wurde durch den
Wechsel der Forschungsperspektive systematisch herausgearbeitet, dass
sich die jüdischen Betroffenen gegen ihre Entrechtung wehrten und dazu
verschiedenen institutionelle wie individuelle Strategien nutzten.[^104]

An diesen Forschungsstand anknüpfend unternahm zuletzt der Historiker
Benno Nietzel im Jahr 2009 den Versuch, die zahlreichen
Forschungsstudien zur Vernichtung der wirtschaftlichen Existenz der
Juden im Nationalsozialismus zu ordnen, indem er die bisherigen
Forschungsfragen, Untersuchungsgegenstände sowie Forschungsergebnisse
zusammenfasste und strukturierte. Er diagnostizierte dem Forschungsfeld
im Großen und Ganzen weiterhin methodisch-konzeptionelle Probleme
aufgrund undifferenzierter Zugänge[^105] und folglich eine ,,analytische
Hilflosigkeit angesichts der Vielschichtigkeit und Komplexität des
Prozesses \[der wirtschaftlichen Existenzvernichtung der Juden, Anm.
S.E.\]", die Erkenntnisfortschritt im Forschungsfeld hemmen.[^106]

## Kriterien des offenen Forschungsdatenmanagements

Nachdem der historiographische Kontext der Forschungsdaten zu jüdischen
Gewerbebetrieben klar ist, können darauf aufbauend die drei Kriterien
,,anschlussfähig", ,,projektübergreifend" und ,,partizipativ" entwickelt
werden, welche die Anknüpfungspunkte für Open Science-Ansätze darstellen
und das *offene* Forschungsdatenmanagement im Forschungsfeld
spezifizieren.

### Anschlussfähig

Wenn die wirtschaftliche Existenzvernichtung der Juden als ein
abgrenzbares Forschungsfeld definiert ist, dann lässt es sich folglich
für eine differenzierte Unterschung abstecken. Nach Nietzel kann dies in
fünf Teilbereichen erfolgen:[^107]

-   Verdrängung der Juden aus dem Berufsleben (Angestellte, Beamte,
    Selbstständige wie Rechtsanwälte, Ärzte oder Wissenschaftler)

-   Vernichtung der jüdischen Gewerbetätigkeit (Besitztransfer und
    Liquidation)

-   staatliche Enteignung des jüdischen Vermögens (Privatbesitz,
    Firmenvermögen, Immobilienvermögen aus Grundbesitz)

-   Entgrenzung (transnationale Perspektiven)

-   Wiedergutmachung nach 1945 in der BRD

Zwar betonte Nietzel deren überschneidende Beziehungen und Verhältnisse
zueinander, nahm aber in erster Linie eine separierte Betrachtung zum
Zwecke der inhaltlichen Erschließung und zur Herausarbeitung von
Spezifika des Forschungsthemas vor.[^108]

Neben den bereits erläuterten Teilprozessen ordnete Nietzel dem
Forschungsfeld außerdem die historisch untrennbare materielle
Wiedergutmachung nach 1945 in der BRD zu, welche zum einen die
Restitution/ Rückerstattung und zum anderen die Entschädigung meint.
Hiervon ausgenommen ist die Entziehung und die Restitution von
Kulturgütern, die Nietzel dem eigenen Forschungsfeld der
Provenienzforschung zuordnete.[^109] Im Falle der Entgrenzung vor allem
nach Kriegsbeginn geht um die europaweite Perspektive der
wirtschaftlichen Existenzvernichtung. Im Sinne des transnationalen
Forschungsansatzes stehen dabei der Transfer von Erfahrungswissen und
der Export von Verfolgungspraktiken sowie deren Weiterentwicklung in den
besetzten Gebieten im Fokus. Auch Kollaboration und die Rolle von
deutschen Unternehmen bei der Ausplünderung der europäischen Juden
werden in den Blick genommen.[^110]

Nietzels Systematisierungsversuch wurde bisher auffallend wenig von der
historischen Forschung rezipiert.[^111] Lediglich der Historiker
Christoph Kreutzmüller nahm 2016 darauf Bezug und ergänzte den neuesten
Forschungsstand zur Vernichtung der jüdischen Gewerbetätigkeit.[^112]
Auch wenn dieser eine deutliche Professionalisierung darstellt, weil
erstmals unter Einbeziehung aller relevanten Forschungsstudien
konzeptionell mit dem komplexen Forschungsthema auseinandergesetzt
wurde, so bleibt festzuhalten, dass der Begriff ,,Arisierung" als
Untersuchungsbegriff in der historischen Forschung nach wie vor zur
Anwendung kommt.[^113]

Diese Situation ist für das offene Forschungsdatenmanagement insofern
problematisch, als dass sich mit ,,Arisierung" (oder auch ,,Entjudung")
auf der technischen Ebene nicht arbeiten lässt, da eine
widerspruchsfreie Abbildung und Beschreibung des unpräzisen Begriffs in
Form eines Datenmodells nicht möglich ist. Eine kritische Reflexion
reicht, wie es in den meisten Studien gehandhabt wird, hier nicht aus,
da die technische Implementierung an sich zur Differenzierung zwingt.
Als derzeit einzige Möglichkeit bietet sich an dieser Stelle der
Systematisierungsversuch des Historikers Nietzel an, der in dieser
Arbeit methodisch als Taxonomie aufgegriffen wird. Sichtbar wird damit
auch, dass die Forschungsdaten zu den jüdischen Gewerbebetrieben
inhaltlich lediglich einen kleinen Ausschnitt aus dem Gesamtkomplex der
wirtschaftlichen Existenzvernichtung der Juden im NS abbilden, diesen
also nur teilweise repräsentieren. Zudem ist das zugehörige
Forschungsfeld Teil der umfassenden NS-Forschung und knüpft insbesondere
an die Holocaust-Forschung an.

Das Forschungsdatenmanagement ist folglich inhaltlich offen, das heißt
es muss neben der Vernichtung der jüdischen Gewerbetätigkeit
anschlussfähig erstens an alle angrenzenden Untersuchungbereiche im
Forschungsfeld sein und muss zweitens in der Entwicklungsperspektive
auch an benachbarte Forschungsfelder der Verfolgung und Vernichtung im
Nationalsozialismus andocken können.

### Projektübergreifend

Im Forschungsfeld dominieren lokal- bzw. regionalgeschichtliche
Studien.[^114] Da sich die historische Forschung, wie oben erläutert,
früh auf die Vernichtung der jüdischen Gewerbetätigkeit in Deutschland
konzentriert hat, ist diese Entwicklung wissenschaftlich begründet. Denn
die systematische Vernichtung erfolgte erst ab 1938 mit der Einführung
reichsweiter Gesetze und Regelungen.[^115] Das heißt, dass die jüdische
Gewerbetätigkeit für die nationalsozialistische Wirtschaftspolitik erst
spät auf dem Plan stand.[^116] Anders sah es hingegen in der politischen
Peripherie aus, wo bereits ab 1933 mit den Aprilboykotten jüdische
Gewerbebetriebe gezielt verfolgt wurden und in deren Folge jüdische
Gewerbebetriebe verschwanden. Es waren insbesondere also lokale Akteure
gewesen, die den Vernichtungsprozess vorangetrieben hatten. Auch nach
1938 waren sie es, die die reichsweiten Gesetze und Bestimmungen
umsetzten. Es ist daher wenig überraschend, dass die Wissenschaft
überwiegend den lokalhistorischen Zugang gewählt hat, da in einer
Überblicksdarstellung für Deutschland die Vernichtung der jüdischen
Gewerbetätigkeit unmöglich in der notwendigen Dichte beschrieben und
rekonstruiert werden kann.[^117] In den letzten fünfzehn Jahren sind in
diversen einzelnen lokalen Forschungsprojekten, Publikationen zu Klein-
und Großstädten erschienen und erstmals auch systematisch Daten zu
jüdischen Gewerbebetrieben erfasst worden.

Aus den Interviews sowie aus Nietzels Bericht von 2009 geht jedoch
hervor, dass die einzelnen Lokalstudien gegenseitig kaum Kenntnis
voneinander genommen haben und bisher mehrheitlich nebeneinander stehen
als sich aufeinander zu beziehen.[^118] Wenn man also im Forschungsfeld
von geografisch geschlossenen Studien sprechen kann, dann gilt dies auch
für die zugehörigen Forschungsdaten, welche sich deshalb als Datensilos
charakterisieren lassen. Damit bleiben Aussagen zum Vernichtungsprozess
über lokale/ regionale Grenzen auf der Datenebene bisher noch begrenzt.

Um diese Isolation der Daten aufzubrechen und Datenvernetzung zu
ermöglichen, muss das Forschungsdatenmanagement demnach
projektübergreifend funktionieren.[^119]

### Partizipativ

Neben der wissenschaftlichen Begründung des lokalgeschichtlichen
Zugangs[^120], wird seltener reflektiret, dass viele Forschungsprojekte
dem Bereich der lokalen, insbesondere der städtischen Gedenk- und
Erinnerungskultur entsprungen sind, was zur lokalgeschichtlichen
Dominanz im Forschungsfeld beigetragen hat.[^121] Als Erklärungsansatz
für diese besondere Entwicklung sind die gesellschaftlichen Auf- und
Umbruchszeiten der 1980er Jahre plausibel. In der Tradition der
basisdemokratischen und dezentralen Graswurzelbegewegung (,,Grabe, wo du
stehst")[^122] mit der Etablierung zahlreicher lokaler
Geschichtswerkstätten ab Anfang der 1980er Jahre in der BRD war die
Motivation verbunden, die nationalsozialistische Geschichte des eigenen
Ortes kritisch aufzuarbeiten.[^123] Ab Mitte der 80er Jahre rückten
zunehmend die jüdischen Opfer ins Bewusstsein und es stand ein
angemessenes, innovatives Gedenken sowie die Schaffung von Gedenkorten
im Fokus.[^124] Die Historiker Thomas Lindenberger und Michael Wildt,
beide zum damaligen Zeitpunkt sowohl akademisch tätig als auch in
Geschichtswerkstätten aktiv, haben bereits im Jahr 1989 die Bedeutung
der von den Geschichtswerkstätten praktizierten ,,lokalen Feldforschung"
zur Freilegung von Spuren und Zeugnissen jüdischen Lebens als
mikrohistorischen Zugriff auf die Vergangenheit für die historische
Forschung herausgearbeitet.[^125] Es waren und sind also vor allem auch
diese zivilgesellschaftlichen Akteure, die akribisch Informationen zu
jüdischen Personen, Geschäften und anderen Orten aus unterschiedlichen
Quellen zusammengetragen und veröffentlicht haben.

Das bedeutet für das Forschungsdatenmanagement, dass die Forschungsdaten
zur jüdischen Gewerbetätigkeit und darüber hinaus nicht ausschließlich
im akademischen Umfeld entstanden, sondern gleichermaßen abseits der
traditionellen Wissenschaft aus unterschiedlichsten öffentlichen
Aktivitäten hervorgegangen sind. Es waren die Akteure der
Basisbewegungen, die von einem emanzipatorischen (,,Geschichte von
unten"), einem aufklärerischem (Lernen aus der Geschichte) sowie einem
moralischen (Vergangenheit nicht vergessen) Antrieb geleitet waren und
die etablierte Geschichtsforschung und Erinnerungspolitik durch
Demokratisierung von unten und Pluralismus von Grund auf verändern
wollten.[^126] Lindenberg und Wildt sprechen in Bezug auf die Praxis der
Geschichtswerkstätten schon 1989 von ,,öffentlicher Wissenschaft"[^127]
und zitieren jene mit:

> Wir beanspruchen, unsere Projekte für jede/n - ob ,wissenschaftlich'
> ausgebildet oder nicht - offen zu halten. Das Interesse am Gegenstand,
> an der gemeinsamen Auseinandersetzung mit der Vergangenheit im
> jeweiligen Projekt, sind entscheidend.[^128]

Damit wird sehr deutlich, dass der historischen Forschung im
Forschungsfeld die von der Open Science-Bewegung eingeforderte Offenheit
im Sinne der Partizipation an Wissenschaft keinesfalls fremd ist,
sondern im Gegenteil bereits über Jahrzehnte praktiziert wird. In der
Konsequenz muss auch das Forschungsdatenmanagement partizipativ angelegt
sein.

## Stakeholder

Im vorausgegangenem Kapitel haben sich bereits diverse potentielle
Nutzer\*innen von offenem Forschungsdatenmanagement im Forschungsfeld
herauskristallisiert. Wenn dieses, wie oben zum Ziel erklärt, konsequent
partizipativ sein will, müssen demnach alle Anspruchsgruppen
(Stakeholder) berücksichtigt werden, die ein berechtigtes Interesse an
offenem Forschungsdatenmanagement haben und selbst, wie gezeigt worden
ist, einen Beitrag zur (historischen) Forschung leisten. Nachfolgend
werden deshalb die Beteiligten an offenem Forschungsdatenmanagement noch
einmal aufgeschlüsselt. Freilich sind die Grenzen durchlässig, da sich
die Akteure nicht in feste Kategorien pressen lassen, sondern sich
fluide hin und her bewegen. Dennoch bietet die Einteilung die
Möglichkeit, unterschiedliche Interessen und Ziele aufzuzeigen, die
unberücksichtigt bleiben würden, wenn von vornherein eine Zielgruppe
festgelegt wäre. Dies scheint insbesondere im Zusammenhang mit den sich
im Aufbau befindlichen Infrastrukturen von Bedeutung. Aus der aktuellen
statistischen Übersicht der DFG zu den Antragseingägen für NFDI geht
hervor, dass mit 60 Prozent die Universitäten als antragstellende
Einrichtungen klar in der Mehrheit sind und notwendige Infrastrukturen
demzufolge vorwiegend aus dem Wissenschaftssystem heraus
entstehen.[^129] Es steht die Frage im Raum, inwieweit diese
ausschließlich auf die zugehörigen Akteure ausgerichtet hin entwickelt
werden. Wie die Forschungsdaten zu den jüdischen Gewerbetrieben bereits
gezeigt haben, wäre es unzureichend, außerhalb liegende
Interessengruppen lediglich nachträglich als reine Konsumenten von
Forschungsdaten zu begreifen. Vielmehr sind sie (Mit-)Produzenten von
Forschungsdaten, für die ein gleichberechtigter Zugang zu entsprechenden
Infrastrukturen von Anfang an mitgedacht werden sollte. Im Fall der hier
betrachteten Forschungsdaten liefe man andernfalls Gefahr, essentielle
Gruppen im Forschungsfeld auszuschließen.

### Akademische Wissenschaft

Die größte Interessengruppe stellt die akademische Wissenschaft dar,
denn sie hat systematisch und in Bezug auf die Vernichtung der jüdischen
Gewerbetätigkeit bisher den Großteil der Forschungsdaten produziert.
Dies geschah überwiegend im Rahmen von Dissertations- oder akademischen
Forschungsprojekten.[^130] Zur Gruppe gehören demnach
Wissenschaftler\*innen, die in der Regel aber nicht ausschließlich an
Universitäten angebunden sind und folglich innerhalb des
Wissenschaftssystems agieren. Abgrenzungskriterium ist, dass in dieser
Gruppe kritische Methodenreflexion, Konzeptentwicklungen und analytische
Durchdringung mit dem klaren Ziel des Erkenntnisfortschritts im Zentrum
stehen.

### Gedenk- und Erinnerungskultur

Eine weitere große Interessengruppe stellen die Akteure aus der Gedenk-
und Erinnerunskultur dar. Hier stehen die Daten zu jüdischen
Gewerbebetrieben meist im Kontext von Ausstellungen, Stadtführern,
Gedenkbüchern und anderen öffentlichen, oft städtischen, Aktionen.[^131]
Die Akteure sind vorwiegend zivilgesellschaftliche Initiativen, aber
auch Gedächtniseinrichtungen wie kleinere städtische Museen und Archive,
die nicht primär wissenschaftliche Institutionen sind, werden zu dieser
Gruppe gezählt. Die gemeinsame Klammer bei sämtlichen Aktivitäten ist
die Bewahrung und Vermittlung von vergangener Wirklichkeit sowie ein
sensibles, sinnstiftendes Gedenken und Erinnern.[^132]

### Einzelpersonen

In der dritten Interessengruppe werden all die Akteure zusammengefasst,
die weder institutionell noch an sonstige Infrastrukturen angebunden
sind. Hierbei handelt es sich vorwiegend um Einzelpersonen, deren
intrinsische Interessen und Motive sehr voneinander abweichen können. Es
ist selbst für ein offenes Forschungsdatenmanagement, das sich als
partizipativ versteht, unmöglich, alle Einzelinteressen gleichermaßen zu
berücksichtigen. Hervorzuheben sind allerdings zwei Gruppen. Erstens
sind das die sogenannten Amateur- oder Hobbyforscher sowie
selbstständige Historiker\*innen. Sie haben einerseits ebenfalls
systematisch Daten zu jüdischen Gewerbebetrieben gesammelt und
analysiert.[^133] Andererseits fordern inbesondere diese Akteure den
Zugang zu Forschungsdaten ein.[^134]

Die zweite wichtige Gruppe, die mit Forschungsdatenmanagement nicht
unbedingt assoziiert wird, sind die Nachkommen der Opfer des
Nationalsozialismus. Sie leben heute aufgrund von Flucht und Vertreibung
ihrer Vorfahren aus Deutschland häufig über den gesamten Globus
verstreut. Oft sprechen sie nicht mehr die deutsche Sprache. Wegen
dieser geografischen und sprachlichen Barrieren ist für sie die
Aufarbeitung der eigenen Familiengeschichte vor Ort in Deutschland in
städtischen Archiven besonders schwierig. Deshalb sollten gerade die
Angehörigen der Opfer Zugang zu den Forschungsdaten haben, die Auskunft
geben über das Leben der vertriebenen oder ermordeten Verwandten.[^135]

## Bereitschaft zu Open Science im Forschungsfeld

Damit offenes Forschungsdatenmanagement im Forschungsfeld am Ende
funktioniert, braucht es neben der Erfüllung technischer Voraussetzungen
die grundätzliche Bereitschaft von den diversen Stakeholdern, Open
Science in die eigene Forschungsarbeit zu integrieren. Die für diese
Arbeit geführten Experteninterviews stellen keine repräsentive Umfrage
dazu dar, allein weil sie das Akteursspektrum nicht widerspiegeln, aber
sie vermitteln ein Stimmungsbild. Festzuhalten ist zunächst, dass von
insgesamt acht Interviewanfragen[^136], zwei Personen ein Gespräch mit
der Begründung ablehnten, mit den Themen der Arbeit nicht vertraut zu
sein und daher nicht in der Lage seien, umfassende und fundierte
Auskunft zu erteilen. Ohne diese Selbsteinschätzungen im Einzelnen
beurteilen zu können, deuten sie darauf hin, dass es Berührungsängste
mit der Thematik gibt.

Bei den befragten Personen ist Bereitschaft vor allem in Bezug auf die
universellen Open Science-Grundsätze vorhanden. Schlagwörter wie
Verfügbarkeit, Teilen, Austausch, Vernetzung oder Nachvollziehbarkeit
sind mehrheitlich gefallen. Es wird sogar hervorgehoben, dass sie gerade
im Kontext des Forschungsfelds wichtig seien.[^137] Die konkrete
Realisierung wurde allerdings an Bedingungen geknüpft, die wie folgt
zusammengefasst werden können:

-   Es muss ersichtlich sein, was offenes Forschungsdatenmanagement
    bezwecken will. Offenes Forschungsdatenmanagement ist, jedenfalls in
    der gegenwärtigen Phase, noch kein Selbstzweck, sondern braucht eine
    klare Zielformulierung, die die Benefits deutlich heraushebt.[^138]

-   Offenes Forschungsdatenmanagement im Forschungsfeld kann nicht rein
    wissenschaftlich ausgerichtet sein, sondern braucht eine Kopplung
    zum erinnerungskulturellen Teil des Forschungsfelds.[^139]

-   Um ein offenes Forschungsdatenmanagement steuern und kontrollieren
    zu können, bedarf es gemeinsamer Regeln und Strategieentwicklung
    sowie methodischer Führung.[^140]

-   Es bedarf der Reflektion forschungsethischer Implikationen und der
    Umsetzung entsprechender Richtlinien.[^141]

-   Offenes Forschungsdatenmanagement muss Diskurse im Forschungsfeld
    abbilden können.[^142]

-   Offenes Forschungsdatenmanagement braucht langfristige Betreuung und
    Pflege. Es muss sich stetig an neue Bedarfe im Forschungsfeld
    anpassen lassen können.[^143]

## Rechtliche und ethische Rahmenbedingungen

Die rechtlichen und ethischen Rahmenbedingungen entscheiden maßgeblich
darüber, ob die Forschungsdaten zu jüdischen Gewerbebetrieben in einer
Open Data-Lizenz publiziert werden können. In Bezug auf
nutzungsrechtliche Fragen gingen aus den Interviews keine gesichterten
Antworten hervor.[^144] Daher können pauschal für das Forschungsfeld
keine Aussagen gemacht werden. Eine ansatzweise fundierte Auskunft ist
aber auf der Grundlage der vorliegenden Forschungsdaten zu Berlin
möglich. Hier wurden vier relevante Datenquellen identifiziert. Die
erste Datenquelle, aus der Grunddaten zu Name, Rechtsform, Adresse,
Inhaber und Bilanzen entnommen wurden, stammen aus der
Zentralhandelsregisterbeilage (ZHRB), welche dem Deutschen
Reichsanzeiger und Preußischen Staatsanzeiger täglich beilag.[^145] Bei
diesen Daten handelt es sich um Informationen aus dem Handelsregister,
zu deren Offenlegung Unternehmer nach dem Handelsgesetzbuch (HGB)
verpflichtet waren.[^146] Es handelt sich folglich um amtliche,
öffentliche Informationen, die keiner rechtlichen Einschränkung
unterliegen. Das gilt generell für publiziertes historisches
Material.[^147] Die zweite Datenquelle bildet eine Grauzone. Hierbei
geht es um Daten, die aus externen Online-Datenbanken kommen und wo die
Nachnutzung nicht eindeutig ist. Dies ist zum Beispiel bei dem
,,Gedenkbuch Opfer der Verfolgung der Juden unter der
nationalsozialistischen Gewaltherrschaft in Deutschland 1933 -
1945"[^148] des Bundesarchivs der Fall. Dort ist ein Copyright ,,©
Bundesarchiv" für die gesamte Website zwar vermerkt, aber das Gedenkbuch
erlaubt durch Datenexporte (CSV und PDF) theoretisch, Daten
nachzunutzen. Im Datensatz selbst sowie in den Dateien findet sich
jedoch keinerlei Hinweis darauf, wie die Daten nachgenutzt werden
dürfen.[^149] Hier zeigt sich, dass im Sinne der Creative
Commons-Philosophie eine klare Kommunikation seitens der Datenprovider
notwendig ist.[^150] Die dritte Datenquellen stellen alle in Archiven
vorliegenden, aber nicht veröffentlichten Quellen dar.[^151]. Auch wenn
die darin enthaltenden Daten selbst keinen Schutzfristen mehr
unterliegen, verfügt das Archiv als Besitzer über die Vergabe
Nutzungsrechte. Rechtlich brisant sind die Wiedergutmachungsakten, da
sie sich auf natürliche Personen beziehen und daher besonderen
Schutzfristen unterliegen. Sie werden deshalb hier als vierte
Datenquelle extra gezählt. Das betrifft nicht nur Daten zu Überlebenden,
sondern auch die zu den nichtjüdischen Erwerber\*innen von jüdischem
Eigentum.[^152] Für das offene FDM mit Open Research Data wird eine
offene Lizenz angestrebt. Wichtig wäre also, dass für die Datenquellen,
bei denen die Nachnutzung nicht sicher ist, im Vorfeld eine
entsprechende Veröffentlichung mit den Archiven abgeklärt wird. Das
macht deutlich, dass Open Science im Forschungsfeld auch von der
Bereitschaft anderer Institutionen wie Archiven abhängt. Unabhängig
davon ist generell wichtig für das offene FDM, Nutzungsrechte zum
Beispiel mit einer Creative Commons-Lizenz transparent zu machen.

Aus ethischer Perspektive scheinen die Forschungsdaten auf den ersten
Blick unbedenklich, da es sich vorwiegend um amtliche, öffentliche
Massendaten handelt. Allerdings gibt es im Forschungsfeld sowie in der
Holocaust-Forschung allgemein eine Auseinandersetzung zum Missverhältnis
in der Veröffentlichung von Daten von Holocaust-Opfern gegenüber
deutschen Täter\*innen und Mittäter\*innen. Dass heute Daten über
jüdischen Personen überhaupt in dieser Breite und Tiefe publiziert
werden dürfen, beruht einzig auf der Tatsache, dass die Mehrheit dieser
Menschen vor 80 Jahren die nationalsozialistische Verfolgung und
Vernichtung nicht überlebten. Zudem waren sie zu Lebzeiten bereits einer
vollständigen Erfassung und Markierung ausgesetzt, die die systematische
bürokratische Verfolgung erst ermöglichte.[^153] Das Recht auf
Anonymität existierte für sie zu Lebzeiten nicht. Im Gegenzug
unterliegen personenbezogene Daten zu deutschen Täter\*innen und
Mittäter\*innen gesetzlichen Schutzfristen über den Tod hinaus, weil
diese Menschen noch leben oder bis vor Kurzem noch gelebt haben.[^154]
Dieses ethische Dilemma kann offenes Forschungsdatenmanagament nicht
auflösen. Festzuhalten ist jedoch, dass es sich hierbei um eine genuin
deutsche Debatte handelt.[^155] Das internationale Holocaust-Museum *Yad
Vashem* in Israel wiederum sieht in der Online-Veröffentlichung seiner
Daten von über 3 Millionen Personen die Chance, fehlende Informationen
von der Öffentlichkeit zu erhalten, die die Sammlung der Namen der
Ermordeten sukzessive erweitern können[^156]

Letztendlich muss abgewogen werden, ob ethische Grenzen dem öffentliches
Interesse an diesen Daten überwiegen. Die Forschungsdaten zu den
jüdischen Gewerbebetrieben werden an dieser Stelle im Großen und Ganzen
als unproblematisch eingestuft, weil es in erster Linie Verwaltungsdaten
sind. Nichtsdestotrotz hat offenes Forschungsdatenmanagament aufgrund
des sensiblen Forschungsthemas forschungsethische Implikationen, die
parallel zur prototypischen Lösung im nächsten Kapitel mitdiskutiert
werden.

# Prototypische Lösung

## Lösungsansatz

Bei der prototypischen Lösung steht im Zentrum dieser Arbeit die
Wissensdatenbank *Wikidata*[^157] als offener
Forschungsdatenmanagement-Service. Bei Wikidata handelt sich
ursprünglich um ein offenes dankenbankbasiertes Angebot von Wikimedia
für strukturierte Daten im Wiki\*versum, das das Konzept von Linked Open
Data umsetzt. Damit ist es flexibel und sprachenunabhängig einsetzbar,
wodurch es als Modell auch für Forschungsdatenmanagement in der
akademischen Wissenschaft interessant wird. Tatsächlich wird dieser Weg
im Rahmen von NFDI gegenwärtig bestritten. Das *Open Science Lab* am
,,Leibniz-Informationszentrum Technik und Naturwissenschaften und
Universitätsbibliothek"[^158] hat für das Konsortium
*NFDI4Culture*[^159] Wikidata und insbesondere die zugrunde liegende
Software *Wikibase*[^160] auf die Einsetzbarkeit für ein
Forschungsdatenmanagement von Kulturdaten hin evaluiert. Erste
Ergebnisse wurden im März 2022 auf dem TIB-Blog veröffentlicht.[^161]
Parallel führt das NFDI4Culture-Konsortium selbst die Workshop-Reihe
,,Wikibase" durch.[^162]

Auch im Kontext historischer Forschung kommt Wikidata bereits zum
Einsatz. Das Online-Portal ,,Archivführer. Deutsche Kolonialgeschichte"
nutzt Wikidata als strukturierte Datenbasis für in Zusammenhang mit dem
Thema ,,Deutsche Kolonien und Schutzgebiete" stehende
Forschungsdaten.[^163] Das Portal führt lediglich die Wikidata-Daten für
die Datenpräsentation zusammen und ermöglicht einen multiperpektivischen
Zugang zu den Daten.[^164] Die Besonderheit ist, dass die
Datenbereitstellung durch Wikidata ermöglicht, über die Projektlaufzeit
hinaus Daten von jeder/jedem erweitern zu lassen sowie diese in gänzlich
anderen Kontexten zu verwenden. Darüber hinaus verfolgt das Projekt das
Ziel, die Daten mit der ,,kolonialen Vergangenheiten anderer
Ländern"[^165] zu verknüpfen und auf diese Weise das Forschungsfeld zum
Deutschen Kolonialismus anschlussfähig an die Forschung zum Europäischen
Kolonialismus zu machen. Die Zusammenarbeit und der kollaborative
Austausch dazu erfolgen ebenfalls global in Wikidata mit dem
,,Wikidata:WikiProject European Colonialism".[^166] Das internationale
Projekt ,,European Holocaust Research Infrastructure" (EHRI), welches im
Rahmen der Open Science-Strategie von der Europäischen Kommission seit
2017 gefördert wird[^167] nutzt Wikidata als zentrales Verzeichnis zur
Erstellung einer Liste von Ghettos aus der Zeit des Holocausts.[^168]
Ziel ist, Daten aus verschiedenen Enzyklopädien, die bisher isoliert
waren, in Wikidata erstmals zusammenzuführen und zu verknüpfen.[^169]

Grundsätzlich ist bei der Implementierung des offenen
Forschungsdatenmanagements mit Wikidata ist zu beachten, dass hier das
Konzept von Linked (Open) Data umgesetzt wird, bei dem es sich, wie in
Kapitel 2.2.2 bereits erläutert wurde, um einen wesentlichen Baustein
des *Semantic Web* handelt. Damit erfolgt offenes FDM in der höchsten
Open Data-Stufe (= 5 Sterne). Vorteil ist, dass die Stärken dieses
Konzepts, welche vor allem in der Verknüpfung und Vernetzung von Daten
liegen, für das Forschungsdatenmanagement ausgenutzt werden können.
Nachteilig ist, dass dieser Ansatz voraussetzungsreicher als andere
Lösungen ist, da zum einen Kenntnisse der allgemeinen Technologien von
Linked Data Web wie RDF (Resource Description Framework), JSON-LD
(JavaScript Object Notation for Linked Data) oder URI (Uniform Ressource
Identifier)[^170] und zum anderen Kenntnisse des spezifische
Metadatenschemas bzw. der Onotologie zugrunde liegenden Software
Wikibase von Wikidata.[^171] für die Umsetzung benötigt werden.
Kurzgefasst ist im Wesentlichen zu beachten, dass jegliche Modellierung
von Daten graphenbasiert in sogenannten Tripeln als
Subjekt-Prädikat-Ausdrücke erfolgt, was sich grundlegend von der
konventionellen tabellenbasierten relationalen Datenmodellierung mit
Tupeln unterscheidet. In Wikidata werden diese Ausdrücke als Aussagen
(Statements) bezeichnet. Mit ihnen können Konzepte inhaltlich
erschlossen werden.[^172]

## Erhebung

> \[\...\] Dass dieses methodisches Vorgehen auch transparent und
> nachvollziehbar ist.[^173]
>
> \[\...\] Das große Problem ist, was ist in Gottes Namen ein jüdisches
> Unternehmen.[^174]

Datenerhebung in der empirischen historischen Forschung geht mit
historischer Quellenanalyse und Quellenkritik einher.[^175] Anders als
in der naturwissenschaftlichen Datenerhebung, wo anhand von
Experimenten, Beobachtungen, Simulationen oder Messungen, Daten in
Echtzeit gewonnen werden und dementsprechend die Erhebungsmethoden an
den Forschungsfragen angepasst werden können, ist die Vorgehensweise bei
den geschichtswissenschaftlichen Disziplinen maßgeblich von der
Überlieferungstruktur und der Quellensituation abhängig.[^176]
Informationen zur Erhebung sind also essentiell, um Forschungsdaten im
Sinne einer Datenkritik kontextualisieren, verstehen und damit letztlich
bewerten zu können. Bei den Forschungsdaten zu jüdischen
Gewerbebetrieben sind diese jedoch nicht hinterlegt und es handelt sich
daher bisher um implizites Wissen, was eine Nachnutzung erschwert oder
sogar unmöglich machen kann. Hinsichtlich der Nachvollziehbarkeit und
Transparenz von Forschungsdaten ist daher Ziel von offenem
Forschungsdatenmanagement, das Wissen um den Entstehungsrahmen sowie um
die geschichtswissenschaftliche Datenerhebungsmethode explizit zu
machen. Dabei soll das grundsätzliche methodische Definitionsproblem des
Begriffs ,,jüdischer Gewerbebetrieb" mitdiskutiert werden.

### Entstehungsrahmen

Im Forschungsfeld ist der Großteil der Forschungsdaten zu jüdischen
Gewerbebetrieben in lokalen wissenschaftlichen Forschungsprojekten
erhoben worden, daher stellen vor allem sie die relevanten Informationen
zum Entstehungsrahmen bereit. Die Frage, wie verschiedene (akademischen)
Forschungsaktivitäten zur semantische Anreicherung von Forschungsdaten
konzeptionalisiert und formalisiert werden können, scheint gegenwärtig
noch nicht Gegenstand des Forschungsdatenmanagements zu sein, denn einen
wissenschaftlichen Standard, nach denen diese beschrieben werden können
und sollen, konnte nicht ermittelt werden. Zwar gibt es inzwischen
generische Metadatenstandards wie *Dublin Core* der *Dublin Core
Metadata Initiative*[^177] oder *DataCite*[^178] des gleichnamigen
internationalen Konsortiums. ,,DublinCore" fokussiert aber in erster
Linie auf Informationen zur technischen Umsetzung sowie zur
Veröffentlichung von digitalen Ressourcen und ist damit näher an der
traditionellen Praxis der Formalerschließung in der
Bibliothekskatalogisierung dran. ,,DataCite" ist umfangreicher und lässt
als optionale Elemente auch Angaben zu Fördermittelgebern zu.[^179] Ein
Konzept ,,Forschungsprojekt" findet sich aber in beiden Standards nicht
wieder. Dem gegenüber bietet Wikidata einen entscheidenden Vorteil: Zur
Verbesserung strukturierter Beschreibungen von bestimmten Konzepten wie
zum Beispiel ,,Mathematik" oder ,,Astronomie" können von der
Wikidata-Community sogenannte *Wikidata:Wikiprojekte* angelegt werden.
Sie bieten die Möglichkeit der kollaborativen Modellierung und des
gemeinsamen Austauschs. Dadurch kann ein festes Vokabular (Authority
File) für ein Konzept in Wikidata angelegt werden, die allerdings nur
informellen Charakter haben. Inzwischen gibt es eine Vielzahl an
unterschiedlichen Projekten, die in Kategorien unterteilt sind.[^180] In
der Kategorie *Category:Research WikiProjects* beschäftigt sich eine
internationale Wissenschaftler\*innengruppe mit der Abbildung des
Konzepts ,,Forschung" in Wikidata.[^181] Dort integriert ist das
Unterprojekt *Wikidata:WikiProject Wikidata for research/Data
models/Research projects*, in dem sich ausschließlich mit dem Konzept
,,Forschungsprojekt" befasst wird.[^182] Hier zeigt sich die Stärke des
gemeinschaftlichen Ansatzes von Wikidata besonders, denn die Chance,
dass sich in Wikidata mit einem Problem schon befasst wird, ist sehr
hoch.

Folglich wäre die eigene Modellierung von ,,Forschungsprojekt" für die
lokalen Forschungsprojekte im Forschungsfeld redundant, da diese von dem
bestehenden Wikidata-Projekt abgeleitet werden kann (Abbildung
4.1).[^183] Aus dem Modell in Abbildung 4.1 geht darüber hinaus hervor,
dass viele Entitäten in Wikidata bereits existieren und nicht neu
angelegt werden müssen.[^184] Auch die Verknüpfung von externen
Information ist möglich. Die Deutsche Forschungsgemeinschaft (DFG) hat
mit dem Informationssystem ,,GEPRIS -- Geförderte Projekte der DFG"
(GEPRIS)[^185] in Auszügen ihre Daten zu allen gegenwärtigen und
vergangenen geförderten Projekten veröffentlicht. Dort ist auch das
Forschungsprojekt ,,Geschichte mittlerer und kleiner jüdischer
Unternehmen in Frankfurt am Main und Breslau 1929/39 bis 1945"
archiviert.[^186] Mit der vorhandenen Wikidata-Property ,,GEPRIS ID
(Projekt) (P4870)", kann demnach das DFG-Projekt mit dessen eindeutiger
nummerischer DFG-Kennung ,,48308995" in Wikidata verknüpft werden.[^187]

Zusammengefasst bietet die vielfältige Nutzung der Wikidata eine Menge
Nachnutzungsmöglichkeiten auch für die historische Forschung. Diese Form
der Nachnutzung trägt außerdem zur Qualitätsicherung in Wikidata bei.
Zudem können erstmals Projekt-Daten aus vrteilten Datenquellen in
Wikidata zusammengeführt und auf diese Weise Informationen vernetzt
werden. Sollten für das Forschungsfeld weitere Informationen notwendig
werden, können diese dynamisch ergänzt werden, was wiederum der Vorteil
des Linked Data-Konzept gegenüber einer herkömmlichen relationen
Modellierung in einer SQL-Datenbank ist. Dort ist diese Flexibilität
nicht gegeben. Dadurch, dass die Forschungsprojekte als eigene
Wikidata-Items nun einen eindeutigen Wikidata-Identifikator besitzen,
können sie den zugehörigen Forschungsdaten zugeordnet werden, womit der
projektbezogene Entstehungsrahmen erstmals transparent wird.

### Erhebungsmethode

Da die methodischen Vorgehensweisen der verschiedenen
Wissenschaftsdisziplinen voneinander abweichen, existieren zu deren
formalen Beschreibung keine disziplinübergreifenden
Metadatenstandards.[^188] Das heißt, diese als Prozessmetadaten
bezeichneten Daten sind fachspezifisch. Im naturwissenschaftlichen
Bereich und in der Archäologie gibt es mit der *Research Resource
Identification Initiative* (RRI)[^189] und mit *IANUS*[^190] bereits
zentrale Ansätze, wie Methodiken schematisch und anhand von Thesauri
oder festen Vokabularen formal beschrieben werden können.[^191]
Allerdings sind sie nicht übertragbar auf den
geschichtswissenschaftlichen Bereich. Offenes Forschungsdatenmanagement
ist hier mit zwei Herausforderungen konfrontiert. Erstens gibt es einen
fachspezifischen Standard für die Geschichtswissenschaften nicht.
Zweitens ist fraglich, wie sich die Erhebungsmethoden im Forschungsfeld
formalisieren lassen. Als Einstiegspunkt soll hier der Versuch einer
groben Schematisierung der methodischen Vorgehensweise anhand der
Lokalstudien, welche systematisch Daten zu jüdischen Gewerbebetrieben
erhoben haben, vorgenommen werden.[^192] Zunächst ist festzuhalten, dass
die Datenanalyse und -auswertung aller Studien auf Stichprobenziehung
beruhte.[^193] Festzustellen ist weiterhin, dass die Überlieferung
überall als disparat und lückenhaft bezeichnet wurde, da viele Bestände
teilweise oder überwiegend von den Nationalsozialisten vernichtet
wurden, um Spuren zu verwischen, oder in den letzten Kriegstagen
unwiederbringlich zerstört wurden. Oft sind nur Überreste und Splitter
erhalten. Abbildung 4.2 zeigt einen idealtypischen Ablauf der
Datenerhebung im Forschungsfeld. Demnach wurde eine Hauptquelle
(Datenquelle 1) ausgewählt, aus der ein Sample gezogen wurde.[^194] In
den meisten Fällen konnten daraus die wesentlichen Grunddaten (Name,
Inhaber, Branche und Adresse) der Gewerbebetriebe erfasst. Ausgangspunkt
bildeten im Idealfall publizierte und unpublizierte Verzeichnisse,
Listen oder Karteisammlungen in denen Gewerbebetriebe dezidiert und
systematisch mit dem Ziel der Verfolgung als jüdisch markiert und
gelistet wurden.[^195] Im nächsten Schritt wurden diese Daten mit
weiteren Quellen abgeglichen, die den Vorgang der Verfolgung der
einzelnen Gewerbebetriebe verwaltungsseitig dokumentierten. Zu dieser
zweiten Datenquelle gehören verschiedene zeitgenössische
Aktenbestände.[^196] Aus diesem Rahmen fällt das Berliner
Forschungsprojekt, wo man einen gänzlich anderen Ansatz verfolgt hat.
Mangels überlieferter Quellen, wurde ein Sample anhand der
Zentralhandelsregisterbeilage (ZHRB) erstellt und aus dieser die
Aktivitäten aller handelsregisterlich geführten Unternehmen zwischen
1932 und 1942 erfasst. Man nahm hier folglich eine Gesamtaufnahme des
Handelsregisters vor, welches im zweiten Schritt nacheinander mit
weiteren Quellen abgeglichen und bei einer eindeutigen Indizienlage
Gewerbebetriebe als jüdisch identifiziert wurden.[^197] Auch wenn mit
ca. 8.000 identifizierten jüdischen Gewerbebetrieben nur etwa 16
Prozenzt der insgesamt in Berlin ansässigen jüdischen Gewerbebtriebe
erhoben werden konnte, stellt das Sample in Bezug auf das
Handelsregister als Grundgesamtheit fast eine Vollerhebung dar.[^198]

Nachteil der vereinfachten, groben Schematisierung ist, dass diese
Detailinformationen nicht enthalten sind. Darüber hinaus fehlen die mit
der Quellenlage einhergehenden Stichproben-Verzerrungen (Bias) der
Studien, welche bisher überhaupt nicht kommuniziert werden:

-   Viele Hauptquellen setzen zeitlich erst mit den reichsweiten
    Gesetzen ab 1938 ein. Die frühe Phase der Vernichtung der jüdischen
    Gewerbetätigkeit bleibt somit unterrepräsentiert, weil schlichtweg
    Daten dazu fehlen.

-   Bei der Verwendung von überwiegend Wiedergutmachungsakten,
    insbesondere aus Rückerstattungsverfahren wie in Hamburg, liegt der
    Schwerpunkt automatisch auf den größeren Unternehmensverkäufen und
    den ehemaligen Eigentümern, die den Nationalsozialismus meist durch
    Emigration überlebt haben. Liquidationen bleiben in diesem Ansatz
    unterrepräsentiert sowie der komplette Ostteil Deutschlands, da hier
    die Wiedergutmachung erst in den 90er Jahren mit dem Ende der DDR
    teilweise einsetzte.

-   In Berlin wiederum liegt der Fokus mit der ZHRB auf den
    handelsregisterlich eingetragenen Firmen und damit auf
    mittelständischen Gewerbebetrieben, wodurch vor allem
    Kleinstunternehmen unterrepräsentiert bleiben. Außerdem liegt der
    Schwerpunkt auf Liquidationen, da das Handelsregister
    Besitzübernahmen nicht abbildet.

Es wird deutlich, dass geschichtswissenschaftliche
Datenerhebungsmethoden aufgrund der historischen Quellengrundlage nicht
analog zu den naturwissenschaftlichen Methoden standardisiert werden
können. Es ist die Lückenhaftigkeit und es sind die Fehlstellen in der
historischen Forschung, die eine adäquate Abbildung auf ein festes
Schema zu einer spezifischen Herausforderung im Fach machen. Daher
stellt sich insbesondere auch die Frage, welche Notwendigkeit
Standardisierung hier besitzt. Es wäre genauer zu untersuchen, was der
Mehrwert davon für die historische Forschung wäre oder ob zum Zwecke der
methodischen Transparenz und Nachvollziehbarkeit eine rein textuelle
Beschreibung oder Dokumentation zum Beispiel in Form einer Readme-Datei
ausreicht. Tatsache ist, dass die Ausführungen zur Erhebung in die
einzelnen Lokalstudien bisher unterschiedlich ausfallen und
entscheidenden Informationen zum Verständnis der Forschungsdaten ganz
fehlen. Auch im Sinne der Nachnutzbarkeit von historischen
Forschungsdaten ist also die offene Frage, welche Informationen zur
Methodik überhaupt benötigt werden.

### Problem *Jüdischer* Gewerbebetrieb

Da Untersuchungsgegenstand aller Lokalstudien ,,Jüdische
Gewerbebetriebe" oder ,,Jüdische Unternehmen" sind, wurde folglich Daten
zu jüdischen Gewerbebetrieben erfasst. Hieraus ergibt sich eine
grundlegende methodische Schwierigkeit: Da die Konfessionszugehörigkeit
bezüglich eines Gewerbebetriebs oder Unternehmens schlichtweg unlogisch
ist, ist der Begiff alleine ohne Kontext unbrauchbar. Dieses Problem
wird von dem meisten Studien reflektiert und betont, dass es sich
hierbei um eine antisemitische Zuschreibung und Konstruktion handelte.
Diese Kennzeichnung und Diffamierung diente den Nationalsozialisten als
Instrument für die weiteren Verfolgungspraktiken. Zur einfacheren
Handhabung wurde der Begriff als Quellenbegriff jedoch von allen Studien
beibehalten. Hierbei fallen zwei unterschiedliche Verwendungen auf:

-   Der Begriff ,,jüdischer Gewerbebetrieb" wird ausschließlich auf die
    jüdischen Besitzer\*innnen bezogen und angewandt.[^199] Damit wird
    jedoch das methodische Problem nicht aufgelöst, sondern verlagert
    sich auf den Begriff ,,jüdische Person" oder ,,Jude/ Jüdin", bei dem
    es sich ebenfalls um eine rassistische Zuschreibung handelte und
    nichts mit dem Selbstverständnis der Betroffenen zu tun hatte.[^200]
    Darüber hinaus werden in dieser Verwendung weitere
    Verfolgungskontexte vernachlässigt. So war es in der frühen Phase
    der Verfolgung durchaus möglich, dass Gewerbebetriebe als jüdisch
    diffamiert wurden, die zum Beispiel einen hohen Anteil jüdischer
    Mitarbeiter\*innen aufwiesen, deren Besitzer aber selbst nach der
    nationalsozialistischen Ideologie nichtjüdisch waren.[^201]

-   Der Begriff ,,jüdischer Gewerbebetrieb" wird mit ,,als jüdisch
    betrachtet/ verfolgt" übersetzt. In dieser Verwendung ist die
    jüdische Eigentümerschaft eines Gewerbebetriebs zunächst
    unerheblich, das heißt sie wird nicht vorausgesetzt, sondern es
    werden alle Gewerbebetriebe erfasst, die im nationalsozialistischen
    Kontext diffamiert wurden. Damit wird einerseits der
    Konstruktioncharakter des Begriff hervorgehoben und andererseits dem
    Umstand Rechnung getragen, dass die rassistischen Zuschreibungen
    grundsätzlich jeglicher rationalen Begründung entbehrten und aus
    diesem Grund willkürlich erfolgen konnten.

Auch wenn in allen Studien der selbe Untersuchungsgegenstand genannt
wird, so zeigt sich erst in der konkreten Verwendung, dass dieser
unterschiedlich ausgedehnt werden konnte, weil der Begriff an sich nicht
widerspruchsfrei ist. Aus forschungsethischer Perspektive ist zudem
problematisch, dass ein rassistisch konnotierter Begriff in der
wissenschaftlichen Forschung beibehalten wird. Wichtig wäre, sich im
Forschungsfeld auf eine einheitliche Verwendung zu einigen, denn bisher
werden Jüdische Gewerbebetrieben unterschiedlich erhoben. Hierzu wird
keine abschließende Entscheidung getroffen, da dies in einem Diskurs im
Forschungsfeld gemeinsam entschieden werden sollte. Um dafür den Anstoß
zu geben und um insbesondere auch die forschungsethischen Implikationen
kritisch zu reflektieren, wurde im erstellten Wikidata-Projekt[^202] der
*Wikidata talk* ,,How do we use and model ,Jüdischer Gewerbebetrieb'?"
mit der Disskussionsfunktion angelegt und zwei Vorschläge unterbreitet
(Abbildung ):

-   ,,Jüdischer Gewerbebetrieb" wird als eigenes Item angelegt und mit
    Statements angereichert, die die nationalsozialistische Herkunft
    deutlich machen. Da in Wikidata Items von jedem/ jeder ohne
    Einschränkung angelegt werden können, wäre diese Lösung schnell
    umsetzbar. Bei der Frage mit welcher Eigenschaft (Property) das Item
    als Value auf einen Gewerbebetrieb abgebildet werden soll, lohnt
    abermals ein Blick auf benachbarte Wikidata-Projekte. Im Projekt
    *Wikidata:WikiProject Victims of National Socialism* wurde 2020 die
    Verwendung des Begriffs ,,Holocaust-Opfer" diskutiert.[^203]. Da in
    der Wikidata Konvention ist, Personen so neutral wie möglich zu
    beschreiben und Zuschreibungen von außen mit entsprechenden Aussagen
    kenntlich zu machen, hat man sich im Wikidata-Projekt darauf
    geeinigt, den Begriff nunmehr zusammen mit ,,Subjekt fungiert als
    (P2868) Opfer des Holocaust (Q5883980)" zu verwenden und nicht mehr
    als ,,ist ein(e) (P31) Holocaust-Opfer (Q5883980)".[^204] Diese
    Verwendung kann für Gewerbebetriebe übernommen werden. Zwar geht es
    hier ausdrücklich nicht um Personen. Da aber die Verwendung ,,ist
    ein(e) (P31) Jüdischer Gewerbebetrieb (Q???)" - wie gezeigt wurde -
    unlogisch wäre, bietet sich ,,Subjekt fungiert als (P2868) Jüdischer
    Gewerbebetrieb (Q???)" an.

-   Statt als Item kann ,,Jüdischer Gewerbebetrieb" auch als Property
    ,,als jüdisch betrachtet/ verfolgt (P???)" oder ähnlich modelliert
    werden.[^205] Da diese Eigenschaft bisher noch nicht existiert, wäre
    diese Umsetzung etwas langwieriger, da Eigenschaften in der Wikidata
    nicht von jedem/jeder erstellt werden, sondern zunächst
    vorgeschlagen werden müssen.[^206] Nach einer öffentlichen Debatte
    entscheidet eine berechtigte Administratoren-Gruppe der Wikidata, ob
    die Property neu aufgenommen wird oder ob Alternativ-Eigenschaften
    zur Verfügung stehen. Mit diesem Verfahren sollen Redundanzen und
    Widersprüchlichkeiten verhindert werden. Es dient zur
    Qualitätskontrolle der Wikidata. Daher ist es möglich, dass für das
    Forschungsfeld notwendige Eigenschaften für die Wikidata insgesamt
    nicht die Relevanz besitzen und aus diesem Grund abgelehnt werden
    können. Wie liberal oder konservativ die Wikidata-Politik hier ist,
    müsste erprobt werden.

## Aufbereitung

> Also ich denke, die sitzen alle auf irgendwelchen Excellisten oder
> wenn das ältere Forschungsprojekte sind, Herr Bajohr weiß ich nicht,
> ob der schon Excel genutzt hat für sein Hamburg-Buch oder ob der noch
> Karteikarten hatte.[^207]

Um eine valide Datengrundlage für die Analyse zu erhalten, werden die
erhobenen Rohdaten vorab aufbereitet. Damit erfolgt erstmalig eine
Verarbeitung der Daten, denn der Operationalisierung der
Forschungsfragen entsprechend werden die Daten ausgewählt, strukturiert
erfasst und bereinigt. In der historischen Forschung liegt die Situation
vor, dass die Rohdaten im Quellenmaterial bereits vorliegen, sich aber
mitunter über viele Quellen verteilen. Daher muss festgelegt werden,
erstens welche Informationen aus den Quellen extrahiert werden sowie
zweitens, mit welchem Werkzeug diese strukturiert und organisiert werden
sollen. Dieser Prozess der Forschungsdaten-Genese ist bisher im
Forschungsfeld weitestgehend unsichtbar und findet lediglich in den
Studien zu Berlin und Frankfurt am Main nachträglich in den
Publikationen Erwähnung.[^208]. In beiden Projekten kamen ,,Datenbanken"
zum Einsatz, die anhand der Interviews als Microsoft Access-Datenbanken
der Version 2007 spezifiziert werden konnten.[^209] Da es sich hierbei
um eine Anwendung handelt, deren Datenorganisation auf relationalen
Tabellen beruht, braucht es als Basis vorab ein Datenmodell,
visualisiert zum Beispiel anhand eines Entity-Relationship-Diagramms
(ERD) mit einer Beschreibung der darin verwendeten Elemente. Dieses ist
für beide Studien allerdings nicht verfügbar. Damit ist eine Beurteilung
der Daten hinsichtlich ihrer Verarbeitung bisher nicht möglich. Ziel von
offenem Forschungsdatenmanagement ist es, die bisher unsichtbare Phase
der Aufbereitung durch kollaborative Zusammenarbeit im Forschungsfeld
transparenter zu gestalten.

Zu diesem Zweck wurde in Wikidata das Projekt *Wikidata:WikiProject
Destruction of the Economic Existence of the Jews Research* erstellt
(Abbildung 4.3.).[^210] Dieses besitzt grob drei Funktionen: Erstens
können beliebig viele Seiten mithilfe von standardisierten Templates
hierarchisch im Projekt angelegt werden (Pages und Subpages).[^211]
Diese bieten die Möglichkeit, die in Kapitel 3 methodisch aufgegriffene
Taxonomie und damit die unterschiedlichen Zugänge im Forschungsfeld
funktional umzusetzen. Auf der Hauptseite (Home) wurden bereits
Hintergrundinformatioen zum Projekt sowie zu dessen Zielen hinzugefügt.
Dort ist auch erwähnt, dass diese Arbeit nur den Ausgangspunkt bildet
und von hier aus sukzessive die angrenzenden Untersuchungsbereiche
integriert werden können. Außerdem findet sich hier die nicht unwichtige
Information, dass die Taxonomie im Forschungsfeld dem
Systematisierungversuch von Nietzel aus dem Jahr 2009 entlehnt
ist.[^212]

Die bisherige Implementierung versteht sich explizit als Vorschlag, um
eine Ausgangsbasis zu haben, von der aus Anpassungen und
Weiterentwicklungen möglich werden. Um später in den gemeinsamen
Austausch zu treten und Änderungen vorzunehmen, kann hierfür die zweite
grundlegende Funktion der Diskussionseiten genutzt werden. Schließlich
gibt es mit der Versionierung (,,Versionsgeschichte") eine
Kontrollfunktion, mit der sich alle Bearbeitungen zurückverfolgen und
gegebenfalls auf einen früheren Stand zurücksetzen lassen.[^213]
Ingesamt bietet das Wikidata-Projekt damit die Möglichkeit des
kollaborativen Austauschs und der gemeinsamen Strategieentwicklung im
Forschungsfeld. Erstmals können Methodiken und Konzepte im
Forschungsfeld diskutiert sowie in Bezug auf die in der Arbeit
betrachteten Forschungsdaten ein allgemeingültiger Leitfaden zur
Erfassung jüdischer Gewerbebetriebe entwickelt werden. Thematisch ist
das Wikidata-Projekt in die Kategorien *History WikiProjects* und
*Research WikiProjects* eingeordnet.[^214] Hier zeigt sich darüber
hinaus, dass benachbarte Forschungsfelder zum Nationalsozialismus und
zum Holocaust bereits mit eigenen Projekten vertreten sind, womit sich
Anknüpfungspunkte über das Forschungsfeld hinaus ergeben.[^215]

### Zusammenführung der Quellen

##### Datenmodell

Beim Zusammenführen der Quellen wurden die ausgewählten verteilten
Informationen als strukturierte Daten zentral in Excel oder Access
gespeichert. Auch wenn es in den Interviews von keinem Befragten bewusst
formuliert wurde, so haben alle zur ,,Handhabbarmachung der
Informationen"[^216] eine *Modellierung* von den zu erfassenden Daten
vorgenommen. Bei diesem Vorgang wird ein eindeutig definierter realer
Ausschnitt auf ein Modell abgebildet und die enthaltenen Konzepte
operationalisiert. Aus den Interviews geht außerdem hervor, dass ein
Datenmodell vorab nicht fest fixiert war, sondern dieses parallel zur
Datenerfassung entstand und erweitert wurde.[^217] Daraus ergeben sich
zwei Anforderungen an offenes Forschungsdatenmanagement: Kollaborative
Zusammenarbeit zwischen den Projekten kann nur funktionieren, wenn man
sich auf eine Terminologie und auf ein Schema einigt. Es müssen folglich
erstens die vielen unterschiedlichen Modelle und Begriffe der einzelnen
Studien für eine gemeinsame Nutzung kompatibel gemacht werden. Da
aufgrund der besonderen Überlieferungsstruktur ein statisches Modell
vorab nicht feststeht, muss dieses zweitens dynamisch und skalierbar
sein.

Anhand der für die Arbeit zu Verfügung gestellten Daten aus Berlin,
Mannheim und Krefeld sowie mithilfe der Interviews wurde zunächst
versucht, eine begriffliche Kontrolle im Untersuchungsfeld zur
Vernichtung der jüdischen Gewerbetätigkeit im NS zu erhalten. Hierbei
wurde sich der Methodik der Dokumentbeschreibungssprachen aus den
Bibliotheks-, Dokumentations- und Informationswissenschaften bedient,
mit der Fachgebiete mittels Thesauri oder Klassifikationen hierarchisch
geordnet und inhaltlich erschlossen werden (Sacherschließung).[^218] In
diesem Sinne wird das Untersuchungsfeld als eigenes Begriffssystem
verstanden, mittels dessen es sich inhaltlich beschreiben lässt.[^219]
Auf diese Weise konnte nicht nur eine Übersicht über die wesentlichen
historischen Informationen im Untersuchungsfeld erstellt werden, sondern
es zeigte sich mit dieser Methode auch, dass es zum einen
Mehrdeutigkeiten bei der Bezeichnung von Sachverhalten gibt
(Synonymproblem) und zum anderen Unklarheiten bestehen, wie Begriffe
angewandt werden sollen.[^220] Für das Synonymproblem können
Äquivalenzklassen vorgeschlagen werden.[^221] Die unklaren Begriffe
müssen in dieser Arbeit offen bleiben, da abschließend deren globale
Relevanz für das Forschungsfeld nicht bestimmt (z.B. Insolvenz)[^222]
oder ihre Ambiguität (z.B. Geschäftsaufgabe) nicht aufgelöst werden
konnte.

Das feine Begriffssystem[^223] wurde grob abstrahiert, sodass die
generischen Begriffe auf der ersten Ebene eine Top-Level-Ontologie
ergeben, die Studien-unabhängig auf alle Forschungsdaten im
Forschungsfeld und darüber hinaus angewandt werden kann.[^224] Auf diese
Weise kann das Datenmodell kompatibel und interoperabel gehalten werden,
in der Konsequenz also zukünftig auch an andere Forschungsfelder
anschließen.

Das generische Metadatenschema wurde im nächsten Schritt in das
Wikidata-Projekt integriert, welches somit eine Strukturierung der Daten
grob vorgibt (Abbildung 4.5.).

Am Beispiel des Berliner Gewerbebetriebs ,,Gorbatschow Liköre F. Kramer
& Co", welches 1938 vom Eigentümer Josef Kramer verkauft werden musste,
wurde ein erster Entwurf für das präzise Datenmodell in Wikidata
erstellt.[^225] Analog zur Modellierung der Forschungsprojekte wurden
vorhandene Items und Properties nachgenutzt. Wo dies nicht möglich war,
sind die Entities farblich markiert. Der Entwurf wurde anschließend im
Wikidata-Projekt dokumentiert (Abbildung 4.6. Siehe auch
Wikidata-Projekt, URL (stable):
[https://www.wikidata.org/w/index.php?title=Wikidata:WikiProject_Destruction_of_the_Economic_Existence_of_the_Jews_Research/Vernichtung_der_jüdischen_Gewerbetätigkeit&oldid=1648462059](https://www.wikidata.org/w/index.php?title=Wikidata:WikiProject_Destruction_of_the_Economic_Existence_of_the_Jews_Research/Vernichtung_der_jüdischen_Gewerbetätigkeit&oldid=1648462059){.uri}.).

Hier kann das Datenmodell zur Beschreibung jüdischer Gewerbebetriebe
kollaborativ angepasst und weiterentwickelt werden. In der Tabelle in
Abbildung 4.6 stellt jede Zeile eine Aussage zu einer Entität dar (im
Bild Gewerbebetrieb und Branche). In dieser können neben der Statements
außerdem Verwendungsregeln und detaillierte Beschreibungen festgehalten
werden. Das aktuelle prototypische Datenmodell versteht sich lediglich
als Vorschlag und soll in erster Linie den Anstoß für weitere
Diskussionen geben. Denn insbesondere die Frage nach der Modellierung
der Forschungsdaten wird im Forschungsfeld bisher nicht systematisch
bearbeitet. Aber schon in dieser frühen Phase ergeben sich
Pfadabhängigkeiten, die Einfluss auf die anschließende Datenanalyse
haben. Dies kann an einem Beispiel veranschaulicht werden: Wenn zu einem
Gewerbebetrieb nur eine Adresse strukturiert erfasst wird (1:1
Kardinalität), können (überregionale) Umzüge später nicht mehr
untersucht werden. In Berlin gab es in der Access-Datenbank nur Felder
für eine Adresse pro Gewerbebetrieb. Weitere Adressen wurden
unstrukturiert in sogenannten Freitextfeldern erfasst. Damit war und ist
es nur schwer möglich, sich der Untersuchung von Ausweichsbewegungen -
was in Berlin nur auf qualitativer Ebene geschah - quantitativ zu
nähern.[^226] Wikidata mit dem dahinter stehenden Linked Data-Konzept
bietet demgegenüber den entscheidenden Vorteil, dass ausschließlich
strukturierte Daten in Subjekt-Prädikat-Objekt-Ausdrücken erfasst sowie
neue Properties und Items dynamisch ergänzt werden können. Eine
aufwändige Anpassung des Datenmodells entfällt dadurch. Die
Einschränkung ist jedoch, dass erfasste Daten zu Jüdischen
Gewerbebetrieben nicht gegen das Modell geprüft werden können. Das
bedeutet, dass Daten auf der technischen Ebene auch dann gültig wären,
wenn diese vollkommen anders erfasst würden. Damit ist eine Kontrolle
über die Gültigkeit von Daten zu Jüdischen Gewerbebetrieben zum jetzigen
Zeitpunkt nicht gegeben. Wikidata bietet aber mit dem Ziel der weiteren
Qualitätssicherung die Erstellung von *EntitySchemas* an (Abbildung
4.7).[^227] Damit ließe sich ein verbindliches Schema zur Erfassung von
Jüdischen Gewerbebetrieben definieren. Dies ist jedoch erst dann
sinnvoll, wenn ein gemeinsamer Grundstamm an Aussagen im Forschungsfeld
feststeht.

##### Personenbezogene Daten

Auch wenn die Daten zu jüdischen Gewerbebetrieben größtenteils als
ethisch unbedenklich eingestuft wurden[^228], gibt es mit den
Unternehmenseigentümern personenbezogene Daten, die besondere
forschungsethische Fragen aufwerfen, wenn sie in Open Data verfügbar
sind. Zu beachten ist, dass es sich in der Regel nicht um Personen des
öffentlichen Interesses handelt, was eine detaillierte Veröffentlichung
bibliografischer Daten rechtfertigen würde. Das bedeutet, dass der
Eigentümer Josef Kramer von Gorbatschow Liköre F. Kramer & Co nicht mit
Anne Frank[^229] oder der Holocaust-Überlebenden und Aktivistin Margot
Friedländer[^230] gleichzusetzen ist. Gerade auch die Fälle, wo
ehemalige Inhaber den Holocaust durch Emigration überlebt haben und nach
1945 einen Antrag auf Rückerstattung stellten, können rechtliche
Einwände gegen eine Veröffentlichung von detaillierten personenbezogenen
Daten sprechen.[^231] Anders als bisher im Forschungsfeld braucht
offenes Forschungdatenmanagent in Wikidata hier ein gemeinsames Vorgehen
sowie eine klare und nachvollziehbare Strategie, die den
verantwortungsvollen Umgang mit diesen sensiblen Daten sicherstellt.

Hierzu wird folgende Empfehlung gemacht: Generell sollte das grundlose
Sammeln personenbezogener Daten vermieden werden. Das bedeutet, auch
wenn sie in den Quellen vorhanden sind, aber nicht der Bearbeitung von
Forschungsfragen direkt dienen, werden sie nicht in Wikidata
aufgenommen. Der Grundsatz ist, so wenig wie möglich personenbezogene
Daten und so viel wie nötig zu erfassen. Sofern es also keine
personenbezogenen Forschungsfragen gibt, werden lediglich Daten erfasst,
die im Zusammenhang mit der unternehmerischen Tätigkeit stehen. Dies
wurde am Beispiel der Gorbatschow Liköre F. Kramer & Co für den
Eigentümer Josef Kramer in Wikidata umgesetzt.[^232] Wenn wie in einigen
Lokalstudien das Schicksal der Eigentümer nach der Besitzübernahme oder
Liquidation statistisch untersucht werden soll[^233], werden hier nur
die wesentlichen Informationen zu Emigration oder Deportation
aufgenommen. Bei der Beschreibung des Verfolgungskontextes wird auf das
bereits erwähnte WikiData-Projekt ,,Wikidata:WikiProject Victims of
National Socialism" zurückgegriffen. Demnach werden die
Eigentümer\*innen mit ,,Subjekt fungiert als (P2868)
Holocaustüberlebender (Q12409870)" bzw. ,,Subjekt fungiert als (P2868)
Opfer des Holocaust (Q5883980)" beschrieben. Für deren Schicksal werden
die Aussagen ,,Schlüsselereignis (P793) ist ein(e) (P31)
Holocaust-Gefangenentransport (Q61927259)" bzw. ,,Schlüsselereignis
(P793) ist ein(e) (P31) Auswanderung (Q187668)" verwendet. Für den Fall,
dass es weitere Informationen zu den Eigentümer\*innen in externen
öffentlichen Datenbanken gibt, die aber für die eigene Forschung nicht
relevant sind, kann zur Datenvernetzung die eindeutige externe
Personenkennung als Wikidata-Identifikator hinzugefügt werden (Abbildung
4.8).

Aus forschungsethischer Sicht kann das in dieser Arbeit angelegte
Wikidata-Projekt ein Forum sein, wo die Handhabung personenbezogener
Daten diskutiert werden kann und wo allgemeingültige Grundsätze sowie
Strategien festgehalten werden können.[^234] Damit wäre es über die
Datenmodellierung hinaus eine Plattform, die wichtige Orientierung im
Umgang mit sensiblen Daten im Forschungsfeld gibt vor allem auch für
Forscher\*innen, die sich gänzlich neu mit dem Thema befassen.

##### Quellennachweise

Die Information, woher die Daten zu jüdischen Gewerbebetrieben kommen,
stellt das vielleicht wichtigste Qualitätskriterium von offenem
Forschungsdatenmanagement im Forschungsfeld dar.[^235] Insbesondere weil
der Untersuchungsgegenstand ,,Jüdischer Gewerbebetrieb", wie gezeigt
worden ist, methodische Schwierigkeiten mit sich bringt, braucht es
Nachweise, die diesen in den Quellen eindeutig belegen. Wikidata ist für
diese Anforderung funktional besonders gut geeignet. Denn die globale
Wissensdatenbank versteht sich ausdrücklich als sekundäre Datenbank und
nicht als Primärquelle.[^236] Das bedeutet, dass jede Aussage in
Wikidata grundsätzlich als Behauptung aufgefasst wird, die erst dann als
valide gewertet wird, sobald sie durch Quellen- und Literaturangaben
belegt ist. Um den hohen Anspruch der Nachprüfbarkeit erfüllen zu
können, enthält das allgemeine Datenmodell der Wikidata neben der Items,
Properties außerdem noch sogenannte Qualifier und References
(Fundstellen), die jedem Aussagenwert (Value) eines Items beliebig oft
hinzugefügt werden können.[^237] Der Funktionsumfang der Wikidata geht
hier also über das einfache Linked Data-Modell weit hinaus. Bei der
Zitation und Erstellung von bibliografischen Items, orientiert sich
Wikidata zudem an bewährten bibliografischen Metadatenstandards wie zum
Beispiel *Functional Requirements for Bibliographic Records* (FRBR) und
verweist auf entsprechende Wikidata-Projekte, die sich auf die
Modellierung bestimmer Quellengattungen spezialisiert haben.[^238]

Für das Forschungsfeld eröffnet sich dadurch die Möglichkeit,
detailliert erstens Informationen zu Jüdischen Gewerbebetrieben mit
einer oder mehreren Belegstelle zu versehen und zweitens Angaben zu
deren Gültigkeit mittels Qualifikatoren zu machen (Abbildung 4.9).

Wie in der Abbildung 4.9 an der zweiten Fundstelle außerdem zu sehen
ist, kann ein permanenter Link zum gegenbenfalls im Web vorhandenen
Quellendigitalisit hinterlegt werden. Falls dieses in einer Open
Data-Lizenz veröffentlicht ist, bietet sich darüber hinaus an, es direkt
in das Schwesternprojekt und in die öffentliche Bildersammlung
*Wikimedia Commons*[^239] hochzuladen. Dort gibt es bereits Bildmaterial
zu Jüdischen Gewerbebetrieben vor allem in Zusammenhang mit der
Reichspogromnacht 1938 sowie mit announcierten Besitzübernahmen, das bei
zugehörigen Wikidata-Items direkt eingebunden werden kann (Abbildung
4.10).[^240]

Daraus ergibt sich erstmalig eine direkte Verknüpfung von
Forschungsdaten und historischen Quellen, die eine bisher nie dagewesene
Datenüberprüfung und -verifizierung ermöglicht und in der Konsequenz die
Glaubwürdigkeit von Forschungsdaten im Forschungsfeld enorm steigern
kann.[^241]

Das Wikidata-Projekt kann daneben zur methodischen Führung sowie zur
Entwicklung von Kriterien, welche Quellen sich als Belege für Jüdische
Gewerbebetriebe eignen, genutzt und eine qualifzierte Quellensammlung im
Forschungsfeld sukzessive aufgebaut werden.

### Erfassung von jüdischen Gewerbebtrieben

Für die Erfassung der jüdischen Gewerbebetriebe, so geht es aus den
Interviews hervor, kamen herkömmliche Microsoft-Produkte wie Excel oder
Access zum Einsatz.[^242] Es wurde folglich in erster Linie proprietäre
Software genutzt, die in der Regel nicht in Open Source veröffentlicht
ist. Dies erschwert generell eine kollaborative Arbeit auf den Daten,
denn die MS-Access-Anwendung zum Beispiel steht für Unix-Betriebssysteme
wie Linux oder Apple gar nicht oder nur eingeschränkt zur Verfügung und
ist somit nicht plattformunabhängig einsetzbar, was ein wesentliches
Kriterium von Open Source ist.

Im Zusammenhang mit der Datenerfassung ist daher die wohl größte
Herausforderung und aufwändigste Arbeit, ein User-Interface (UI) zu
gestalten, das die bestmögliche User Experience und Usability (UX)
bietet. Hier hält Wikidata nicht die perfekte Lösung bereit, aber
zumindest Auswege aus möglichen anwendungsbedingten Einschränkungen und
Zwängen, indem es nicht nur eine sondern mehrere Möglichkeiten der
Erfassung von Daten gibt. Am einfachsten ist die Eingabe der Daten im
Linked Open Data Interface direkt auf der Website von Wikidata, wo per
Mouseclick eines neues einzelnes Datenobjekt erstellt und erfasst werden
kann (Abbildung 4.11).

Diese Lösung eignet sich besonders gut, wenn nur wenige Jüdische
Gewerbebetriebe zur erfassen sind. Mit steigender Zahl kann die Eingabe
im Wikidata-Interface schnell an Grenzen stoßen. Für Berlin, Frankfurt
a.M. sowie Mannheim wurden jeweils Daten im 1.000er-Bereich
erhoben.[^243] Diese alle manuell und einzeln einzugeben, kostet vor
allem Zeit. Sinnvoller kann es hier sein, wesentliche Grunddaten zuerst
kompakt in einer Tabelle zu sammeln. Dies scheint auch vor dem
Hintergrund realistisch, wenn immer mehr Quellen mit OCR (Optical
Character Recognition) erschlossen sind und

von Wikidata --\> manuell oder über Open Refine integrieren Bulk Import
Funktion Interface eignet sich bei vielen Daten nicht so gut, vor allem
wenn zukünftig immer Mehr Daten aus automatisiert gescrapt werden können
Pipeline bauen --\> Open Refine Daten erfassen --\> in Wikidata
automatisch importierten Siehe zur Pipeline Open Refine --\>
Wikibase/Wikidata Verananstaltung
<https://nfdi4culture.de/news-events/events/jcdl-workshop-open-refine-to-wikibase-a-new-data-upload-pipeline.html>

Wikidata nicht perfekt UI und UX im aber bietet durch viele Optionen und
folglich an den jeweiligen Use Case angepasst werden können.

### Verknüpfung von Sample und Fallbeispielen

Verknüpfung strukturierter und unstrukturierter Daten --\> gängige
Praxis im Wiki\*versum Textuelle Daten WikiCommons Möglichkeit
Digitalisate zu hinterlegen und mit Wikidata zu verknüpfen Datenvielfalt
Daneben sind für das Forschungsdatenmanagement nur die Datenquellen
relevant, in denen nachweislich Forschungsdaten zu jüdischen
Gewerbebetrieben existieren. Das sind erstens vor allem die empirischen
Studien, die Teilbereiche wie die Vernichtung der jüdischen
Gewerbetätigkeit auf der Basis von Stichproben mit einer (deskriptiven)
statistischen Datenanalyse ausgewertet haben. Mit dieser Methode konnten
erstmals allgemeinere Aussagen zum Vernichtungsprozess gewonnen
werden.[^244]. Zum zweiten sind das Veröffentlichungen in analoger oder
digitaler Form, die einen stark dokumentarischen Charakter aufweisen,
der sich vorwiegend in einem deskriptiven Zusammentragen von verteilten
Informationen zu jüdischen Gewerbebetrieben und jüdischen Unternehmern
niedergeschlagen hat.[^245] Hierunter zählen auch jene
Veröffentlichungen, die nicht primär auf Daten zu jüdischen
Gewerbebetrieben fokussiert sind, sondern wo diese eher als anreichernde
Daten verstanden werden können.[^246]

Demzufolge existieren zwei Arten von Forschungsdaten zur Vernichtung der
jüdischen Gewerbetätigkeit:

1.  Es handelt es sich um **quantitative (Massen-)Daten**, die
    strukturiert, entweder als Rohdaten oder in aggregierter Form,
    vorliegen. Sie besitzen eine statistische Aussagekraft.

2.  Es handelt es sich überwiegend um **qualitative Daten**, die in der
    Regel textuell und damit unstrukturiert oder semistruktiert
    vorliegen.

Die textuellen Daten waren für eine wissenschaftlich analytische
Auswertung bislang zu unsystematisch.[^247] Umgekehrt fehlt den
statistischen Daten ihres Umfang wegens oft die entsprechende Datentiefe
und die Einzelschicksale und -geschichten hinter der Statistik sind
nicht sichtbar.[^248] Das macht diese Daten vor allem außerhalb der
wissenschaftlichen Forschung weniger greif- und nutzbar.

## Analyse

keine komplexen statistischen Auswertungen sondern sehr einfache
deskriptive Statistik, was sich über Datenabfrage umsetzen lässt
wikidata bietet mächtige Instrumente für die Auswertung sowie
Visualisierung, die für das Forschungsfeld nutzbar gemacht werden können
nachfolgend nur explorativ und beispielhaft (an einem
Beispieltdatensatz) auf Fragen konzentrieren die bisher nicht
antizipiert wurden

### Gewerbestruktur

##### Verteilung nach Branchen

##### Verteilung im Stadtraum

Siehe https://w.wiki/5D8w braucht Geodaten

##### Geschäftsfrauen

braucht Gender-Angabe

### Vernichtung

Anzahl Besitztransfer und Liquidationen (mit Liquidation ab bis
Gelöscht) im Vergleich, Entwicklung über die Zeit (Zeitreihen-Analyse)

##### 

### Abwehrstrategien

##### Namen- und Rechtsformveränderungen

##### Umzüge

## Archivierung

Möglichkeiten des Datenexports in Wikidata --\> kann in Zenodo
hochgeladen werden, dort mit doi versehen werden

## Veröffentlichung und Nachnutzung

Wikidata in der offenen Lizenz, die es gibt nämlich jede Nutze ohne
Namensnennung Fraglich, inwiefern das zumindest im akademischen Bereich
funktioniert, wo Zitation essentiell für Reputations sind. Für
Regierungsdaten in Deutschland wurde die ,,Datenlizenz Deutschland"
entwickelt die zwei Varianten hat Namensnennung Zero von

<https://www.govdata.de/lizenzen>

Es wäre hier wünschenswert,

##### Teamarbeit

bei der Erfassung und nachträglichen Bearbeitung von Daten (vor allem
Anreicherung von Quellendaten) Sowohl Datenfelder als auch Eingabe

aber auch in Hinblick auch Partizipationsgedanke wurde hier mit
aufgegriffen, der in Kapitel 3.2.3 bereits als Kriterium von offenem FDM
festgelegt wurde, findet sich auch in den Interviews wieder. Alle
grundsätzlich positiv gegenüber Citizen Science eingestellt und sehen es
nicht als Behinderung für die wissenschaftliche Forschung

Strategieentwicklung

##### Diskussionsforum

bringt Kollaboration mit sich, dass Diskurs ermöglicht wird, wo Regeln
vereinbart werden können, verständigt sich auf Vokabular, Normdaten
etc., Weiterentwicklung des Datenmodells

##### Dynamische Anpassungen

Flexible und stetige Dateneditierebene als auch auf Datenmodellebene
Datenmodell steht nicht von Anfang fest, sondern ist dynamisch, hängt
mit den Erhebungsmethoden zusammen

##### Multiperspektivischer Datenzugang

Heusler

##### Datentransfer und Nachnutzung

Recherche in Datensammlungen Daten für Erinnerungsinitiativen zur
Verfügung stellen, verschiedene Visualisierungmöglichkeiten

##### Dauerhafte Kuratierung und -pflege

keine tote Daten produzieren

##### Test- und Evaluationsphasen

der Forschungsdatenumgebung, Mitsprache bei neuen Funktionalitäten,
Involvierung in den Entwicklungsprozess

# Fazit und Ausblick

Drei wesentliche Erkenntnisse:

1\. Interviews haben gezeigt, dass Bedarfe adhoc nicht eindeutig
formuliert werden (können), was aber nicht bedeutet, dass diese nicht
vorhanden sind oder das Wissenschaftler diese nicht sehen (es braucht
Übersetzungszeit) sondern unterschiedliche Sprachwelten aufeinander
prallen, Kommunikation essenziell --\> hier braucht es Übersetzer, wie
es mit dieser Masterarbeit unternommen wurde. Erkenntnis, die persönlich
aus dieser Arbeit mitgenommen wird, dass Fragen teilweise viel zu
technisch gestellt waren, würde heute anders gestellt werden, d.h.
Versuch der Übersetzungen, Bedarfsformulierung scheitert nicht an
mangelnden Bedarfen sondern wegen der Kommunikation

2\. Gerade für verteilte projektbasierte Forschungsvorhaben zu einem
Themenkomplex wie der Vernichtung der wirtschaftlichen Existenz sind
zentralere Services notwendig, Projekte institutionell unterschiedlich
angebunden, welche jeweils ihre eigenen Dienste und Infrastrukturen
haben. Für das Forschungsfeld kann es konzeptionell ein immenser
Fortschritt bedeuten, projektübergreifend kollaborativ zu arbeiten.
Reichen Datenrepositorien Fortschritt, wären aber für das Forschungsfeld
nicht ausreichend, braucht auf der Ebene der Datenmodellierung
Infrastrukturen

3\. Forschung ist nicht auf die akademische Wissenschaft allein
beschränkt wie das hier betrachtete Forschungsfeld besondern deutlich
macht, die Frage ist, wie bekommt man die unterschiedlichen Akteure
zusammen bzw. welche Akteure werden einbezogen und welche ausgeschlossen

4\. Wenn entsprechende Infrastrukturen vorhanden und genutzt werden, das
zeigt die prototypische Implementierung, Open Science erweitert
Erkenntnismöglichkeiten, welche im Ergebnis zu einem
Erkenntnisfortschritt führen können. Verschiebt Erkenntnisgrenzen

Denn was Open Science am Ende ist, ist - wenn man der Open-Bewegung
konsequent folgt - keine Frage von einzelnen Akteuren, sondern ein
andauernder demokratischer Aushandlungsprozess vor allem aber nicht
ausschließlich auf der wissenschaftlichen Ebene

Sichtbarkeit der Forschungsarbeit erhöhen, nicht nur auf
Publikationsebene, Projekt und Forschungsdatenebene

Wie kann Schnittstelle zwischen Wissenschaft und öffentlichem Wissen/
Öffentlichkeit funktionieren (Fellow-Programm Wikimedia)

hier auf Desiderate aus den Interviews eingehen

##### Benefits

##### Drawbacks

Datenqualität in Wikidata nicht perfekt, aber bei Christoph auch nicht
Datenkonsistenz und -integrität

##### Sideeffects

Datenqualität der Wikidata verbessern und Informationen auf der
Wikipedia nachweislich stärker kontextualisieren als bisher --\> am
Beispiel von
<https://de.wikipedia.org/w/index.php?title=Wodka_Gorbatschow&oldid=222273519>
und Q2587685

Abschließend zur Forschungsfeldbetrachtung ist festzustellen, dass das
dieses inhaltlich mit steigender Anzahl von Lokalstudien in den letzten
20 Jahren enorm voranschritt, aber im Vergleich auf konzeptueller Ebene
die Weiterentwicklung überraschend stagnierte. Wenn mehrheitlich in den
Studien der Begriff ,,Arisierung" (oder ,,Entjudung") kritisch und
problemorientiert hinterfragt wird, in der Konsequenz aber nicht aus der
wissenschaftlichen Arbeit verbannt, sondern entgegen der eigenen
Argumentation als Untersuchungsbegriff beibehalten wird, dann herrscht
ein offensichtlicher Mangel an einer breiteren konzeptionellen und
methodischen Auseinandersetzung im Forschungsfeld. Dafür spricht auch,
dass es bis heute keine einheitliche Definition des Begriffs gibt.[^249]
Einerseits wird darunter speziell der Transfer von jüdischem Eigentum,
insbesondere Firmeneigentum, in nicht-jüdischen Besitz und andererseits
generisch der gesamte Prozess der wirtschaftlichen Existenzvernichtung
der Juden gefasst, wobei dieser unterschiedlich ausgedehnt wurde[^250]
Einen allgemeingültigen wissenschaftlichen Konsens scheint es auf der
methodischen Ebene im Forschungsfeld nicht zu geben. Unklar ist, warum
nach den eindeutig nachvollziehbaren Gegeneinwänden und alternativen
Vorschlägen aus dem Forschungsfeld selbst sich diese methodische
Schwäche bis heute hartnäckig hält.

Die Herausforderung besteht darin, zentrale sowie einheitliche
Infrastrukturen zu schaffen, die von den überwiegend einzelgeförderten
Forschungsprojekten - bei der DFG immerhin mehr als ein Drittel im Jahr
2020 projektbezogener Einzelförderung -- nicht allen Forschungsvorhaben
ein nachhaltiges Forschungsdatenmanagement inhärent ist. Da es
entsprechende Forschungsgebiete in der Vergangenheit schlichtweg noch
nicht gab, war der Umgang mit Forschungsdaten mehr von individuellen
digitalen Kenntnissen und Kompetenzen des oder der Wissenschaftler\*in
abhängig als von allgemeingültigen wissenschaftlichen Kriterien sowie
technischen Standards. Zeitökonomisch betrachtet bedeutet der
wissenschaftliche Umgang mit digitalen Forschungsdaten zudem
Arbeitsaufwand, der zu den routinierten Abläufen hinzukommt. Erst recht,
wenn sich ganz neu mit dieser Thematik auseinandergesetzt werden muss.
Das wirft die berechtigte Frage nach dem Kosten-Nutzen-Verhältnis für
die eigene Forschungsarbeit auf.

Eine Synthese dieser bisher nebeneinander existierenden
Forschungsergebnisse gibt es noch nicht.[^251]

# Abkürzungsverzeichnis

# Abbildungsverzeichnis

# Literaturverzeichnis

# Forschungsdaten

## Transkripte

## Codesystem

## Modellierungen

## SPARQL-Beispielabfragen

[^1]: Genau genommen ist das Konzept von Open Science, also im Kern
    eigene Forschungsmethoden, -praktiken und -ergebnisse transparent
    für andere zu machen, schon älter und findet Anwendung bereits in
    der Renaissance. Für das Thema dieser Arbeit ist eine longue durée
    letztlich wissenschaftlicher Praxis jedoch nicht relevant. Daher
    wird sich auf die aktuelle Bewegung und deren direkte Ursprünge
    begrenzt. Siehe auch Paul A. David: Common Agency Contracting and
    the Emergence of ,,Open Science" Institutions, in: The American
    Economic Review (Hrsg.), 2. Ausgabe, 1998, S. 15--21, URL (stable):
    <http://www.jstor.org/stable/116885.>.

[^2]: Vgl. ayway media (Hrsg.): Das digitale Handbuch, Kapitel C.15 Die
    ,,Open-Bewegung", Vettelschloss 2016, S. 252

[^3]: Als erste Replikationsstudie dieser Art wird jene des
    Medizinwissenschaftlers und Statistiskers John Ioannidis aus dem
    Jahr 2005 gezählt, mit der er erstmals systematisch versuchte,
    veröffentlichte Untersuchungsergebnisse nachträglich zu replizieren/
    reproduzieren. Siehe John P.A. Ioannidis: Why Most Published
    Research Findings Are False, PLoS Med 2(8): e124, 2005,
    doi:10.1371/journal.pmed.0020124. Es folgten eine Reihe weiterer
    Replikationsstudien auch in anderen Fächern wie den
    Sozialwissenschaften. Siehe zum Beispiel Marjan Bakker, Annette van
    Dijk, Jelte M. Wicherts: The Rules of the Game Called Psychological
    Science, in: Perspectives on Psychological Science, 7(6), 2012, S.
    543-554, doi:10.1177/1745691612459060; Thomas Herndon, Michael Ash,
    Robert Pollin: Does high public debt consistently stifle economic
    growth? A critique of Reinhart and Rogoff, in: Cambridge Political
    Economy Society (Hrsg.), Cambridge Journal of Economics, Band 38, 2.
    Ausgabe, Oxford 2014, S. 257-279, URL (stable):
    <https://www.jstor.org/stable/24694929>; Jeremy Freese, David
    Peterson: Replication in Social Science, in: Annual Reviews (Hrsg),
    Annual Review of Sociology, Band 43, San Mateo 2017, S. 147-165,
    doi:10.1146/annurev-soc-060116-053450

[^4]: Diskutiert wurden insbesondere, wie das Institut für Psychologie
    an der Humboldt-Universität zu Berlin konzis berichtete,
    \"p-hacking, selektives Berichten von (abhängigen) Variablen,
    Hypothesizing After the Results are Known (HARKING), nur
    signifikante Ergebnisse berichten, mehr Daten sammeln nachdem die
    bestehenden Daten keine positiven Ergebnisse hervorgebracht haben,
    Publikations Bias\". Methodengruppe Berlin (Autorengruppe): Die
    Replikationskrise und Open Science, Blog Post, Humboldt-Universität
    zu Berlin, Lebenswissenschaftliche Fakultät Institut für
    Psychologie, Lehrstuhl für Psychologische Methodenlehre (Hrsg), URL:
    <http://methods-berlin.com/de/replikationskrise_open_science/>
    (letzter Zugriff am 21.04.2022). Siehe auch Klaus Fiedler, Norbert
    Schwarz: Questionable Research Practices Revisited, in: SAGE
    Publishing (Hrsg.), Social Psychological and Personality Science,
    Band 7, 1. Ausgabe, 2016, S. 45-52, doi:10.1177/1948550615612150;
    Annie Franco, Neil Malhotra, Gabor Simonovits: Publication bias in
    the social sciences. Unlocking the file drawer, in: American
    Association for the Advancement of Science (Hrsg.), Science, Band
    345, Ausgabe 6203, Washington 2014, S. 1502-1505,
    doi:10.1126/science.1255484.

[^5]: Vgl. Deutsche Forschungsgemeinschaft (Hrsg.): Replizierbarkeit von
    Forschungsergebnissen. Eine Stellungnahme der Deutschen
    Forschungsgemeinschaft, Stand: April 2017, URL:
    <https://www.dfg.de/download/pdf/dfg_im_profil/geschaeftsstelle/publikationen/stellungnahmen_papiere/2017/170425_stellungnahme_replizierbarkeit_forschungsergebnisse_de.pdf>
    (letzter Zugriff am 21.04.2022).

[^6]: Entsprechend der Internationalität der Open Science-Bewegung,
    existieren weltweit Open Science Initiativen, von denen allein in
    Deutschland hier nur eine Auswahl wiedergegeben werden kann: Berlin
    School of Public Engagement and Open Science als
    Kollaborationsprojekts des Museums für Naturkunde Berlin, der
    Humboldt-Universität zu Berlin und der Robert-Bosch-Stiftung, URL:
    <https://www.museumfuernaturkunde.berlin/de/future/wissenschaftscampus/berlin-school-public-engagement-and-open-science>;
    Open Science Working Group an der FU Berlin, URL:
    <https://www.fu-berlin.de/sites/open-science>; Open Science Center
    an der LMU München; Initiative für Offene Wissenschaft und
    Innovation des Stifterverbands, URL:
    <https://www.stifterverband.org/open-science-innovation-netzwerke>.

[^7]: Zu dessen Hauptakteuren gehören u.a. Berlin University Alliance,
    das Helmholtz Center (Open Science), das LMU Open Science Center
    (OSC), das Netzwerk der Open Science Initiativen (NOSI), die
    Deutsche Gesellschaft für Psychologie (DGPs), u.a. Siehe Ankündigung
    der Berlin University Alliance: German Reproducibility Network
    gestartet, News vom 01.02.2021, URL:
    <https://www.berlin-university-alliance.de/news/items/2021/210201-grn.html>.
    Homepage des GRN unter URL: <https://reproducibilitynetwork.de/>
    (alle letzter Zugriff am 27.04.2022).

[^8]: URL: <https://www.cos.io/?hsLang=en> (letzter Zugriff am
    21.04.2022).

[^9]: Brian A. Nosek, Johanna Cohoon, Mallory C. Kidwell, Jeffrey R.
    Spies: Estimating the reproducibility of psychological science, in:
    American Association for the Advancement of Science (Hrsg.),
    Science, Band 349, Ausgabe 6251, Washington 2015,
    doi:10.1126/science.aac4716.

[^10]: Wikimedia Deutschland e. V., Open Knowledge Foundation
    Deutschland e. V. (Hrsg.): ABC der Offenheit, Berlin 2019, S. 4f.,
    URL:
    [https://commons.wikimedia.org/wiki/File:ABC_der_Offenheit\_-\_Broschüre\_(2019).pdf](https://commons.wikimedia.org/wiki/File:ABC_der_Offenheit_-_Broschüre_(2019).pdf){.uri}
    (letzter Zugriff am 26.04.2022).

[^11]: Ebd. sowie siehe auch Open Knowledge Foundation (Hrsg.): Why open
    data? URl: <https://okfn.org/opendata/why-open-data/> (letzter
    Zugriff am 26.04.2022).

[^12]: Veröffentlichung des ersten Webbrowsers Netscape in offener
    Lizenz, die Personen auf der ganzen Welt mit PC und
    Internetverbindung ermöglichte, frei im Web ,,zu surfen"

[^13]: Erfunden wurde das WWW vom Physiker und Informatiker Tim
    Berners-Lee, der 1989 am CERN in Genf arbeitete und technischen
    Lösungen suchte, wie unter Forschern schnell und einfach
    kommuniziert werden kann. Die grundlegenden Technologien des WWW
    waren und sind es bis heute: HTML zur Darstellung und Verlinkung von
    Informationen (Hyper Text Markup Language), URI/ URL (Unified
    Ressource Identifier bzw. Locator) zur Lokalisierung einer Ressource
    z.B. eines HTML-Dokuments im Rechnernetz, HTTP (Hyper Text Transfer
    Protocol) zur Übertragung dieser Ressource im Rechnernetz. Zur
    detaillierten Historie, Funktionsweise und weiteren Entwicklung des
    WWW siehe zum Beispiel Tim Berners-Lee, Mark Fischetti: Weaving the
    web. The original design and ultimative destiny of the World Wide
    Web by its inventor, New York 2011. Niels Brügger: Web history, New
    York, Bern 2010. James Gilles, Robert Cailliau: How the Web was
    born. The story of the World Wide Web, Oxford University Press,
    2000.

[^14]: Vgl. Benedikt Fecher, Sönke Friesike: Open Science. One Term,
    Five Schools of Thought, Springer, 2014, S.11,
    doi:10.1007/978-3-319-00026-8_2.

[^15]: Der Begründer Tim Berners-Lee hat sich von Anfang dafür
    eingesetzt das WWW offen zu halten. Er gründete 2012 in London das
    gemeinnützige Open Data Institute (ODI) mit, wodurch er selbst ein
    (einflussreicher) Vertreter der Open-Bewegung ist. URL:
    <https://theodi.org/> (letzter Zugriff am 27.04.2022).

[^16]: Siehe Erklärung der ,,Budapest Open Access Initiative" vom
    14.02.2002, URL:
    <https://www.budapestopenaccessinitiative.org/read/> sowie
    ,,Berliner Erklärung über den offenen Zugang zu wissenschaftlichem
    Wissen" vom 22. Oktober 2003, abgerufen auf der Website der Max
    Planck Gesellschaft, URL:
    <https://openaccess.mpg.de/Berliner-Erklaerung> (alle letzter
    Zugriff am 02.05.2022)

[^17]: Vgl. Birgit Schmidt, Astrid Orth, Gwen Franck, Iryna Kuchma, Petr
    Knoth, José Carvalho: Stepping up Open Science Training for European
    Research, in: Publications (Hrsg), 2 Ausgabe, 2016, S. 3,
    doi:10.3390/publications4020016. Eine konzise Übersicht aller
    Bereiche siehe auch WMK, OKF (2019), ABC der Offenheit, S. 14-54

[^18]: URL: <https://wikimediafoundation.org/de/> (letzter Zugriff am
    22.04.2022)

[^19]: Vgl. den Wikipedia-Eintrag zur Wikimedia Foundation, Seite
    ,,Wikimedia Foundation". In: Wikipedia -- Die freie Enzyklopädie.
    Bearbeitungsstand: 31. März 2022, 20:07 UTC. URL:
    <https://de.wikipedia.org/w/index.php?title=Wikimedia_Foundation&oldid=221669459.>
    (letzter Zugriff am 22.04.2022) In Deutschland vertreten durch den
    Verein Wikimedia Deutschland e. V., vgl. ebd.

[^20]: URL: <https://de.wikipedia.org/wiki/Wikipedia:Hauptseite>
    (letzter Zugriff am 22.04.2022)

[^21]: Zum Beispiel das Wörterbuch Wictionary (2002), URL:
    <https://de.wiktionary.org/>; die Text- und Quellensammlung
    Wikisource (2003), URL: <https://de.wikisource.org/wiki/Hauptseite>;
    die Mediensammlung Wikimedia Commons (2004), URL:
    <https://commons.wikimedia.org/wiki/Hauptseite>; die
    Wissensdatenbank Wikidata (2012), URL:
    <https://www.wikidata.org/wiki/Wikidata:Main_Page> (alle letzter
    Zugriff am 22.04.2022). Eine Auflistung aller Wikimedia-Projekte ist
    auf der Homepage zu finden unter
    <https://www.wikimedia.de/projekte/> (letzter Zugriff am 22.04.2022)

[^22]: Eine Übersicht ist auf der Website zu finden unter URL:
    <https://doc.wikimedia.org/> (letzter Zugriff am 22.04.2022)

[^23]: URL: <https://okfn.org/> (letzter Zugriff am 22.04.2022).

[^24]: URL: <https://okfn.de/> (letzter Zugriff am 22.04.2022).

[^25]: URL: <https://ckan.org/>. GitHub URL:
    <https://github.com/ckan/ckan> (alle letzter Zugriff am 15.05.2022).

[^26]: Siehe Website der AG Open Science, URL:
    <https://ag-openscience.de/netzwerk/> (letzter Zugriff am
    03.05.2022).

[^27]: Vgl. Open Science AG (Hrsg.): Mission Statement. Science - Open
    by default, Verison 1.0, Oktober 2014, URL:
    <https://ag-openscience.de/mission-statement/> (letzter Zugriff am
    03.05.2022).

[^28]: Wikimedia Deutschland (Hrsg.): Freies Wissen und Wissenschaft,
    Blogreihe, Teil 01-07, URL:
    <https://blog.wikimedia.de/2015/04/20/freies-wissen-und-wissenschaft-teil-01-science-2-0-die-digitalisierung-des-forschungsalltags/>
    (letzter Zugriff am 03.05.2022).

[^29]: Sarah Behrens, Christopher Schwarzkopf, Anna-Katharina Gödeke,
    Dr. Dominik Scholl, Nico Schneider (2022): Fellow-Programm Freies
    Wissen 2016 - 2021, Zenodo, doi:10.5281/zenodo.5788379. Siehe auch
    Informations- und Kommunikationskanäle des Fellow Programms auf
    de.wikimedia.org, URL's:
    <https://www.wikimedia.de/projects/fellow-programm-freies-wissen/>,
    <https://de.wikiversity.org/wiki/Wikiversity:Fellow-Programm_Freies_Wissen>,
    <https://blog.wikimedia.de/c/fellow-programm-freies-wissen-de/>
    (alle letzter Zugriff am 03.05.2022)

[^30]: Vgl. Moritz Schubotz, Isabella Peters, Benedikt Fecher, Dominik
    Scholl (2020): Lessons Learned aus dem Fellow-Programm Freies
    Wissen. Open-Access-Tage 2020 (OAT2020), Bielefeld, Germany, Zenodo,
    doi:10.5281/zenodo.4009144

[^31]: Bestätigt wird diese Aussage von dem öffentlichen Wiki
    ,,forschungsdaten.org" der Universität Koblenz, welches seit 2019
    von der Universität betrieben wird (vorher vom Helmholtz-Zentrum
    Potsdam und Deutschem GeoForschungsZentrum GFZ), in dem allein 11
    Definitionen vorgstellt werden, vgl. URL:
    <https://www.forschungsdaten.org/index.php/Open_Science> (letzter
    Zugriff am 30.04.2022).

[^32]: Siehe zum Beispiel Freie Universität Berlin (Hrsg.): FDM Glossar.
    Open Science Open Research Open Scholarship, URL:
    <https://www.fu-berlin.de/sites/forschungsdatenmanagement/glossar/open-science-open-research-open-scholarship.html>,
    Ben Kaden: Drei Gründe für Forschungsdatenpublikationen, Blogartikel
    auf eDissPlus, DFG-Projekt: Elektronische Dissertationen Plus,
    29.09.2016, URL:
    <https://www2.hu-berlin.de/edissplus/2016/09/29/gruende-fuer-forschungsdatenpublikationen/>
    (alle letzter Zugriff am 30.04.2022).

[^33]: Vgl. Ina Friebe: Forschungsqualität durch Open Science
    verbessern, veröffentlicht auf der Website der Berlin University
    Alliance (Hrsg.) am 12.05.2021, URL:
    <https://www.berlin-university-alliance.de/impressions/210512-lecture-series-o3/index.html>
    (letzer Zugriff am 27.04.2022).

[^34]: Vgl. CODATA Coordinated Expert Group, Paul Arthur Berkman, Jan
    Brase, Richard Hartshorn, Simon Hodson, Wim Hugo, Sabina Leonelli,
    Barend Mons, Hana Pergl, Hans Pfeiffenberger: Open Science for a
    Global Transformation: CODATA coordinated submission to the UNESCO
    Open Science Consultation. Zenodo 2020, Version 1, S. 13
    doi:10.5281/zenodo.3935461.

[^35]: Siehe Abschnitt ,,Infrastrukturen".

[^36]: Horizon Europe startete 2020 und läuft noch bis 2027 mit einem
    Förderungsumfang von insgesamt 95,5 Milliarden Euro (Phase 2021-27),
    URL:
    <https://ec.europa.eu/info/research-and-innovation/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe_en>
    (letzter Zugriff am 03.05.2022)

[^37]: Siehe zum Beispiel die Citizen Science-Plattform ,,Bürger
    schaffen Wissen", URL: <https://www.buergerschaffenwissen.de/>
    (letzter Zugriff am 03.05.2022).

[^38]: URL: <https://osf.io/> (letzter Zugriff am 28.04.2022).

[^39]: URL:
    <https://osf.io/sc9yf/?view_only=aa5eb53a48ba4eaab512d049712d704a>,
    hier nur mit lesendem Zugriff auf das Projekt.

[^40]: Vertrauensvorschuss erhält das COS vor allem durch eine
    konsequent transparente Politik wie zum Beispiel der
    Veröffentlichung aller Finanzberichte, URL:
    <https://www.cos.io/about/finances> (letzter Zugriff am 28.04.2022).

[^41]: Zum Beispiel Princeton University, New York University, George
    Washington University, u.a. Siehe <https://osf.io/institutions>
    (letzter Zugriff am 21.04.2022).

[^42]: Gemeint sind hier Social-Media-Plattformen wie Facebook, Twitter,
    Google, Amazon, etc., wo die momentane Plattformökonomie
    Monopolstellung und Machtzentrierung fördert. Siehe zu dieser
    Problematik Justus Haucap: Plattformökonomie. Neue Wettbewerbsregeln
    -- Renaissance der Missbrauchsaufsicht, in: Wirtschaftsdienst 100
    (Hrsg.), 2020, S. 20-29, doi:10.1007/s10273-020-2611-9. Siehe auch
    das jüngste Urteil des Europäischen Gerichtshofs (EuGH) zu
    Verbandsklagen gegen Facebook und dessen Datenschutzpraktiken, vgl.
    Alexander Fanta: EU-Gericht erlaubt Verbandsklagen gegen Facebook,
    netzpolotik.org, 28.04.2022, URL:
    <https://netzpolitik.org/2022/dsgvo-eu-gericht-erlaubt-verbandsklagen-gegen-facebook/>
    (letzter Zugriff am 30.04.2022). Zur Zeit in den Schlagzeilen und
    kontrovers diskutiert ist der Kauf von Twitter durch den
    Tech-Milliardär Elon Musk, vgl. Alexander Fanta: Der EU droht die
    Kraftprobe mit Elon Musks Twitter, netzpolitik.org, 26.04.2022, URL:
    <https://netzpolitik.org/2022/digitale-dienste-gesetz-der-eu-droht-die-kraftprobe-mit-elon-musks-twitter/>
    (letzter Zugriff am 30.04.2022)

[^43]: Positiv hervorzuheben ist zudem, dass das COS alle seine
    Softwareprodukte auf GitHub in Open Source veröffentlicht. Siehe
    URL: <https://github.com/CenterForOpenScience> (letzter Zugriff am
    30.04.2022).

[^44]: URL: <https://zenodo.org/> (letzter Zugriff am 28.04.2022)

[^45]: Siehe Upload-Seite in Zenodo, URL:
    <https://zenodo.org/deposit/new> (letzter Zugriff am 30.04.2022)

[^46]: Zum Beispiel die Community ,,Deutsch-jüdische Geschichte", URL:
    <https://zenodo.org/communities/djg> (letzter Zugriff am 28.04.2022)

[^47]: Siehe URL: <https://zenodo.org/account/settings/github/> (letzter
    Zugriff am 28.04.2022)

[^48]: Dies kann über die Versionsnummer der Ressource identifiziert
    werden. URL der Suchanfrage am 29.04.2022:
    <https://zenodo.org/search?page=1&size=20&type=dataset&type=publication&subtype=article&sort=mostrecent>
    Viele Artikel und Datensätze existieren häufig nur in einer Version
    (v1), was dafür spricht, dass insbesondere die finalen Ergebnisse
    auf Zenodo veröffentlicht werden. Es wäre an dieser Stelle
    interessant gewesen, einmal systematisch und mit computationalen
    Methoden zu evaluieren, wie Zenodo von Wissenschaftler\*innen
    verwendet wird und empirisch gesicherte Aussagen zu treffen, bis zu
    welchem Grad Open Science tatsächlich praktiziert wird. Dies könnte
    zum Beispiel mit der von Zenodo bereitgestellten öffentlichen
    REST-API oder dem OAI-PMH Protokoll realisiert werden, URL:
    <https://developers.zenodo.org/> (letzter Zugriff am 29.04.20222).
    Diese Auswertung konnte im Rahmen der Arbeit nicht mehr geleistet
    werden.

[^49]: URL: <https://eosc-portal.eu/> (letzter Zugriff am 27.04.2022)

[^50]: Europäische Kommission (Hrsg.): European Open Science Cloud, URL:
    <https://digital-strategy.ec.europa.eu/en/policies/open-science-cloud>
    (letzter Zugriff am 28.04.2022).

[^51]: URL: <https://eosc-portal.eu/> (letzter Zugriff am 28.04.2022).

[^52]: Auch hier wurde testweise ein Projekt für die Masterarbeit
    angelegt. Eigene Ressourcen konnten nicht hochgeladen/ eingebunden,
    sondern nur in der Cloud registrierte Open Science Angebote in einer
    privaten Liste gespeichert werden..

[^53]: In Commons digitalisiert
    (<https://commons.wikimedia.org/w/index.php?title=Category:Gartenlaube_(Magazine)&oldid=334192328&uselang=de>),
    mit Wikisource transkribiert
    (<https://de.wikisource.org/w/index.php?title=Die_Gartenlaube&oldid=4048963>)
    und in Wikidata strukturiert erfasst und ausgewertet. Siehe zum
    Projekt auch das öffentliche Repositorium auf GitHub, URL:
    <https://github.com/DieDatenlaube> sowie das Blog, URL:
    <http://diedatenlaube.github.io>. Ein Überblick über das Projekt ist
    auf das Wikimedia-Blog veröffentlicht, siehe Christopher
    Schwarzkopf: Hilfe für die Datenlaube: mit
    \[\[Wikisource+Wikidata\]\] die freie Quellensammlung verbessern,
    Wikimedia Deutschland, 16. Oktober 2019, URL:
    <https://blog.wikimedia.de/2019/10/16/hilfe-fuer-die-datenlaube-mit-wikisourcewikidata-die-freie-quellensammlung-verbessern/>
    (letzter Zugriff am 01.05.2022).

[^54]: Siehe Vorstellung des Projekts auf der Website der Universität
    Bamberg, URL: <https://www.uni-bamberg.de/islamwissenschaft/bie/>
    (letzter Zugriff am 01.05.2022). Beispielartikel in der Wikipedia
    *Fādilīya*, URL:
    [https://de.wikipedia.org/w/index.php?title=Fādilīya&oldid=202323908.](https://de.wikipedia.org/w/index.php?title=Fādilīya&oldid=202323908.){.uri}

[^55]: Dies wird auch in den beiden vorgestellten wissenschaftlichen
    Wiki\*versum-Projekten so reflektiert.

[^56]: Vgl. Dawei Lin, Jonathan Crabtree, Ingrid Dillo, u.a.: The TRUST
    Principles for digital repositories, in: Scientific Data, Ausgabe
    144, 2020, S. 6ff., doi:10.1038/s41597-020-0486-7.

[^57]: Dieser Entwicklung entsprechend haben sich mittlerweile
    Lehrstühle wie der für Digital History an der Humboldt-Universität
    zu Berlin etabliert, die sich auf ,,digitale Methoden, Techniken und
    Standards für die Geschichtswissenschaften" sowie auf ,,den
    digitalen Transformationsprozess im Fach" fokussiert haben, URL:
    <https://www.geschichte.hu-berlin.de/de/bereiche-und-lehrstuehle/digital-history/profil>
    (letzter Zugriff am 03.05.2022).

[^58]: Vgl. Johannes Fournier: Komplexität und Vielfalt gestalten, in:
    Markus Putnings, Heike Neuroth, Janna Neumann (Hrsg.),
    Praxishandbuch Forschungsdatenmanagement, Berlin/Boston 2021, S. 3,
    doi:10.1515/9783110657807.

[^59]: So zum Beispiel im Zusammenhang mit der unter Kapitel 2.1.3.
    vorgestellten EOSC. Vgl hierzu Achim Streit und Jos van Wezel:
    Deutschland in der European Open Science Cloud, in: Praxishandbuch
    Forschungsdatenmanagement, 2021, S. 31-52. Am Helmholtz-Zentrum ist
    FDM direkt an das dortige Helmholtz Open Science Office angebunden.
    Siehe N. L. Weisweiler, R. Bertelmann, J. Bumberger, K. Elger, M.
    Fiedler, P. Fuhrmann, O. Knodel, R. Krahl, Ö. Özkan, F. Rhiem, I.
    Schmahl, S. Servan, A. Upmeier, K. Wedlich-Zachodin (2022):
    Helmholtz Open Science Briefing. Helmholtz Open Science Praxisforum
    Forschungsdatenmanagement: Report, (Helmholtz Open Science
    Briefing), Potsdam : Helmholtz Open Science Office,
    doi:10.48440/os.helmholtz.044. Auch im Open Science-Thesaurus des
    Institut de l'information scientifique et technique in
    Vandoeuvre-lès-Nancy (Frankreich) erscheint FDM,
    doi:10.13143/lotr.9297.

[^60]: Nationale Forschungsdateninfrastruktur, BMBF, URL:
    [https://www.bmbf.de/de/nationale-forschungsdateninfrastruktur-8299.html (letzter Zugriff am 04.05.2022).](https://www.bmbf.de/de/nationale-forschungsdateninfrastruktur-8299.html (letzter Zugriff am 04.05.2022).){.uri}

[^61]: Bund-Länder-Vereinbarung zu Aufbau und Förderung einer Nationalen
    Forschungsdatenin-frastruktur (NFDI) vom 26. November 2018. URL:
    <https://www.gwk-bonn.de/fileadmin/Redaktion/Dokumente/Papers/NFDI.pdf>
    (letzter Zugriff am 04.05.2022).

[^62]: Nationale Forschungsdateninfrastruktur, DFG, URL:
    <https://www.dfg.de/foerderung/programme/nfdi/> (letzter Zugriff am
    04.05.2022).

[^63]: URL: <https://www.nfdi.de/verein/> (letzter Zugriff am
    04.05.2022).

[^64]: DFG (Hrsg.): Nationale Forschungsdateninfrastruktur. Statistische
    Übersichten zum Antragseingang (Dritte Ausschreibungsrunde, November
    2021), Stand: 26.11.2021, Version: 1.0, S. 18, URL:
    <https://www.dfg.de/download/pdf/foerderung/programme/nfdi/statistik_antragseingang_nfdi_3_runde_20211202.pdf>
    (letzter Zugriff am 04.05.2022).

[^65]: Siehe VHD (Hrsg.): Geschichtswissenschaft im digitalen Zeitalter:
    NFDI4Memory, veröffentlicht am 10.09.2019, URL:
    <https://www.historikerverband.de//verband/nfdi.html> (letzter
    Zugriff am 04.05.2022).

[^66]: Vgl. DFG (Hrsg.): Zeitplan für das Entscheidungsverfahren zur
    Förderung von Basisdiensten in der Nationalen
    Forschungsdateninfrastruktur, Stand 7. Dezember 2021, URL:
    <https://www.dfg.de/download/pdf/foerderung/programme/nfdi/zeitplan_nfdi_basisdienste_20211208.pdf>
    (letzter Zugriff am 05.05.2022).

[^67]: Vgl. S. Blumesberger (2021): Forschungsdaten in den
    Geisteswissenschaften. Bereits selbstverständlich oder doch noch
    etwas exotisch?, O-Bib. Das Offene Bibliotheksjournal / Herausgeber
    VDB, 8(4), S. 1--8, doi:10.5282/o-bib/5739.

[^68]: Siehe M. Wilkinson, M. Dumontier, I. Aalbersberg, u.a.: The FAIR
    Guiding Principles for scientific data management and stewardship.
    Sci Data 3, 160018 (2016). https://doi.org/10.1038/sdata.2016.18.

[^69]: Vgl. The Future of Research Communications and e-Scholarship
    (FORCE 11), The FAIR Data Principles, URL:
    <https://force11.org/info/the-fair-data-principles/> (letzter
    Zugriff am 06.05.2022).

[^70]: Bis März 2019 am Helmholtz-Zentrum Potsdam, Deutsches
    GeoForschungsZentrum GFZ, URL: <https://www.forschungsdaten.info/>
    (letzter Zugriff am 05.05.2022).

[^71]: Ebenfalls von der Uni Koblenz betrieben, URL:
    <https://www.forschungsdaten.org/index.php/Hauptseite> (letzter
    Zugriff am 05.05.2022).

[^72]: Go Fair, URL: <https://www.go-fair.org/> und FORCE11, Guiding
    Principles for Findable, Accessible, Interoperable and Re-usable
    Data Publishing version b1.0, URL:
    <https://force11.org/info/guiding-principles-for-findable-accessible-interoperable-and-re-usable-data-publishing-version-b1-0/>(alle
    letzter Zugriff am 05.05.2022).

[^73]: Wie wichtig diese Form der Wissenschaftskommunikation und
    Vermittlung ist, macht auch die aktuelle Ankündigung der DFG
    ,,Aktualisierung des Förderprogramms Informationsinfrastrukturen für
    Forschungsdaten" deutlich, in der ,,umfangreichen Maßnahmen zu
    Aufbau und Weiterentwicklung von Informationsinfrastrukturen für
    Forschungsdaten" geplant sind, Information für die Wissenschaft Nr.
    32 vom 3. Mai 2022, URl:
    <https://www.dfg.de/foerderung/info_wissenschaft/info_wissenschaft_22_32/>
    (letzter Zugriff am 05.05.2022).

[^74]: Vgl. ebd.

[^75]: URL: <https://5stardata.info/en/> (letzter Zugriff am
    06.05.2022).

[^76]: Vgl. Tim Berner-Lee: Linked Data, digitales Paper veröffentlicht
    am 27.07.2006, URL:
    <https://www.w3.org/DesignIssues/LinkedData.html> (letzter Zugriff
    am 06.05.2022). Siehe auch Günther Neher, Bernd Ritschel:
    Semantische Vernetzung von Forschungsdaten, in: Stephan Büttner,
    Hans-Christoph Hobohm, Lars Müller (Hrsg.), Handbuch
    Forschungsdatenmanagement, Bad Honnef 2011, S. 169-190.

[^77]: Siehe Informationsportal des WWW-Konsortium (w3c) zum Semantic
    Web, URL: <https://www.w3.org/standards/semanticweb/> (letzter
    Zugriff am 06.05.2022).

[^78]: Open Knowledge Open Definition Group: Open Definition. DEFINING
    OPEN IN OPEN DATA, OPEN CONTENT AND OPEN KNOWLEDGE, Version 2.1,
    URL: <https://opendefinition.org/od/2.1/en/> (letzter Zugriff am
    06.05.2022).

[^79]: Vgl. Creative Commons, URL:
    <https://creativecommons.org/share-your-work/public-domain/>
    (letzter Zugriff am 18.05.2022).

[^80]: URL: <https://creativecommons.org/> (letzter Zugriff am
    18.05.2022).

[^81]: Diese Arbeit zum Beispiel wurde in einer CC-BY-SA Lizenz auf
    GitHub veröffentlicht, siehe URL:
    <https://github.com/sopheck/offenes-fdm-fuer-historische-fd>
    (letzter Zugriff am 18.05.2022).

[^82]: Definition vom 17.02.2015, Version 1.1, URL (stable):
    <https://freedomdefined.org/index.php?title=Definition&oldid=19268>

[^83]: URL:
    <https://creativecommons.org/share-your-work/public-domain/freeworks>
    (letzter Zugriff am 18.05.2022).

[^84]: Vgl. Creative Commons (2022): Understanding Free Cultural Works,
    URL:
    <https://creativecommons.org/share-your-work/public-domain/freeworks>
    (letzter Zugriff am 18.05.2022).

[^85]: Immerhin hat die aktuelle Regierungskoalition der BRD allgemein
    einen Rechtsanspruch auf Open Data zum Ziel erklärt, dessen
    unkonkrete Umsetzungsziele aber von der Wikimedia Deutschland
    kritisiert werden. Vgl. John Weitzmann, Justus Dreyling:
    Rechtsanspruch auf Open Data. Jetzt muss es endlich losgehen,
    Blogbeitrag auf Wikimedia Deutschland vom 17. März 2022, URL:
    <https://blog.wikimedia.de/> (letzter Zugriff am 06.05.2022).

[^86]: Open Data Handbook der OKF: What is Open Data? Abschnitt What
    Data are You Talking About?, URL:
    <http://opendatahandbook.org/guide/de/what-is-open-data/> (letzter
    Zugriff am 06.05.2022).

[^87]: Hierzu gehören in erster Linie sensible Daten in der
    Gesundheitsforschung. Vgl. FAIR4Health Consortium (Hrsg.): Improving
    Health Research in EU through FAIR Data, D2.3. Guidelines for
    implementing FAIR Open Data policy in health research.pdf, Version
    1, 2019, URL: <https://osf.io/3u7dt/>.

[^88]: Peter Murray-Rust, Cameron Neylon, Rufus Pollock, John Wilbanks:
    Panton Principles, Principles for open data in science,
    veröffentlicht am 19 Februar 2010, URL:
    <https://pantonprinciples.org/> (letzter Zugriff am 06.05.2022). Es
    handelt sich dabei nicht wie bei den FAIR Data Principles um
    handfeste Kriterien, sondern um Empfehlungen.

[^89]: Im Jahr 1966 erschien die Pionierstudie von Helmut Genschel. Erst
    20 Jahre später folgte die nächste grundlegende Studie des
    israelischen Historikers Avraham Barkai, der an Gentschels
    Ergebnisse anknüpfte. Vgl. Benno Nietzel: Die Vernichtung der
    wirtschaftlichen Existenz der deutschen Juden 1933-1945. Ein
    Literatur und Forschungsbericht, in: Friedrich-Ebert-Stiftung (Hg.),
    Archiv für Sozialgeschichte, Band 49, Bonn 2009, S. 561-613.

[^90]: Als wegweisend wird regelmäßig die Lokalstudie zu Arisierung in
    Hamburg des Historikers Frank Bajohr aus dem Jahr 1997/98 gewertet.
    Siehe zum Beispiel Nietzel 2009, S. 561 oder Christiane Fritsche:
    Ausgeplündert, zurückerstattet und entschädigt. Arisierung und
    Wiedergutmachung in Mannheim, 2. Aufl., Ubstadt-Weiher, Heidelberg,
    Neustadt a. d. W., Basel 2013, S. 21. Frank Bajohr: ,,Arisierung" in
    Hamburg. Die Verdrängung der jüdischen Unternehmer 1933-1945, 2.
    Aufl., Hamburg 1998 (zuerst 1997). Auf Ursachen des Forschungsbooms
    kann im Rahmen dieser Arbeit nicht eingegangen werden. Siehe dazu
    auch Christoph Kreutzmüller, Vernichtung der jüdischen
    Gewerbetätigkeit im Nationalsozialismus. Abläufe, Blickwinkel und
    Begrifflichkeiten, Version: 2.0, in: Docupedia-Zeitgeschichte,
    12.3.2020, URL:
    <http://docupedia.de/zg/Kreutzmueller_vernichtung_der_juedischen_Gewerbetaetigkeit_v2_de_2020>

[^91]: Siehe zu den unterschiedlichen Deutungen und Perspektiven
    (insbesondere Intentionalismus vs. Strukturalismus) Bajohr 1998, S.
    10-14

[^92]: Vgl. Ludolf Herbst, Christoph Kreutzmüller, Ingo Loose u.a.,
    Einleitung, in: Ludolf Herbst, Christoph Kreutzmüller, Thomas Weihe
    (Hg.): Die Commerzbank und die Juden 1933-1945, München 2004, S.
    10-13. Diese Selbstkritik war ohne Zweifel richtig und auch
    notwendig, da sie grundlegende konzeptionelle Probleme im
    Forschungsfeld aufdeckte. Dennoch ist die einseitige Perspektive auf
    Täter, Mittäter und Mitwisser vor dem Hintergrund des
    jahrzehntelangen Verdrängens in der deutschen Nachkriegs- und
    Tätergesellschaft bis hin zu Geschichtsrevisionismus und
    Opfer-Umkehrung ein verständliches Anliegen gewesen. Letztlich
    leistete die Geschichtswissenschaft damit zwar einen späten aber
    nicht weniger wichtigen Beitrag zur historischen Aufarbeitung der
    NS-Verbrechen.

[^93]: Vgl. Nietzel 2009, S. 562-565. Mitunter wird der Begriff bis in
    die Zwangsarbeit hinein ausgeweitet. Siehe Britta Bopf:
    ,,Arisierung" in Köln. Die wirtschaftliche Existenzvernichtung der
    Juden 1933-1945, Köln 2004, S. 11.

[^94]: Siehe zum Beispiel Barbara Händler-Lachmann/Thomas Werther:
    Vergessene Geschäfte, verlorene Geschichte. Jüdisches
    Wirtschaftsleben in Marburg und seine Vernichtung im
    Nationalsozialismus, Marburg 1992; Alex Bruns-Wüstefeld: Lohnende
    Geschäfte. Die ,,Entjudung" der Wirtschaft am Beispiel Göttingens,
    Hannover 1997; Bajohr 1997/98, Einleitung, S. 9f.; Marian Rappl:
    ,,Arisierung" in München. Die Verdrängung der jüdischen
    Gewerbetreibenden aus dem Wirtschaftsleben der Stadt 1933-1939, in:
    Kommission für bayerische Landesgeschichte bei der Bayerischen
    Akademie der Wissenschaften in Verbindung mit der Gesellschaft für
    fränkische Geschichte und der Schwäbischen Forschungsgemeinschaft
    (Hrsg.), Zeitschrift für bayerische Landesgeschichte, Bd. 63, Heft
    1, München 2000, S. 82-123, hier S. 125; Heinz-Jürgen Priamus
    (Hrsg.): Was die Nationalsozialisten ,,Arisierung" nannten.
    Wirtschaftsverbrechen in Gelsenkirchen während des ,,Dritten
    Reiches", Essen 2007, S. 11ff.

[^95]: Vgl. Nietzel 2009, S. 565.

[^96]: Kreutzmüller 2016/2020, URL:
    <http://docupedia.de/zg/Kreutzmueller_vernichtung_der_juedischen_Gewerbetaetigkeit_v2_de_2020.>

[^97]: Vgl. Nietzel 2009, S. 564 und Herbst/Weihe, Commerzbank, 2004, S.
    10ff..

[^98]: Pionierarbeit leistet hier u.a. das Forschungsprojekt
    ,,Geschichte der Commerzbank von 1870 bis 1958" am Lehrstuhl für
    Zeitgeschichte an der Humboldt-Universität zu Berlin unter Leitung
    von Prof. Dr. Ludolf Herbst sowie das Forschungsprojekt zur
    Vernichtung der jüdischen Gewerbetätigkeit im Nationalsozialismus in
    den drei Großstädten Berlin, Breslau, Frankfurt am Main, ebendort.
    Siehe Ludolf Herbst/Thomas Weihe (Hg.), Die Commerzbank und die
    Juden 1933-1945, München 2004; Christoph Kreutzmüller, Ausverkauf.
    Die Vernichtung der jüdischen Gewerbetätigkeit in Berlin 1930-45,
    Berlin 2012; Benno Nietzel, Handeln und Überleben: jüdische
    Unternehmer aus Frankfurt am Main 1924-1964, Göttingen 2012

[^99]: Unwissenschaftlich insofern, als dass es sich um rassistisch
    konnotierte Begriffe handelt, die selbst eigentlich zu historisieren
    wären, anstatt diese in die Wissenschaftssprache aufzunehmen. Vgl.
    Nietzel 2009, S. 563.

[^100]: Raul Hilberg: Die Vernichtung der europäischen Juden, Band 1,
    Frankfurt am Main 1990 (zuerst englisch 1961), S. 85-163. Eine
    wichtige Ergänzung zu Hilbergs Thesen war, dass die wirtschaftliche
    Existenzvernichtung der Juden der Teilprozess, war, der ,,am
    längsten -- nämlich über den Tod der Opfer hinaus -- dauerte und
    demzufolge in alle anderen Prozesse hineinreichte". Kreutzmüller
    2012, S. 378.

[^101]: Exemplarisch wurden erstmals alle Teilprozesse systematisch im
    Rahmen der Erforschung der Geschichte der Commerzbank betrachtet.
    Siehe Herbst/Weihe, Commerzbank, 2004.

[^102]: Vgl. Kreutzmüller 2016/2020.

[^103]: Vgl. Nietzel 2012, S. 164 und Kreutzmüller 2012, S. 250.

[^104]: Systematisch untersucht von Kreutzmüller, Ausverkauf, 2012,
    Kapitel IV. Abwehrstrategien jüdischer Gewerbetreibender, S.
    257-357; Nietzel, Handeln und Überleben, 2012, Kapitel II.2
    Erwartungen, Anpassung und Selbstbehauptung, S. 99-150.

[^105]: Vgl. ebd. S. 562-565.

[^106]: Ebd. S. 564.

[^107]: Vgl. Nietzel 2009, S. 562.

[^108]: Nietzel 2009, S. 562. Nietzel greift außerdem die Beteiligung
    von nichtjüdischen Unternehmen mit auf aber explizit nicht als eine
    eigene Kategorie sondern als Querschnittaspekt, weshalb dieser hier
    nicht berücksichtigt wird, da er strenggenommen zum Forschungsfeld
    der Unternehmensgeschichte gehört. Siehe zu Unternehmensgeschichte
    Ralf Ahrens, Unternehmensgeschichte, Version: 1.0, in:
    Docupedia-Zeitgeschichte, 1.11.2010, URL:
    <http://docupedia.de/zg/Ahrens_unternehmensgeschichte_v1_de_2010.>.

[^109]: Vgl. ebd. S. 273.

[^110]: Vgl. ebd. S. 602-608.

[^111]: Aus Literaturrecherche und Interviews ging nicht hervor, dass
    Nietzels Systematik nachträglich kontrovers diskutiert oder
    weiterentwickelt wurde.

[^112]: Siehe Kreutzmüller 2016/2020, URL:
    <http://docupedia.de/zg/Kreutzmueller_vernichtung_der_juedischen_Gewerbetaetigkeit_v2_de_2020.>

[^113]: Siehe Maren Janetzko: Die ,,Arisierung" mittelständischer
    jüdischer Unternehmen in Bayern 1933-1939. Ein interregionaler
    Vergleich, Ansbach 2012, S. 17f; Claudia Flümann: ,,\... doch nicht
    bei uns in Krefeld!\". Arisierung, Enteignung, Wiedergutmachung in
    der Samt- und Seidenstadt 1933-1963, Krefeld 2015, S. 13 oder jüngst
    bei Monika Juliane Gibas: ,,Arisierung" der Wirtschaft in Thüringen:
    Das Beispiel Arnstadt, in: Schlossmuseum Arnstadt (Hrsg.): Jüdische
    Familien aus Arnstadt und Plaue. Katalog zur Sonderausstellung im
    Schlossmuseum Arnstadt, Arnstadt 2021, S. 108-148..

[^114]: Zwar wurde das Thema auch in Form von Überblicks- oder
    Gesamtdarstellungen zum Deutschen Reich (in den Grenzen von 1937)
    abgehandelt, dies jedoch nur vereinzelt und vor allem in den
    Anfangsjahren der wissenschaftlichen Auseinandersetzung mit dem
    Thema. Siehe zum Beispiel die bereits erwähnten grundlegenden
    Studien von Genschel 1966 und Barkai 1987. Danach erschienen sind
    noch: Günter Plum, Wirtschaft und Erwerbsleben, in: Wolfgang Benz
    (Hrsg.), Die Juden in Deutschland 1933-- 1945. Leben unter
    nationalsozialistischer Herrschaft, München 1988, S. 268--313.
    Dieter Ziegler, Die wirtschaftliche Verfolgung der Juden im »Dritten
    Reich«, in: Heinz-Jürgen Priamus (Hrsg.), Was die
    Nationalsozialisten ,,Arisierung" nannten. Wirtschaftsverbrechen in
    Gelsenkirchen während des »Dritten Reiches«, Essen 2007, S. 17--40.
    Für die Literaturanalyse wurden vier Überblicks- bzw.
    Gesamtdarstellungen und fünfzehn Lokalstudien erfasst. Es ist
    natürlich nicht auszuschließen, dass es mehr Darstellungen zum
    Deutschen Reich oder zu Europa gibt, aber eine Tendenz im
    Forschungsfeld hin zu lokalhistorischen Studien ist nichtsdestotrotz
    deutlich erkennbar.

[^115]: Darunter fiel auch die antisemitische Definition, was unter
    einem \"jüdischen Gewerbebetrieb\" verstanden werden sollte.

[^116]: Vgl. Nietzel 2009, S. 562, 565 und 576.

[^117]: Programmatisch war hier wieder die Lokalstudie zu Hamburg von
    Frank Bajohr Ende der neunziger Jahre. Siehe Bajohr 1997/98.

[^118]: Die einzige vergleichend angelegte Studie, allerdings nur auf
    regionaler Ebene, stammt aus dem Jahr 2012 von der Historikerin
    Maren Janetzko, erschien also nach Nietzels Literaturbericht. Vgl.
    Nietzel 2009, S. 562. Janetzko, Die ,,Arisierung" Mittelständischer
    jüdischer Unternehmen in Bayern 1933-1939. Ein interregionaler
    Vergleich 2012. Vgl. Interview B3_Transkript: ,,\[\...\] dass
    esviele Einzelstudien zur verschiedenen Städten gibt, zu Hamburg, zu
    München, zu Berlin ansatzweise - ist natürlich eine ganz andere
    Dimension in Berlin. Zu Göttingen, dann eben zu Mannheim, aber das
    sind ja alles so einzelne Bausteine.".

[^119]: Vgl. zu den Datensilos Interview B4_Transkript: ,,\[\...\] dass
    diese Vernetzungsansätze nicht nur punktuell stattfinden, weil sie
    dann auch wieder nur Fragment bleiben, sondern dass sie tatsächlich
    auch übergreifend funktionieren \[\...\]".

[^120]: Siehe Bajohr 1997, S. 12f., Rappl 2000, S. 123f., Nietzel 2009,
    S. 17

[^121]: Siehe zum Beispiel das Netzwerk ,,Jüdisches Leben Erfurt",
    Informationen zu jüdischen Unternehmen in Erfurt zusammenträgt, URL:
    <https://juedisches-leben.erfurt.de/jl/de/19jh/jgemeinde/junternehmen/index.html>.
    Bisher erschienen ist daraus die Miniatur von Christoph
    Kreutzmüller, Eckart Schörle (Hg.): Stadtluft macht frei? Jüdische
    Gewerbebetriebe in Erfurt 1919 bis 1939, Berlin 2013. Das Jüdische
    Museum Berlin (JMB) hat im Jahr 2020 die Citizen Science Plattform
    ,,Jewish Places" online geschalten, auf der Orte zu jüdischem Leben
    europaweit kollaborativ gesammelt werden können, darunter auch
    Gewerbe, URL:
    [https://www.jewish-places.de/map?term=&filter\[type\]\[0\]=facility&filter\[facility_category_facet\]\[0\]=Gewerbe\~Geschäft&filter\[location\]\[center\]=52.829120842815996,13.830385954234998&rows=100000](https://www.jewish-places.de/map?term=&filter[type][0]=facility&filter[facility_category_facet][0]=Gewerbe~Geschäft&filter[location][center]=52.829120842815996,13.830385954234998&rows=100000){.uri}.
    (alle letzter Zugriff am 07.05.2022). Oft sind Informationen zu
    jüdischen Gewerbebetrieben und Unternehmern in Form von
    Gedenkbüchern gesammelt erschienen, siehe zum Beispiel: Wolfram
    Selig: ,,Arisierung" in München. Die Vernichtung jüdischer Existenz
    1937-1939, München 2004.

[^122]: Programmatisch war das gleichnamige Handbuch des schwedischen
    Literaturhistorikers Sven Lindqvist aus dem Jahr 1978, deutsch 1989:
    Grabe wo du stehst. Handbuch zur Erforschung der eigenen Geschichte,
    Bonn 1989.

[^123]: Siehe zur Geschichte und zum Einfluss der Bewegung: Jenny
    Wüstenberg, Zivilgesellschaft und Erinnerungspolitik in Deutschland
    seit 1945, Berlin Münster 2020, Kapitel 4 Grabe, wo stehst: Die
    Geschichtsbewegung und die Graswurzel-Erinnerungskultur S. 147-200
    und Kapitel 5 Memorialästhetik und die Erinnerungsbewegungen der
    1980er, S. 201-230.

[^124]: Das bekannteste Projekt ist wahrscheinlich das
    Stolperstein-Projekt des Künstlers Gunther Demnig. Vgl. Wüstenberg
    2020, S. 209. Die erste Verlegung in Berlin-Kreuzberg im Jahr 1996
    war von den Behörden noch nicht genehmigt worden und wurde erst
    später legalisiert. Siehe Projektwebsite, URl:
    <http://www.stolpersteine.eu/start/> (Letzter Zugriff am
    26.01.2022).

[^125]: Thomas Lindenberger, Michael Wildt: Radikale Pluralität.
    Geschichtswerkstätten als praktische Wissenschaftskritik, in:
    Friedrich-Ebert-Stiftung (Hrsg.), Archiv für Sozialgeschichte, Band
    29, Bonn 1989, S. 393-411 (hier S. 395), URL (stable):
    <http://library.fes.de/jportal/receive/jportal_jparticle_00013422>.

[^126]: Diese Entwicklung hatte natürlich auch Auswirkung auf die
    akademische Geschichtswissenschaft, die sich von einer
    sozialhistorischen Ausrichtung hin zu einer *Alltagsgeschichte*, als
    neuen Forschungsansatz, weiterentwickelte. Siehe dazu Lindenberg/
    Wildt 1989, S. 393f., 405-409.

[^127]: Lindenberg/ Wildt 1989, S. 394.

[^128]: Ebd.

[^129]: DFG 2021, S. 13.

[^130]: Dissertationen: Hamburg (Bajohr 1998), Köln (Bopf 2004),
    Mittelfranken (Janetzko 2012), Mannheim (Fritsche 2013); Akademische
    Forschungsprojekte: Berlin (Kreutzmüller 2012), Frankfurt am Main
    (Nietzel 2012), Breslau (2012).

[^131]: Nürnberg und Fürth (Matthias Henkel u.a.: Entrechtet,
    entwürdigt, beraubt. Die Arisierung in Nürnberg und Fürth, hrsg. für
    d. Museen d. Stadt Nürnberg, 2012/2013), Erfurt (Christoph
    Kreutzmüller, Eckart Schörle: Stadtluft macht frei? Jüdische
    Gewerbebetriebe in Erfurt 1919 bis 1939, Leipzig 2013), jüngst
    Arnstadt (Schlossmuseum Arnstadt (Hrsg.): Jüdische
    Gewerbeansiedlungen in Arnstadt von 1874 bis 1929 und ,,Arisierung"
    der Wirtschaft in Thüringen: Das Beispiel Arnstadt, in: Jüdische
    Familien in Arnstadt und Plaue, Begleitband zur Ausstellung,
    Arnstadt 2021) ).

[^132]: Vgl. Interview B4_Transkript: ,,\[\...\] und da habe ich
    vielleicht einen anderen Zugang, als ein reiner Wissenschaftler -
    mir geht es auch immer um die erinnerungskulturelle Bedeutung oder
    die erinnerungskulturelle Sinnstiftung hier in diesem Gemeinwesen
    München, die steht für mich - nicht an erster Stelle, aber sie steht
    für mich sehr prominent weit vorne \[\...\]".

[^133]: Für Krefeld immerhin 135 jüdische Gewerbebetriebe, vgl. Flümann
    2015. Die Autorin hat der Verfasserin dieser Arbeit
    dankenswerterweise ihre Daten zur Verfügung gestellt.

[^134]: Vgl. Interview B2_Transkript: ,,\[\...\] weil ich immer wieder
    Anfragen bekomme und weiß, dass Leute sich mit all möglichen
    Unternehmensschicksalen oder Schicksalen jüdischer Bürger in ihrer
    Stadt, in ihrem Viertel auseinandersetzen und dazu auch
    Informationen suchen.".

[^135]: Vgl. Interview B1_Transkript: ,,Und das ist auch wirklich
    erstaunlich, dass ich auch nach wie vor immer noch Anfragen von
    Nachkommen erhalte, die mich fragen, was ich noch mehr zu ihren
    Vorfahren rausfinden kann.", Pos. 39.

[^136]: Ausgewählt für die Interviews wurden insgesamt 14 Personen, von
    denen acht erreichbar waren.

[^137]: Vgl. Interview B3_Transkript, Pos. 67.

[^138]: Vgl. Interview B2_Transkript, Pos. 47.

[^139]: Vgl. Interview B4_Transkript, Pos. 61.

[^140]: Vgl. Interview B3_Transkript, Pos. 83.

[^141]: Vgl. Interview B4_Transkript, Pos. 19.

[^142]: Vgl. Interview B4_Transkript, Pos. 87.

[^143]: Vgl. Interview B2_Transkript, Pos. 47.

[^144]: Vgl. Interviews B2_Transkript, Pos. 35 und B3_Transkript, Pos.
    51.

[^145]: Heute Bundesanzeiger. Die ZHRB liegt inzwischen als Scan
    vollständig digitalisiert vor, URL:
    <https://digi.bib.uni-mannheim.de/periodika/reichsanzeiger/>
    (letzter Zugriff am 18.05.2022). Siehe zur Geschichte des Deutschen
    Reichsanzeigers und Preußischen Staatsanzeigers Christoph Kling:
    ,,Deutscher Reichsanzeiger und Preußischer Staatsanzeiger.
    Einleitung zur Veröffentlichung der Digitalausgabe", Mannheim, 2016.

[^146]: Die Veröffentlichungs-, Offenlegungs- und
    Bekanntmachungspflichten bestehen bis heute. Siehe Bundesamt für
    Justiz, URL:
    <https://www.bundesjustizamt.de/DE/Themen/Ordnungs_Bussgeld_Vollstreckung/Jahresabschluesse/Offenlegung/Offenlegungspflichten/Offenlegungspflichten_node.html>.
    Das Handelsregister kann jedoch heute online eingesehen werden, URL:
    <https://www.handelsregister.de/rp_web/welcome.xhtml> (alle Zugriff
    am 18.05.2022).

[^147]: Für Berlin zum Beispiel Zeitschriften wie die ,,Jüdische
    Rundschau" oder ,,Der Stürmer" sowie öffentliche
    Vereinsmitgliederverzeichnisse, Jüd. Gemeindeblätter, Jüd.
    Adressbücher, etc. Informationen basieren auf einer
    SQL-Datenbankabfrage vom 18.05.2022.

[^148]: URL:<https://www.bundesarchiv.de/gedenkbuch/>.

[^149]: Siehe am Beispiel des Datensates de1086146, URL:
    <https://www.bundesarchiv.de/gedenkbuch/de1086146>.

[^150]: Das gleiche gilt im Übrigen auch für die ,,Zentrale Datenbank
    der Namen der Holocaustopfer" der Gedenkstätte Yad Vashem. Siehe
    Datensatz 11536340 zu selben Person wie oben, URL:
    <https://yvng.yadvashem.org/index.html?language=de&s_id=&s_lastName=Kann&s_firstName=Marion&s_place=Berlin&s_dateOfBirth=&cluster=true>
    (letzter Zugriff am 18.05.2022).

[^151]: Dazu gehören sogenannte Arisierungslisten, Entjudungsakten,
    Handelsregisterakten, etc.

[^152]: Hier gilt mitunter noch die Einschränkung nach dem
    Bundesarchivgesetz § 11 Abs. 2, dass nach Ablauf der allgemeinen
    Schutzfrist (für die Wiedergutmachungsakten in den 90er Jahren),
    personenbezogene Akten entweder mit Erlaubnis der betroffenen
    Personen oder frühestens 10 Jahre nach Tod der Person benutzt werden
    dürfen. Vgl. Bundesarchivgesetz vom 10. März 2017, URL:
    <https://www.bundesarchiv.de/DE/Navigation/Meta/Ueber-uns/Rechtsgrundlagen/Bundesarchivgesetz/bundesarchivgesetz.html>
    (letzter Zugriff am 18.05.2022).

[^153]: Vgl. Götz Aly, Karl Heinz Roth: Die restlose Erfassung.
    Volkszählen, Identifizieren, Aussondern im Nationalsozialismus,
    Berlin 1984, S. 67-105.

[^154]: Bajohr spricht sogar von ,,umfassenden Täterschutz", Bajohr
    1998, S. 24.

[^155]: Sie hat sich auch in den Interviews widergespiegelt, vgl.
    Interview B1_Transkript, Pos. 123, 125, 127, 129.

[^156]: The Central Database of Shoah Victims' Names, URL:
    <https://yvng.yadvashem.org/> (letzter Zugriff am 18.05.2022).

[^157]: URL: <https://www.wikidata.org/wiki/Wikidata:Main_Page> (letzter
    Zugriff am 20.05.2022).

[^158]: URL: <https://www.tib.eu/de/> (letzer Zugriff am 20.05.2022).

[^159]: URL: <https://nfdi4culture.de/index.html> (letzter Zugriff am
    20.05.2022).

[^160]: URL: <https://wikibase.consulting/what-is-wikibase/> (letzter
    Zugriff am 20.05.2022).

[^161]: Siehe Lozana Rossenova (2022): Examining Wikidata and Wikibase
    in the context of research data management applications,
    veröffentlicht am 16.03.2022 auf dem TIB-Blog, URL:
    <https://blogs.tib.eu/wp/tib/2022/03/16/examining-wikidata-and-wikibase-in-the-context-of-research-data-management-applications/>.

[^162]: URI: <https://nfdi4culture.de/resource/E2261/about.html>.

[^163]: Das Projekt wurde 2017 an der Fachhochschule Potsdam initiiert
    und ist vom Auswärtigen Amt gefördert worden, URL:
    <https://archivfuehrer-kolonialzeit.de/> (letzter Zugriff am
    20.05.2022).

[^164]: Zum Beispiel Georeferenzierung der Orte anhand historischen
    Kartenmaterials, URL: <https://archivfuehrer-kolonialzeit.de/map>
    (letzter Zugriff am 20.05.2022).

[^165]: URL: <https://archivfuehrer-kolonialzeit.de/about> (letzter
    Zugriff am 20.05.2022).

[^166]: URL:
    [Wikidata:WikiProject European Colonialism](Wikidata:WikiProject European Colonialism){.uri}
    (letzter Zugriff am 20.05.2022).

[^167]: Im EU-Programm ,,Horizon Europe", das bis 2027 läuft, URL:
    <https://ec.europa.eu/info/research-and-innovation/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-europe_en>.
    Projektwebsite von EHRI, URL: <https://www.ehri-project.eu/> (alle
    letzter Zugriff am 20.05.2022).

[^168]: Nancy Cooey (2018): Using Wikidata to build an authority list of
    Holocaust-era ghettos, veröffentlicht am 12.02.2018 auf dem EHRI
    Document Blog, URL:
    <https://blog.ehri-project.eu/2018/02/12/using-wikidata/#Selecting_Wikidata_as_a_Tool>
    (letzter Zugriff am 20.05.2022).

[^169]: Vgl. ebd. Zentrale Enzyklopädien sind ,,The Yad Vashem
    Encyclopedia of the Ghettos During the Holocaust" von Yad Vashem
    (Israel) und ,,USHMM Encyclopedia of Camps and Ghettos" des United
    States Holocaust Memorial Museum (USA).

[^170]: Im Rahmen dieser Arbeit können diese Technologien nicht
    detailliert vorgestellt werden, daher wird zur Vertiefung auf die
    Grundlagenliteratur verwiesen. Siehe zum Beispiel Malte Rehbein:
    Ontologien, in: Fotis Jannidis, Hubertus Kohle, Malte Rehbein
    (Hrsg.), Digital Humanities, 2017, doi:10.1007/978-3-476-05446-3_11;
    Christian Stein: Linked Open Data -- Wie das Web zur Semantik kam,
    in: Bibliothek Forschung und Praxis (Hrsg.), Band 38, Nr. 3, 2014,
    S. 447-455, doi:10.1515/bfp-2014-0055; Patrick Danowski, Adrian
    Pohl: (Open) Linked Data in Bibliotheken, Berlin, Boston, 2013,
    doi:10.1515/9783110278736; Gradmann, Steffen Hennicke, Marlies
    Olensky: Linked Data, in: Digitale Dienste für die Wissenschaft
    (Hrsg.), 2012, S. 18-22, doi.org/10.18452/6627;

[^171]: Siehe Mediawiki (2022): Wikibase/DataModel,
    URL:<https://www.mediawiki.org/wiki/Wikibase/DataModel> (letzter
    Zugriff am 22.05.2022).

[^172]: Siehe Wikidata Statements, URL:
    <https://www.wikidata.org/wiki/Help:Statements> (letzter Zugriff am
    27.05.2022).

[^173]: B4_Transkript, Pos. 67.

[^174]: B1_Transkript, Pos. 147.

[^175]: Vgl. W. H. Schröder: Historische Sozialforschung:
    Forschungsstrategie - Infrastruktur - Auswahlbibliographie.
    Historical Social Research, in: Supplement (Hrsg.) 1988, Nr. 1, S.
    1-109, hier S. 15ff., URN:
    <https://nbn-resolving.org/urn:nbn:de:0168-ssoar-286038>

[^176]: Was zu einem ,,Quellenproblem" führen kann, siehe dazu ebd. S.
    19f.

[^177]: URL:
    <https://www.dublincore.org/specifications/dublin-core/dcmi-terms/>
    (letzter Zugriff am 15.05.2022)

[^178]: URL: <https://datacite.org/> (letzter Zugriff am 15.05.2022)

[^179]: ,,Funding references", siehe Data-Cite-Dokumentation auf GitHub
    URL:
    <https://github.com/UB-LMU/DataCite_BestPracticeGuide/blob/master/BestPracticeGuide.md#fundingreference>
    (letzter Zugriff am 23.05.2022).

[^180]: Auch die NFDI sowie das Archivportal zum Deutschen Kolonialismus
    sind mit eigenen Projekten vertreten. Wikidata:WikiProject NFDI,
    URL: <https://www.wikidata.org/wiki/Wikidata:WikiProject_NFDI>.

[^181]: URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_Wikidata_for_research>.
    Darunter ist auch eine deutsche Gruppe, URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_Wikidata_for_research/de>.

[^182]: URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_Wikidata_for_research/Data_models/Research_projects>.

[^183]: Als Orientierung diente das Forschungsprojekt ,,Amyloid fibril
    cytotoxicity: new insights from novel approaches", URL:
    <https://www.wikidata.org/w/index.php?title=Q52268104&oldid=1528020632>.

[^184]: Entitäten mit weißem Hintergrund.

[^185]: URL: <https://gepris.dfg.de/gepris/OCTOPUS?task=showAbout>
    (letzter Zugriff am 21.05.2022).

[^186]: URL:
    <https://gepris.dfg.de/gepris/projekt/48308995?context=projekt&task=showDetail&id=48308995&>
    (letzter Zugriff am 23.05.2022). Hieraus ging u.a. die Lokalstudie
    zu Frankfurt am Main hervor sowie die im Interview erwähnte
    Access-Datenbank mit ca. 3.000 Gewerbebetrieben in Frankfurt a.M.,
    Siehe Nietzel 2012 und Interview B2_Transkript, Pos. 27.

[^187]: Auch die Freie Universität Berlin führt ein zentrales
    Projektverzeichnis mit detaillierten Informationen zu den einzelnen
    Projekten, siehe URL: <https://research.zuv.fu-berlin.de/projects>
    (letzter Zugriff am 24.05.2022).

[^188]: Vgl. forschungsdaten.info, URL:
    <https://www.forschungsdaten.info/themen/beschreiben-und-dokumentieren/metadaten-und-metadatenstandards/>
    (letzter Zugriff am 15.05.2022).

[^189]:

[^190]: URL: <https://ianus-fdz.de/>. Der Support war nach Auslaufen der
    DFG-Projektförderung 2017 allerdings eingeschränkt. So konnten neue
    Datensammlungen bis 2022 nicht aufgenommen werden, siehe URL:
    <http://datenportal.ianus-fdz.de/pages/information.jsp#dateneigentuemer>
    (alle letzter Zugriff 15.05.2022).

[^191]: Siehe zum Beispiel die Thesauri des Deutschen Archäologischen
    Instituts, URL: <http://thesauri.dainst.org/de.html> mit der
    Kollektion zu den Methoden, URL:
    <http://thesauri.dainst.org/de/collections/_203bcc05.html> (alle
    letzter Zugriff am 15.05.2022).

[^192]: Das sind zuvorderst die Studien zu Hamburg, Berlin, Frankfurt am
    Main, München, Mannheim und Krefeld.

[^193]: Interessant ist, dass alle Studien mit dem Anspruch gestartet
    sind, die Gesamtzahl jüdischer Gewerbetriebe zu erfassen. Dieser war
    allerdings von keiner Studie einlösbar, da erstens das Ausmaß der
    Zerstörung unterschätzt wurde und zweitens die Projektlaufzeit für
    eine Totalerhebung zu kurz war, vgl. Interview B3_Transkript, Pos.
    11 und B2_Transkript, Pos. 23.

[^194]: In München wurde jeder zweite Buchstabe aus der Gewerbekartei
    mit jüdischen Gewerbebetrieben erfasst, also ca. die Hälfte der
    Gewerbebetriebe, vgl. Rappl 2000, S. 179 Fußnote 217. In Frankfurt
    diente ebenfalls der Bestand aus dem Gewerbeamt als Hauptquelle
    (vgl. Interview B2_Transkript, Pos. 31 und 45.), während in Mannheim
    das Verzeichnis jüdischer Gewerbetreibender sowie alle
    Arisierungsakten ab 1938 erhalten ist, vgl. Interview B3_Transkript,
    Pos. 43 und 47 erhalten sind. In Hamburg basierte die
    Stichprobenziehung im Wesentlichen auf den Wiedergutmachungsakten,
    vgl. Bajohr 1998, S. 21ff. und Interview B1_Transkript, Pos. 33.

[^195]: In München übernahm diese Aufgabe das städtische Gewerbeamt,
    vgl. Rappl 2000, S. 145f. In Frankfurt am Main war der zentrale
    Akteur die Industrie- und Handelskammer.

[^196]: Zum Beispiel die Handelsregisterakten, die sogenannten
    Entjudungsakten oder die Akten der Devisenstellen, aber auch die
    Wiedergutmachungsakten nach 1945.

[^197]: Der Autor beschreibt dieses unkonventionelle Vorgehen im
    Forschungsfeld sehr detailliert in der Einleitung seiner Studie,
    vgl. Kreutzmüller 2012, S. 29-38.

[^198]: Von der Forschung wird geschätzt, dass in Berlin rund die Hälfte
    der jüdischen Gewerbebetriebe im Deutschen Reich ansässig war, also
    rund 50.000. Kreutzmüller geht von ca. 10.000 im Handelsregister
    eingetragenen jüdischen Gewerbebetrieben aus, vgl. Kreutzmüller
    2012, S. 102f.

[^199]: Vgl. Janetzko 2012, S. 18.

[^200]: Das wird in der Studie zu Hamburg auch ausführlich reflektiert.
    Vgl. Bajohr 1997, S. 9.

[^201]: An diesem Beispiel zeigt sich überdies die in Wechselbeziehung
    stehenden Teilprozesse der Verdrängung der Juden aus dem Berufsleben
    und der Vernichtung der jüdischen Gewerbetätig deutlich.

[^202]: Zum Wikidata-Projekt siehe Kapitel 4.3.

[^203]: Wikidata Talk:Q2763 (2020), Modeling of holocaust victim, URL:
    <https://www.wikidata.org/w/index.php?title=Talk:Q2763&oldid=1392179230>

[^204]: Siehe zum Beispiel Wikidata-Item Anne Frank (Q4583), URL:
    <https://www.wikidata.org/w/index.php?title=Q4583&oldid=1645273699>.

[^205]: Dieser Ansatz wurde vom Berliner Forschungsprojekt umgesetzt.

[^206]: Wikidata:Eigenschaften vorschlagen (2022), URL (stable):
    <https://www.wikidata.org/w/index.php?title=Wikidata:Property_proposal/de&oldid=1624532274>.

[^207]: Interview B3_Transkript, Pos. 79.

[^208]: Vgl. Kreutzmüller 2012, S. 38f., Nietzel 2012, S. 17.

[^209]: Vgl. Interview B2_Transkript, Pos. 27.

[^210]: URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_Destruction_of_the_Economic_Existence_of_the_Jews_Research>.

[^211]: Siehe URL: <https://www.mediawiki.org/wiki/Help:Templates>
    (letzter Zugriff am 24.05.2022).

[^212]: Siehe Kapitel 3.2.1.

[^213]: URL:
    <https://www.wikidata.org/w/index.php?title=Wikidata:WikiProject_Destruction_of_the_Economic_Existence_of_the_Jews_Research&action=history>
    (letzter Zugriff am 24.05.2022).

[^214]: Siehe Wikidata:WikiProjekte, URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProjects/de> (letzter
    Zugriff am 24.05.2022).

[^215]: Siehe WikiProject WWII, URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_WWII>;
    WikiProject NS Perpetrator Research, URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_NS_Perpetrator_Research>;
    WikiProject Victims of National Socialism, URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_Victims_of_National_Socialism>;
    WikiProject NS-Täterforschung, URL:
    [https://www.wikidata.org/wiki/Wikidata:WikiProject_NS-Täterforschung](https://www.wikidata.org/wiki/Wikidata:WikiProject_NS-Täterforschung){.uri};
    Wikidata:WikiProject Nuremberg Trials, URL:
    <https://www.wikidata.org/wiki/Wikidata:WikiProject_Nuremberg_Trials>
    (alle letzter Zugriff am 24.05.2022).

[^216]: Kreutzmüller 2012, S. 38.

[^217]: Interview B1_Transkript, Pos. 3, B2_Transkript, Pos. 31 und
    Interview B1_Transkript, Pos. 75.

[^218]: Siehe Gernot Wersig: Thesaurus-Leitfaden. Eine Einführung in das
    Thesaurus-Prinzip in Theorie und Praxis, Berlin, Boston 2016,
    doi:10.1515/9783111412719.

[^219]: Der erstellte Thesaurus als Anhang \... beigefügt.

[^220]: Ebd., S. 47-51.

[^221]: Im Modell in den einzelnen Kästchen fett hervorgehoben

[^222]: Die Geschäftsauflösung bzw. Insolvenz wurde nur in der Krefelder
    Studie untersucht.

[^223]: Im Modell grau hinterlegt

[^224]: Siehe zu Top-Level-Ontologie Rehbein, Ontologien, 2017, S.
    162-174.

[^225]: Das Modell ist als Anhang \... beigefügt.

[^226]: siehe Kreutzmüller 2012, S. 310-310 (Kap. Umzug).

[^227]: Siehe Wikidata Schemas, URL:
    <https://www.wikidata.org/wiki/Wikidata:Schemas>. Siehe zum Beispiel
    das Entity Schema zu Mensch (E10), URL:
    <https://www.wikidata.org/wiki/EntitySchema:E10> (alle letzter
    Zugriff am 27.05.2022).

[^228]: Vgl. Kapitel 3.5.

[^229]: Wikidata-Item Anne Frank (Q4583), URL:
    <https://www.wikidata.org/wiki/Q4583>.

[^230]: Wikidata-Item Margot Friedländer (Q1895371), URL:
    <https://www.wikidata.org/wiki/Q1895371>.

[^231]: Vgl. Kapitel 3.5.

[^232]: Wikidata-Item Josef Kramer (Q112135768), URL:
    <https://www.wikidata.org/wiki/Q112135768>.

[^233]: Siehe Bajohr 1998, S. 388 und Nietzel 2012, S. 121ff.

[^234]: Der Vorschlag aus dieser Arbeit wurde auf der Diskussionsseite
    im Wikidata-Projekt dokumentiert.

[^235]: Vgl. Interview B1_Transkript, Pos. 139 und Interveiw
    B3_Transkript, Pos. 73.

[^236]: Vgl. Wikidata Hilfe:Belege, URL:
    <https://www.wikidata.org/wiki/Help:Sources/de> und
    Wikidata:Nachprüfbarkeit, URL:
    <https://www.wikidata.org/wiki/Wikidata:Verifiability/de> (alle
    letzter Zugriff am 28.05.2022).

[^237]: Siehe Wikidata Help:Qualifikatoren, URL:
    <https://www.wikidata.org/wiki/Help:Qualifiers/de> und
    Wikidata:Tours/References, URL:
    <https://www.wikidata.org/w/index.php?title=Wikidata:Tours/References&oldid=1619471790>
    (alle letzter Zugriff am 28.05.2022).

[^238]: Vgl. Wikidata Hilfe:Belege, ebd. Zu FRBR siehe IFLA Study Group
    on the Functional Requirements for Bibliographic Records, Susanne
    Oehlschläger: Funktionelle Anforderungen an bibliografische
    Datensätze. Abschlussbericht (2006), in: Deutsche Nationalbibliothek
    (Hrsg.), IFLA Series on Bibliographic Control (Translation of Vol.
    19), 2006, URL (stable):
    <https://repository.ifla.org/handle/123456789/817>. Beispiel für
    Wikidata-Prjekt siehe Wikidata:WikiProject Periodicals, URL
    (stable):
    <https://www.wikidata.org/w/index.php?title=Wikidata:WikiProject_Periodicals&oldid=1609366270>.

[^239]: URL: <https://commons.wikimedia.org/wiki/Hauptseite> (letzter
    Zugriff am 28.05.2022).

[^240]: Siehe Abfrage zu ,,Arisierung" in Commons, URL:
    <https://commons.wikimedia.org/w/index.php?search=Arisierung&title=Special:MediaSearch&go=Go&type=image>
    (letzter Zugriff am 28.05.2022).

[^241]: Auch in den Interviews wurde eine mögliche Verknüpfung als
    Funktionalität von offenem Forschungsdatenmanagement herausgehoben,
    vgl. Interview B3_Transkript, Pos. 77.

[^242]: Vgl. Interview B3_Transkript, Pos. 11 und Interview
    B2_Transkript, Pos. 27.

[^243]: In Berlin ca. 8.000, Frankfurt a.M. ca. 3.000 und Mannheim ca.
    1.200.

[^244]: Daneben gibt es noch die rein qualitativen oder
    Einzelfall-Studien, die hier aber nicht näher betrachtet werden, da
    ihr Anteil an Forschungsdaten zu jüdischen Gewerbebetrieben gering
    ist.

[^245]: Nietzel hebt hier die akribisch recherchierte Textsammlung zu
    jüdischen Unternehmen in München des Archivars und Historikers
    Wolfgang Selig aus dem Jahr 2004 hervor, vgl. Nietzel 2009, S. 583.

[^246]: Hier vor allem die zahlreichen Gedenkbücher zu jüdischen
    Personen, die mittlerweile online zugänglich sind und wo sich Daten
    zu jüdischen Gewerbebetrieben in den Biogrammen der Personen
    ,,verstecken". Siehe zum Beispiel ,,Biografisches Gedenkbuch der
    Münchner Juden 1933--1945" der Stadt München, URL:
    <https://gedenkbuch.muenchen.de/> (letzter Zugriff am 12.05.2022).
    Bei der Biografie von Max Hofman ist unter ,,Weitere Informationen"
    vermerkt: ,,Max Hofmann war Inhaber der Fa. Max Hofmann, einem
    Großhandel und Versand von Manufaktur- und Textilwaren, in der
    Paul-Heyse-Straße 28/I. Das Gewerbe wurde am 17.10.1938 für den
    15.10.1938 abgemeldet.", URL (stable):
    <https://gedenkbuch.muenchen.de/index.php?id=gedenkbuch_link&gid=5722>.

[^247]: Ebd.

[^248]: Allein für Berlin hat die Stichprobe einen Umfang von ca. 8.000
    jüdischen Gewerbebetrieben. Auch für Frankfurt am Main sind es in
    der Stichprobe über 2.500 jüdische Gewerbebtriebe. Vgl. Kreutzmüller
    2012, URL: <https://www2.hu-berlin.de/djgb/www/find> (letzter
    Zugriff am 07.05.2022) und Nietzel 2012, S. 15.

[^249]: Und die es auch in der Geschichte des Begriffs nie gegeben
    hat.**Vgl. Nietzel und Kreutzmüller**

[^250]: Nachweis

[^251]: Vgl. Nietzel S.
